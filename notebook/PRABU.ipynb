{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRABU - Incremental Learning untuk Prediksi Risiko Kredit Lintas Sektor\n",
    "\n",
    "Notebook ini mendemonstrasikan penggunaan model Machine Learning dengan kemampuan pembelajaran inkremental untuk memprediksi risiko kredit. Model ini dirancang untuk dapat belajar dari data historis dan data dari berbagai sektor industri."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup dan Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import joblib # Added for potentially reloading label encoder\n",
    "\n",
    "# Tambahkan path ke direktori root proyek jika perlu (misalnya, jika notebook ada di subfolder)\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from PrabuModule import incremental_model_trainer\n",
    "from PrabuModule import ml_credit_risk_predictor\n",
    "\n",
    "# Reload modul untuk memastikan perubahan terbaru terbaca (berguna saat development)\n",
    "importlib.reload(incremental_model_trainer)\n",
    "importlib.reload(ml_credit_risk_predictor)\n",
    "\n",
    "DATASET_DIR = os.path.join(module_path, 'PrabuModule', 'datasets')\n",
    "\n",
    "# Hapus model dan preprocessor lama untuk demo yang bersih setiap kali dijalankan\n",
    "print(\"Menghapus model, preprocessor, dan file kelas lama (jika ada) untuk demo...\")\n",
    "if os.path.exists(incremental_model_trainer.MODEL_PATH): \n",
    "    os.remove(incremental_model_trainer.MODEL_PATH)\n",
    "if os.path.exists(incremental_model_trainer.PREPROCESSOR_PATH): \n",
    "    os.remove(incremental_model_trainer.PREPROCESSOR_PATH)\n",
    "if os.path.exists(incremental_model_trainer.CLASSES_PATH): \n",
    "    os.remove(incremental_model_trainer.CLASSES_PATH)\n",
    "print(\"File-file lama berhasil dihapus.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Memuat Semua Dataset Sintetis\n",
    "Data dari berbagai sektor dan perusahaan dimuat untuk simulasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = incremental_model_trainer.load_all_datasets(dataset_folder=DATASET_DIR)\n",
    "if not all_data.empty:\n",
    "    print(f\"Total data yang dimuat dari semua file CSV: {len(all_data)} baris\")\n",
    "    print(f\"Kolom yang ada: {all_data.columns.tolist()}\")\n",
    "    print(\"\\nContoh beberapa baris data:\")\n",
    "    display(all_data.head())\n",
    "    print(\"\\nDistribusi Kategori Risiko (TARGET_COLUMN):\")\n",
    "    display(all_data[incremental_model_trainer.TARGET_COLUMN].value_counts())\n",
    "    print(\"\\nDistribusi Sektor:\")\n",
    "    display(all_data['Sektor'].value_counts())\n",
    "else:\n",
    "    print(\"Tidak ada data yang dimuat. Pastikan file CSV ada di direktori yang benar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pelatihan Model Awal\n",
    "Model dilatih pada sebagian data awal. Misalnya, data dari sektor 'Pertambangan' dan 'Konstruksi' hingga tahun 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = None\n",
    "current_preprocessor = None\n",
    "current_label_encoder = None # Initialize label encoder\n",
    "\n",
    "if not all_data.empty:\n",
    "    # Pilih data untuk pelatihan awal\n",
    "    # Misal, ambil data dari 2 sektor pertama dan hingga tahun 2021\n",
    "    initial_sectors = ['Pertambangan', 'Konstruksi']\n",
    "    df_initial_train = all_data[\n",
    "        (all_data['Sektor'].isin(initial_sectors)) &\n",
    "        (all_data['PeriodeTahun'] <= 2021)\n",
    "    ].copy()\n",
    "\n",
    "    if not df_initial_train.empty:\n",
    "        print(f\"Jumlah data untuk pelatihan awal: {len(df_initial_train)} baris\")\n",
    "        print(f\"Sektor dalam data awal: {df_initial_train['Sektor'].unique().tolist()}\")\n",
    "        print(f\"Tahun dalam data awal: {df_initial_train['PeriodeTahun'].unique().tolist()}\")\n",
    "        \n",
    "        # train_initial_model now returns model, preprocessor, and label_encoder\n",
    "        current_model, current_preprocessor, current_label_encoder = incremental_model_trainer.train_initial_model(\n",
    "            df_initial_train, \n",
    "            force_retrain_preprocessor=True,\n",
    "            force_retrain_labelencoder=True # Force retrain for the first run\n",
    "        )\n",
    "        if current_model and current_preprocessor and current_label_encoder:\n",
    "            print(\"\\nModel awal dan komponen terkait berhasil dilatih/dibuat.\")\n",
    "        else:\n",
    "            print(\"\\nGagal melatih model awal atau membuat komponen terkait.\")\n",
    "    else:\n",
    "        print(\"Tidak ada data yang memenuhi kriteria untuk pelatihan awal.\")\n",
    "else:\n",
    "    print(\"Tidak ada data untuk diproses.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pembelajaran Inkremental: Menambahkan Data dari Sektor Baru\n",
    "Simulasikan kedatangan data dari sektor baru (misalnya, 'Agro') dan perbarui model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if current_model and current_preprocessor and not all_data.empty:\n",
    "    df_new_sector_data = all_data[\n",
    "        (all_data['Sektor'] == 'Agro') &\n",
    "        (all_data['PeriodeTahun'] <= 2021) # Ambil data historis awal sektor baru juga\n",
    "    ].copy()\n",
    "\n",
    "    if not df_new_sector_data.empty:\n",
    "        print(f\"\\n--- Memperbarui model dengan data sektor baru (Agro) --- ({len(df_new_sector_data)} baris)\")\n",
    "        current_model = incremental_model_trainer.update_model_incrementally(\n",
    "            df_new_sector_data, \n",
    "            existing_model_path=incremental_model_trainer.MODEL_PATH, # Pass model path\n",
    "            preprocessor=current_preprocessor,\n",
    "            label_encoder=current_label_encoder # Pass label encoder\n",
    "        )\n",
    "        if current_model:\n",
    "            print(\"Model berhasil diperbarui dengan data sektor Agro.\")\n",
    "    else:\n",
    "        print(\"\\nTidak ada data untuk sektor Agro yang memenuhi kriteria.\")\n",
    "else:\n",
    "    print(\"Model awal belum dilatih atau tidak ada data, langkah ini dilewati.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pembelajaran Inkremental: Menambahkan Data Historis Baru\n",
    "Simulasikan kedatangan data historis baru (misalnya, tahun 2022 dan 2023) untuk sektor yang sudah ada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if current_model and current_preprocessor and not all_data.empty:\n",
    "    # Ambil data dari tahun 2022 dan 2023 untuk semua sektor yang sudah dikenal model\n",
    "    # (Pertambangan, Konstruksi, Agro pada titik ini)\n",
    "    known_sectors = ['Pertambangan', 'Konstruksi', 'Agro'] \n",
    "    df_new_historical_data = all_data[\n",
    "        (all_data['Sektor'].isin(known_sectors)) &\n",
    "        (all_data['PeriodeTahun'] > 2021) \n",
    "    ].copy()\n",
    "\n",
    "    if not df_new_historical_data.empty:\n",
    "        print(f\"\\n--- Memperbarui model dengan data historis baru (Tahun > 2021) --- ({len(df_new_historical_data)} baris)\")\n",
    "        print(f\"Sektor dalam data historis baru: {df_new_historical_data['Sektor'].unique().tolist()}\")\n",
    "        print(f\"Tahun dalam data historis baru: {df_new_historical_data['PeriodeTahun'].unique().tolist()}\")\n",
    "        current_model = incremental_model_trainer.update_model_incrementally(\n",
    "            df_new_historical_data, \n",
    "            existing_model_path=incremental_model_trainer.MODEL_PATH,\n",
    "            preprocessor=current_preprocessor,\n",
    "            label_encoder=current_label_encoder\n",
    "        )\n",
    "        if current_model:\n",
    "            print(\"Model berhasil diperbarui dengan data historis baru.\")\n",
    "    else:\n",
    "        print(\"\\nTidak ada data historis baru yang memenuhi kriteria.\")\n",
    "else:\n",
    "    print(\"Model awal belum dilatih atau tidak ada data, langkah ini dilewati.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pembelajaran Inkremental: Menambahkan Sektor Lainnya\n",
    "Tambahkan sisa sektor (Manufaktur Alat Berat, Logistik Alat Berat) untuk semua periode waktu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if current_model and current_preprocessor and not all_data.empty:\n",
    "    remaining_sectors = ['Manufaktur Alat Berat', 'Logistik Alat Berat']\n",
    "    df_remaining_sector_data = all_data[all_data['Sektor'].isin(remaining_sectors)].copy()\n",
    "\n",
    "    if not df_remaining_sector_data.empty:\n",
    "        print(f\"\\n--- Memperbarui model dengan data sektor sisanya --- ({len(df_remaining_sector_data)} baris)\")\n",
    "        print(f\"Sektor dalam data baru: {df_remaining_sector_data['Sektor'].unique().tolist()}\")\n",
    "        current_model = incremental_model_trainer.update_model_incrementally(\n",
    "            df_remaining_sector_data, \n",
    "            existing_model_path=incremental_model_trainer.MODEL_PATH,\n",
    "            preprocessor=current_preprocessor,\n",
    "            label_encoder=current_label_encoder\n",
    "        )\n",
    "        if current_model:\n",
    "            print(\"Model berhasil diperbarui dengan data sektor sisanya.\")\n",
    "    else:\n",
    "        print(\"\\nTidak ada data untuk sektor sisanya.\")\n",
    "else:\n",
    "    print(\"Model awal belum dilatih atau tidak ada data, langkah ini dilewati.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Demonstrasi Prediksi\n",
    "Lakukan prediksi pada beberapa sampel data menggunakan model yang sudah final (setelah semua pembaruan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all_data.empty:\n",
    "    # Reload model dan preprocessor terbaru dari file (untuk memastikan kita menggunakan versi yang disimpan)\n",
    "    # ml_credit_risk_predictor._load_resources() # Panggil ini jika ingin paksa reload di modulnya\n",
    "    # atau kita bisa memuatnya secara manual di sini untuk pengujian notebook\n",
    "    final_model = None\n",
    "    final_preprocessor = None\n",
    "    if os.path.exists(incremental_model_trainer.MODEL_PATH):\n",
    "        final_model = joblib.load(incremental_model_trainer.MODEL_PATH)\n",
    "    if os.path.exists(incremental_model_trainer.PREPROCESSOR_PATH):\n",
    "        final_preprocessor = joblib.load(incremental_model_trainer.PREPROCESSOR_PATH)\n",
    "\n",
    "    if final_model and final_preprocessor:\n",
    "        print(\"\\n--- Melakukan prediksi dengan model final ---\")\n",
    "        # Ambil 1 sampel acak dari setiap sektor untuk prediksi\n",
    "        sample_predictions = []\n",
    "        for sector in all_data['Sektor'].unique():\n",
    "            sample_from_sector = all_data[all_data['Sektor'] == sector].sample(1, random_state=42)\n",
    "            if not sample_from_sector.empty:\n",
    "                sample_input_series = sample_from_sector.iloc[0]\n",
    "                # Hapus target asli & kolom non-fitur dari sampel input sebelum prediksi\n",
    "                features_to_drop = [incremental_model_trainer.TARGET_COLUMN, 'UniqueID', 'NamaPerusahaan', 'PeriodeTahun', 'PeriodeKuartal']\n",
    "                sample_input_dict_full = sample_input_series.to_dict()\n",
    "                sample_input_dict_for_pred = {k: v for k, v in sample_input_dict_full.items() if k not in features_to_drop and k != 'Sektor'}\n",
    "                \n",
    "                # Panggil fungsi prediksi dari ml_credit_risk_predictor\n",
    "                importlib.reload(ml_credit_risk_predictor)\n",
    "                _load_res_output = ml_credit_risk_predictor._load_resources() # Panggil fungsi load secara eksplisit\n",
    "                \n",
    "                prediction_result = ml_credit_risk_predictor.predict_credit_risk_ml(\n",
    "                    financial_data_dict=sample_input_dict_for_pred, \n",
    "                    sector=sample_input_series['Sektor']\n",
    "                )\n",
    "\n",
    "                sample_predictions.append({\n",
    "                    'Perusahaan': sample_input_series['NamaPerusahaan'],\n",
    "                    'Sektor_Asli': sample_input_series['Sektor'],\n",
    "                    'Tahun_Asli': sample_input_series['PeriodeTahun'],\n",
    "                    'Kategori_Risiko_Asli': sample_input_series[incremental_model_trainer.TARGET_COLUMN],\n",
    "                    'Prediksi_Kategori_Risiko': prediction_result.get('risk_category'),\n",
    "                    'Probabilitas': prediction_result.get('probabilities'),\n",
    "                    'Error_Prediksi': prediction_result.get('error')\n",
    "                })\n",
    "\n",
    "        if sample_predictions:\n",
    "            df_sample_predictions = pd.DataFrame(sample_predictions)\n",
    "            print(\"\\nContoh Hasil Prediksi pada Sampel Data:\")\n",
    "            display(df_sample_predictions)\n",
    "        else:\n",
    "            print(\"Tidak dapat membuat prediksi sampel.\")\n",
    "            \n",
    "    elif not all_data.empty:\n",
    "        print(\"Model atau preprocessor final tidak ditemukan. Pastikan pelatihan berhasil.\")\n",
    "else:\n",
    "    print(\"Tidak ada data untuk melakukan prediksi.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluasi Model Final dengan ROC AUC\n",
    "\n",
    "Setelah semua langkah pelatihan inkremental, kita akan mengevaluasi model final (`current_model`) menggunakan kurva ROC dan skor AUC pada keseluruhan dataset yang tersedia. \n",
    "Karena semua data (atau sebagian besar) mungkin telah digunakan dalam proses pelatihan secara bertahap (termasuk melalui `init_model` untuk CatBoost), \n",
    "evaluasi ini lebih bersifat demonstratif terhadap kemampuan model pada data yang telah dilihatnya atau data serupa. \n",
    "Untuk evaluasi yang lebih ketat terhadap generalisasi, pemisahan data uji (test set) yang benar-benar terpisah sejak awal akan diperlukan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "\n",
    "if 'current_model' in locals() and current_model and \\\n",
    "   'current_preprocessor' in locals() and current_preprocessor and \\\n",
    "   'current_label_encoder' in locals() and current_label_encoder:\n",
    "    \n",
    "    print(\"\\n--- Mengevaluasi Model Final dengan ROC AUC ---\")\n",
    "    \n",
    "    # Gunakan seluruh all_data sebagai set evaluasi untuk demonstrasi ini\n",
    "    # Idealnya, ini adalah test set yang terpisah\n",
    "    X_eval = all_data.drop(columns=[incremental_model_trainer.TARGET_COLUMN], errors='ignore')\n",
    "    y_eval_raw = all_data[incremental_model_trainer.TARGET_COLUMN]\n",
    "\n",
    "    # Pastikan label encoder sudah ter-fit (seharusnya sudah dari pelatihan)\n",
    "    if not hasattr(current_label_encoder, 'classes_'):\n",
    "        print(\"LabelEncoder tidak valid atau belum di-fit. Memuat ulang...\")\n",
    "        if os.path.exists(incremental_model_trainer.LABEL_ENCODER_PATH):\n",
    "            current_label_encoder = joblib.load(incremental_model_trainer.LABEL_ENCODER_PATH)\n",
    "        else:\n",
    "            print(\"File LabelEncoder tidak ditemukan. Evaluasi ROC dibatalkan.\")\n",
    "            current_label_encoder = None\n",
    "\n",
    "    if current_label_encoder and hasattr(current_label_encoder, 'classes_'):\n",
    "        y_eval_encoded = current_label_encoder.transform(y_eval_raw)\n",
    "        n_classes = len(current_label_encoder.classes_)\n",
    "        \n",
    "        # Binarize the output for OvR ROC curve\n",
    "        y_eval_binarized = label_binarize(y_eval_encoded, classes=list(range(n_classes)))\n",
    "\n",
    "        # Preprocess features\n",
    "        numeric_features_for_model = [col for col in incremental_model_trainer.ALL_NUMERIC_FEATURES if col in X_eval.columns]\n",
    "        categorical_features_for_model = [col for col in incremental_model_trainer.CATEGORICAL_FEATURES if col in X_eval.columns]\n",
    "\n",
    "        X_eval_processed_numeric = pd.DataFrame(current_preprocessor.transform(X_eval[numeric_features_for_model]), columns=numeric_features_for_model, index=X_eval.index)\n",
    "        X_eval_final_for_model = pd.concat([X_eval_processed_numeric, X_eval[categorical_features_for_model].reset_index(drop=True)], axis=1)\n",
    "        \n",
    "        cat_feature_indices_eval = [X_eval_final_for_model.columns.get_loc(col) for col in categorical_features_for_model if col in X_eval_final_for_model.columns]\n",
    "\n",
    "        # Get predicted probabilities\n",
    "        y_score_proba = current_model.predict_proba(X_eval_final_for_model, cat_features=cat_feature_indices_eval)\n",
    "\n",
    "        # Compute ROC curve and ROC area for each class (One-vs-Rest)\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_eval_binarized[:, i], y_score_proba[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        # Compute micro-average ROC curve and ROC area\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_eval_binarized.ravel(), y_score_proba.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "        # Compute macro-average ROC curve and ROC area\n",
    "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "        mean_tpr = np.zeros_like(all_fpr)\n",
    "        for i in range(n_classes):\n",
    "            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "        mean_tpr /= n_classes\n",
    "        fpr[\"macro\"] = all_fpr\n",
    "        tpr[\"macro\"] = mean_tpr\n",
    "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "        # Plot all ROC curves\n",
    "        plt.figure(figsize=(12, 9))\n",
    "        \n",
    "        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "                 label=f'Micro-average ROC curve (area = {roc_auc[\"micro\"]:.2f})',\n",
    "                 color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "                 label=f'Macro-average ROC curve (area = {roc_auc[\"macro\"]:.2f})',\n",
    "                 color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'forestgreen', 'red', 'purple', 'brown'])\n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                     label=f'ROC curve of class {current_label_encoder.classes_[i]} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([-0.05, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Multi-class Receiver Operating Characteristic (ROC) Curves')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"\\nSkor AUC (One-vs-Rest):\")\n",
    "        for i in range(n_classes):\n",
    "            print(f\"AUC for class {current_label_encoder.classes_[i]}: {roc_auc[i]:.4f}\")\n",
    "        print(f\"AUC Micro-average: {roc_auc['micro']:.4f}\")\n",
    "        print(f\"AUC Macro-average: {roc_auc['macro']:.4f}\")\n",
    "        \n",
    "        # Alternative way to get OvR AUC scores directly using roc_auc_score\n",
    "        if n_classes > 1: # roc_auc_score multi_class options are for > 2 classes\n",
    "          try:\n",
    "              auc_ovr_macro_direct = roc_auc_score(y_eval_binarized, y_score_proba, average=\"macro\", multi_class=\"ovr\")\n",
    "              auc_ovr_weighted_direct = roc_auc_score(y_eval_binarized, y_score_proba, average=\"weighted\", multi_class=\"ovr\")\n",
    "              print(f\"Scikit-learn roc_auc_score (OvR, macro, direct): {auc_ovr_macro_direct:.4f}\")\n",
    "              print(f\"Scikit-learn roc_auc_score (OvR, weighted, direct): {auc_ovr_weighted_direct:.4f}\")\n",
    "          except ValueError as e:\n",
    "              # This can happen if y_true is not binarized or other shape mismatches for some averages\n",
    "              print(f\"Note: Could not calculate direct roc_auc_score for multi_class 'ovr': {e}\")\n",
    "              # Try with y_eval_encoded for 'ovo' if applicable\n",
    "              try:\n",
    "                  auc_ovo_macro_direct = roc_auc_score(y_eval_encoded, y_score_proba, average=\"macro\", multi_class=\"ovo\")\n",
    "                  auc_ovo_weighted_direct = roc_auc_score(y_eval_encoded, y_score_proba, average=\"weighted\", multi_class=\"ovo\")\n",
    "                  print(f\"Scikit-learn roc_auc_score (OvO, macro, direct): {auc_ovo_macro_direct:.4f}\")\n",
    "                  print(f\"Scikit-learn roc_auc_score (OvO, weighted, direct): {auc_ovo_weighted_direct:.4f}\")\n",
    "              except Exception as e_ovo:\n",
    "                  print(f\"Error calculating roc_auc_score directly with 'ovo': {e_ovo}\")      \n",
    "else:\n",
    "    print(\"\\nModel, preprocessor, atau label encoder tidak sepenuhnya tersedia. Evaluasi ROC AUC dilewati.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Kesimpulan\n",
    "\n",
    "Notebook ini telah mendemonstrasikan:\n",
    "1. Pemuatan dataset gabungan dari berbagai sektor.\n",
    "2. Pelatihan model klasifikasi risiko kredit awal (`SGDClassifier`) pada subset data.\n",
    "3. Pembaruan model secara inkremental menggunakan `partial_fit` ketika:\n",
    "    - Data dari sektor baru ditambahkan.\n",
    "    - Data historis baru untuk sektor yang sudah ada ditambahkan.\n",
    "4. Penggunaan model yang telah dilatih/diperbarui untuk melakukan prediksi pada data baru.\n",
    "\n",
    "Pendekatan ini memungkinkan model untuk beradaptasi dengan informasi baru dan pola dari berbagai sektor tanpa perlu melatih ulang keseluruhan model dari awal setiap kali ada data baru, yang penting untuk skenario di mana data datang secara bertahap dan beragam."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
