{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae6e51f2",
   "metadata": {},
   "source": [
    "# Parser Teks Dokumen dan Pengekstrak Kata Kunci Keuangan (Tahunan)\n",
    "\n",
    "Notebook ini bertujuan untuk mem-parsing teks dari berbagai jenis dokumen (gambar, TXT, DOCX, PDF) dan kemudian mengekstrak istilah-istilah keuangan spesifik beserta nilainya, dengan fokus pada **data tahun pelaporan terbaru**. Proses ini melibatkan beberapa teknologi dan fitur utama:\n",
    "- **OCR (Optical Character Recognition)**: Untuk mengekstrak teks dari gambar dan PDF berbasis gambar.\n",
    "- **Pra-pemrosesan Gambar**: Sebelum OCR, gambar diproses melalui beberapa tahap (konversi ke skala abu, penghilangan derau, binerisasi, dan percobaan pelurusan kemiringan) untuk meningkatkan kualitas OCR.\n",
    "- **Pemrosesan Paralel untuk PDF**: Halaman PDF yang memerlukan OCR diproses secara paralel untuk mempercepat ekstraksi.\n",
    "- **Mekanisme Caching**: Hasil parsing PDF disimpan dalam cache untuk menghindari pemrosesan ulang file yang sama jika tidak ada perubahan.\n",
    "- **Ekstraksi Kata Kunci Bertarget**: Mencari istilah keuangan yang telah ditentukan (dalam Bahasa Indonesia) dan mencoba mengidentifikasi nilai numerik yang berasosiasi dengan tahun pelaporan terbaru yang terdeteksi dalam dokumen.\n",
    "- **Normalisasi Nilai**: Nilai keuangan yang diekstrak dinormalisasi ke format float.\n",
    "- **Output JSON**: Hasil akhir ekstraksi kata kunci dan nilainya disajikan dalam format JSON.\n",
    "\n",
    "Pastikan semua skrip Python pendukung (`parser_gambar.py`, `parser_dokumen_teks.py`, `parser_pdf.py`, `pengekstrak_kata_kunci.py`, `utilitas_cache.py`) berada di direktori yang sama dengan notebook ini atau terinstal dalam lingkungan Python Anda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cbffd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:21:28.175687Z",
     "start_time": "2025-06-04T16:20:54.483798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berhasil memuat stopwords Bahasa Indonesia.\n",
      "WordNetLemmatizer berhasil diinisialisasi.\n",
      "Tokenizer 'punkt' tampaknya tersedia.\n",
      "Modul-modul kustom berhasil diimpor.\n",
      "Resource NLTK (wordnet) sudah ada.\n",
      "\n",
      "Pengaturan Selesai. Anda dapat melanjutkan ke sel Konfigurasi.\n"
     ]
    }
   ],
   "source": [
    "# Langkah Pengaturan Awal\n",
    "\n",
    "# 1. Impor Pustaka dan Modul Kustom\n",
    "# Pastikan semua skrip Python (.py) yang disebutkan di bawah ini\n",
    "# berada di direktori yang sama dengan notebook ini.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "\n",
    "# Impor fungsi-fungsi dari modul-modul utilitas kita\n",
    "try:\n",
    "    from SaranaModule.parser_gambar import ekstrak_teks_dari_gambar\n",
    "    from SaranaModule.parser_dokumen_teks import ekstrak_teks_dari_txt, ekstrak_teks_dari_docx\n",
    "    from SaranaModule.parser_pdf import ekstrak_teks_dari_pdf # Fungsi ini menggunakan ekstrak_teks_dari_gambar untuk OCR\n",
    "    from SaranaModule.pengekstrak_kata_kunci import (\n",
    "        DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT, # Daftar kata kunci default\n",
    "        identifikasi_tahun_pelaporan,       # Untuk menemukan tahun dalam dokumen\n",
    "        ekstrak_data_keuangan_tahunan,      # Fungsi ekstraksi utama yang baru\n",
    "        format_ke_json,                     # Untuk output JSON\n",
    "        normalisasi_nilai_keuangan,          # Untuk membersihkan nilai angka (jika ingin diuji terpisah)\n",
    "        deteksi_pengali_global              # Untuk mendeteksi pengali global seperti 'juta', 'miliar', dll.\n",
    "    )\n",
    "    print(\"Modul-modul kustom berhasil diimpor.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error mengimpor modul kustom: {e}\")\n",
    "    print(\"Pastikan semua file .py (parser_gambar, parser_dokumen_teks, parser_pdf, pengekstrak_kata_kunci, utilitas_cache) berada di direktori yang sama.\")\n",
    "\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet.zip')\n",
    "    print(\"Resource NLTK (wordnet) sudah ada.\")\n",
    "except LookupError:\n",
    "    import ssl\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    print(\"Resource NLTK (wordnet) tidak ditemukan, mengunduh...\")\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('punkt_tab')\n",
    "    nltk.download('omw-1.4') # wordnet multilingual\n",
    "    nltk.download('punkt')   # untuk tokenisasi\n",
    "    nltk.download('stopwords') # untuk stopwords\n",
    "    print(\"Resource NLTK (wordnet) sudah terunduh.\")\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"Error terkait NLTK: {e}\")\n",
    "\n",
    "print(\"\\nPengaturan Selesai. Anda dapat melanjutkan ke sel Konfigurasi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46b6aed",
   "metadata": {},
   "source": [
    "## Penjelasan Fitur Utama\n",
    "\n",
    "Sebelum melanjutkan ke konfigurasi, berikut adalah ringkasan singkat tentang beberapa fitur utama yang digunakan dalam notebook ini:\n",
    "\n",
    "*   **Pra-pemrosesan Gambar untuk OCR**: Jika dokumen Anda adalah gambar atau PDF yang berisi halaman gambar, kualitas OCR sangat penting. Modul `parser_gambar.py` kini menyertakan langkah-langkah seperti konversi ke skala abu, penghilangan derau (noise), dan binerisasi (mengubah gambar menjadi hitam-putih) untuk meningkatkan akurasi Tesseract OCR. Implementasi dasar untuk pelurusan kemiringan (deskewing) juga ada, meskipun mungkin memerlukan penyesuaian lebih lanjut untuk kasus yang kompleks.\n",
    "*   **Pemrosesan Paralel untuk PDF**: Untuk mempercepat ekstraksi teks dari PDF yang memiliki banyak halaman berbasis gambar (yang memerlukan OCR), `parser_pdf.py` menggunakan `ThreadPoolExecutor`. Ini memungkinkan beberapa halaman diproses secara bersamaan, mengurangi waktu tunggu total.\n",
    "*   **Caching Hasil Parsing**: Untuk menghindari pemrosesan ulang file PDF yang sama berulang kali (yang bisa memakan waktu), `parser_pdf.py` kini terintegrasi dengan mekanisme caching (`utilitas_cache.py`). Hasil ekstraksi teks dari sebuah PDF akan disimpan dalam cache (default di direktori `.cache_parser_dokumen`). Jika Anda memproses PDF yang sama lagi dan file tersebut tidak berubah (berdasarkan path dan timestamp modifikasi terakhir), hasilnya akan diambil dari cache, yang jauh lebih cepat. Anda bisa membersihkan cache ini secara manual atau menggunakan fungsi `bersihkan_cache_lama` (jika ingin diimplementasikan lebih lanjut).\n",
    "*   **Logika Ekstraksi Nilai Berbasis Tahun**: Fungsi `ekstrak_data_keuangan_tahunan` dalam `pengekstrak_kata_kunci.py` dirancang untuk pertama-tama mengidentifikasi tahun pelaporan utama dalam dokumen. Kemudian, saat mencari nilai untuk kata kunci keuangan, ia akan mencoba memprioritaskan angka yang berasosiasi dengan tahun pelaporan tersebut dan membedakannya dari angka untuk tahun sebelumnya, jika keduanya muncul berdekatan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e509a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:24:29.942942Z",
     "start_time": "2025-06-04T16:24:29.937024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konfigurasi dimuat. Direktori dokumen yang akan diproses: train_documents/\n",
      "Kata kunci yang akan dicari: ['Jumlah aset lancar', 'Jumlah aset tidak lancar', 'Jumlah aset', 'Jumlah liabilitas jangka pendek', 'Jumlah liabilitas jangka panjang', 'Jumlah liabilitas', 'Jumlah ekuitas', 'Jumlah liabilitas dan ekuitas', 'Pendapatan bersih', 'Beban pokok pendapatan', 'Laba bruto', 'Laba sebelum pajak penghasilan', 'Beban pajak penghasilan', 'Laba tahun berjalan', 'Arus kas bersih yang diperoleh dari aktivitas operasi', 'Arus kas bersih yang diperoleh dari aktivitas investasi', 'Arus kas bersih yang digunakan untuk aktivitas pendanaan']\n",
      "Direktori cache PDF kustom diatur ke: .cache_parsing_dokumen\n"
     ]
    }
   ],
   "source": [
    "# --- Konfigurasi Pengguna ---\n",
    "\n",
    "# 1. Tentukan path ke dokumen Anda\n",
    "# PENTING: Ganti nilai variabel `path_dokumen` di bawah ini dengan path aktual ke dokumen yang ingin Anda proses.\n",
    "# Contoh untuk Linux/macOS: path_dokumen = \"/home/pengguna/dokumen/laporan_keuangan_2023.pdf\"\n",
    "# Contoh untuk Windows: path_dokumen = r\"C:\\Users\\Pengguna\\Documents\\LaporanKeuangan2023.docx\"\n",
    "path_dokumen = \"train_documents/\"\n",
    "\n",
    "# 2. Definisikan atau Modifikasi Kata Kunci yang Akan Diekstrak\n",
    "# `konfigurasi_kata_kunci_target` adalah list kamus (dictionary).\n",
    "# Setiap kamus harus memiliki:\n",
    "#    - 'kata_dasar': Nama kanonis untuk kata kunci tersebut (misalnya, \"Laba Bersih\"). Ini akan menjadi kunci dalam output JSON.\n",
    "#    - 'variasi': List berisi berbagai cara penulisan atau sinonim kata kunci tersebut yang mungkin muncul di dokumen.\n",
    "#\n",
    "# Anda bisa menggunakan daftar default yang diimpor (`DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT`)\n",
    "# atau membuat/memodifikasi daftar Anda sendiri di bawah ini.\n",
    "#\n",
    "# Untuk menggunakan daftar default:\n",
    "from SaranaModule.pengekstrak_kata_kunci import DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT\n",
    "konfigurasi_kata_kunci_target = DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT\n",
    "\n",
    "# 3. (Opsional) Konfigurasi Direktori Cache untuk PDF Parser\n",
    "# Jika Anda ingin parser PDF menggunakan direktori cache selain default (`.cache_parser_dokumen`),\n",
    "# Anda bisa menentukan path-nya di sini. Jika tidak, biarkan `None` untuk menggunakan default.\n",
    "direktori_cache_pdf_kustom = \".cache_parsing_dokumen\"\n",
    "\n",
    "# --- Akhir Konfigurasi Pengguna ---\n",
    "\n",
    "# Validasi awal konfigurasi\n",
    "if 'path_dokumen' not in locals() or not path_dokumen or path_dokumen == \"MASUKKAN_PATH_DOKUMEN_ANDA_DI_SINI.pdf\": # Placeholder check still relevant\n",
    "    print(\"PERINGATAN: 'path_dokumen' belum diatur, kosong, atau masih menggunakan nilai placeholder.\")\n",
    "    print(\"Mohon perbarui variabel 'path_dokumen' di atas dengan path ke DIREKTORI yang berisi dokumen-dokumen yang ingin Anda proses.\")\n",
    "elif not os.path.isdir(path_dokumen):\n",
    "    print(f\"ERROR: Path yang ditentukan ('{path_dokumen}') bukan direktori atau tidak ditemukan.\")\n",
    "    print(\"Mohon periksa kembali 'path_dokumen' dan pastikan itu adalah direktori yang valid dan ada.\")\n",
    "else:\n",
    "    print(f\"Konfigurasi dimuat. Direktori dokumen yang akan diproses: {path_dokumen}\")\n",
    "    print(f\"Kata kunci yang akan dicari: {[item['kata_dasar'] for item in konfigurasi_kata_kunci_target]}\")\n",
    "    if direktori_cache_pdf_kustom:\n",
    "        print(f\"Direktori cache PDF kustom diatur ke: {direktori_cache_pdf_kustom}\")\n",
    "\n",
    "# Inisialisasi list untuk menyimpan semua hasil ekstraksi dari semua dokumen\n",
    "semua_hasil_ekstraksi = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62ad4464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:24:34.363713Z",
     "start_time": "2025-06-04T16:24:34.357065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mencari dokumen dengan ekstensi yang didukung: .pdf, .jpg, .jpeg, .png, .tiff, .bmp, .gif, .txt, .docx di direktori: train_documents/\n",
      "Ditemukan 1 dokumen untuk diproses: ['astra_lapkeu.pdf']\n",
      "\n",
      "--- Memulai pemrosesan untuk dokumen: astra_lapkeu.pdf ---\n",
      "Tipe berkas terdeteksi: .pdf untuk astra_lapkeu.pdf\n",
      "Cache tidak ditemukan atau tidak valid untuk astra_lapkeu.pdf, memproses dari awal.\n",
      "Menyimpan hasil (hanya Entitas Induk atau kosong) ke cache untuk: astra_lapkeu.pdf\n",
      "Parsing dokumen 'astra_lapkeu.pdf' selesai. Total karakter: 12483\n",
      "Memulai ekstraksi kata kunci untuk: astra_lapkeu.pdf\n",
      "Pengali terdeteksi untuk 'astra_lapkeu.pdf': 1000000000.0\n",
      "Ekstraksi kata kunci untuk 'astra_lapkeu.pdf' selesai.\n",
      "--- Pemrosesan untuk dokumen: astra_lapkeu.pdf selesai. Hasil disimpan. ---\n",
      "\n",
      "=== Semua dokumen dalam direktori telah diproses. ===\n",
      "Total item dalam 'semua_hasil_ekstraksi': 4 (termasuk potensi pesan error global atau info tidak ada file)\n",
      "  Dokumen: astra_lapkeu.pdf, Status Ekstraksi: Sukses\n",
      "  Dokumen: astra_lapkeu.pdf, Status Ekstraksi: Sukses\n",
      "  Dokumen: astra_lapkeu.pdf, Status Ekstraksi: Sukses\n",
      "  Dokumen: astra_lapkeu.pdf, Status Ekstraksi: Sukses\n"
     ]
    }
   ],
   "source": [
    "# Langkah ini akan melakukan iterasi melalui semua dokumen yang didukung dalam direktori yang ditentukan,\n",
    "# mengekstrak teks dari masing-masing dokumen, dan kemudian mengekstrak kata kunci.\n",
    "\n",
    "# Pastikan path_dokumen (direktori) telah dikonfigurasi dengan benar dan merupakan direktori\n",
    "if 'path_dokumen' not in locals() or not path_dokumen or not os.path.isdir(path_dokumen):\n",
    "    if 'path_dokumen' in locals() and (not path_dokumen or path_dokumen == \"MASUKKAN_PATH_DOKUMEN_ANDA_DI_SINI.pdf\"):\n",
    "        pesan_error_global = \"Error: 'path_dokumen' (direktori) belum diatur, kosong atau placeholder. Silakan perbarui di sel Konfigurasi.\"\n",
    "    elif 'path_dokumen' not in locals():\n",
    "         pesan_error_global = \"Error: 'path_dokumen' (direktori) tidak terdefinisi. Silakan definisikan di sel Konfigurasi.\"\n",
    "    else: # Path bukan direktori atau tidak ada\n",
    "        pesan_error_global = f\"Error: Path '{path_dokumen}' bukan direktori yang valid atau tidak ditemukan. Mohon verifikasi path di sel Konfigurasi.\"\n",
    "    print(pesan_error_global)\n",
    "    # Jika path_dokumen tidak valid, kita tidak bisa melanjutkan. Pastikan semua_hasil_ekstraksi ada dan simpan error.\n",
    "    if 'semua_hasil_ekstraksi' not in locals(): \n",
    "        semua_hasil_ekstraksi = [] # Inisialisasi jika belum ada dari sel sebelumnya (seharusnya sudah)\n",
    "    semua_hasil_ekstraksi.append({\n",
    "        \"nama_file\": \"KONFIGURASI_ERROR\",\n",
    "        \"hasil_ekstraksi\": {\"error_global_konfigurasi\": pesan_error_global}\n",
    "    })\n",
    "else:\n",
    "    supported_extensions = ['.pdf', '.jpg', '.jpeg', '.png', '.tiff', '.bmp', '.gif', '.txt', '.docx']\n",
    "    print(f\"Mencari dokumen dengan ekstensi yang didukung: {', '.join(supported_extensions)} di direktori: {path_dokumen}\")\n",
    "    \n",
    "    files_to_process = []\n",
    "    try:\n",
    "        files_to_process = [\n",
    "            f for f in os.listdir(path_dokumen) \n",
    "            if os.path.isfile(os.path.join(path_dokumen, f)) and \n",
    "            os.path.splitext(f)[1].lower() in supported_extensions\n",
    "        ]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Direktori '{path_dokumen}' tidak ditemukan. Periksa konfigurasi path_dokumen.\")\n",
    "        if 'semua_hasil_ekstraksi' not in locals(): semua_hasil_ekstraksi = []\n",
    "        semua_hasil_ekstraksi.append({\"nama_file\": \"DIREKTORI_TIDAK_DITEMUKAN\", \"hasil_ekstraksi\": {\"error_direktori\": f\"Direktori '{path_dokumen}' tidak ditemukan.\"}})\n",
    "    except Exception as e_listdir:\n",
    "        print(f\"Error saat mengakses direktori '{path_dokumen}': {e_listdir}\")\n",
    "        if 'semua_hasil_ekstraksi' not in locals(): semua_hasil_ekstraksi = []\n",
    "        semua_hasil_ekstraksi.append({\"nama_file\": \"AKSES_DIREKTORI_ERROR\", \"hasil_ekstraksi\": {\"error_direktori\": f\"Error mengakses '{path_dokumen}': {e_listdir}\"}})\n",
    "\n",
    "    if not files_to_process:\n",
    "        msg_no_files = f\"Tidak ada dokumen dengan ekstensi yang didukung ditemukan di {path_dokumen}\"\n",
    "        print(msg_no_files)\n",
    "        # Simpan info ini jika belum ada error direktori sebelumnya\n",
    "        if not any(d.get(\"nama_file\") in [\"KONFIGURASI_ERROR\", \"DIREKTORI_TIDAK_DITEMUKAN\", \"AKSES_DIREKTORI_ERROR\"] for d in semua_hasil_ekstraksi):\n",
    "            if 'semua_hasil_ekstraksi' not in locals(): semua_hasil_ekstraksi = []\n",
    "            semua_hasil_ekstraksi.append({\"nama_file\": \"TIDAK_ADA_FILE\", \"hasil_ekstraksi\": {\"info\": msg_no_files}})\n",
    "    else:\n",
    "        print(f\"Ditemukan {len(files_to_process)} dokumen untuk diproses: {files_to_process}\")\n",
    "\n",
    "        for nama_file_dokumen in files_to_process:\n",
    "            current_file_path = os.path.join(path_dokumen, nama_file_dokumen)\n",
    "            print(f\"\\n--- Memulai pemrosesan untuk dokumen: {nama_file_dokumen} ---\")\n",
    "            \n",
    "            teks_hasil_ekstraksi_file = \"\" # Inisialisasi untuk setiap file\n",
    "            kamus_hasil_ekstraksi_file = {} # Inisialisasi untuk setiap file\n",
    "            \n",
    "            ekstensi_file = os.path.splitext(nama_file_dokumen)[1].lower()\n",
    "            print(f\"Tipe berkas terdeteksi: {ekstensi_file} untuk {nama_file_dokumen}\")\n",
    "\n",
    "            try:\n",
    "                if ekstensi_file == '.pdf':\n",
    "                    dir_cache = direktori_cache_pdf_kustom if 'direktori_cache_pdf_kustom' in locals() and direktori_cache_pdf_kustom else None\n",
    "                    teks_hasil_ekstraksi_file = ekstrak_teks_dari_pdf(current_file_path, ekstrak_teks_dari_gambar, direktori_cache_kustom=dir_cache)\n",
    "                elif ekstensi_file in ['.jpg', '.jpeg', '.png', '.tiff', '.bmp', '.gif']:\n",
    "                    teks_hasil_ekstraksi_file = ekstrak_teks_dari_gambar(current_file_path)\n",
    "                elif ekstensi_file == '.txt':\n",
    "                    teks_hasil_ekstraksi_file = ekstrak_teks_dari_txt(current_file_path)\n",
    "                elif ekstensi_file == '.docx':\n",
    "                    teks_hasil_ekstraksi_file = ekstrak_teks_dari_docx(current_file_path)\n",
    "                # Tidak perlu klausa else karena sudah difilter oleh supported_extensions\n",
    "            \n",
    "            except Exception as e_parse:\n",
    "                error_msg_parse = f\"Error selama parsing dokumen '{nama_file_dokumen}': {str(e_parse)}\"\n",
    "                print(error_msg_parse)\n",
    "                teks_hasil_ekstraksi_file = error_msg_parse # Simpan error di sini untuk di-log\n",
    "\n",
    "            # Lanjutkan ke ekstraksi kata kunci jika parsing berhasil dan menghasilkan teks\n",
    "            if not teks_hasil_ekstraksi_file.startswith(\"Error:\") and teks_hasil_ekstraksi_file.strip():\n",
    "                print(f\"Parsing dokumen '{nama_file_dokumen}' selesai. Total karakter: {len(teks_hasil_ekstraksi_file)}\")\n",
    "                # print(f\"Cuplikan: {teks_hasil_ekstraksi_file[:200]}...\") # Opsional: cuplikan per file\n",
    "                \n",
    "                # --- Logika Ekstraksi Kata Kunci (dari sel c87d8344) dipindahkan ke sini ---\n",
    "                print(f\"Memulai ekstraksi kata kunci untuk: {nama_file_dokumen}\")\n",
    "                pengali_dokumen_file = 1.0 # Default pengali\n",
    "                print_output_pengali_file = []\n",
    "\n",
    "                try:\n",
    "                    pengali_dokumen_file = deteksi_pengali_global(teks_hasil_ekstraksi_file)\n",
    "                    print_output_pengali_file.append(f\"Pengali terdeteksi untuk '{nama_file_dokumen}': {pengali_dokumen_file}\")\n",
    "                except Exception as e_pengali:\n",
    "                    print_output_pengali_file.append(f\"Error saat deteksi pengali untuk '{nama_file_dokumen}': {str(e_pengali)}. Menggunakan default 1.0.\")\n",
    "                    pengali_dokumen_file = 1.0\n",
    "                \n",
    "                for msg in print_output_pengali_file: print(msg) # Cetak log pengali\n",
    "                    \n",
    "                if 'konfigurasi_kata_kunci_target' not in locals() or not konfigurasi_kata_kunci_target:\n",
    "                    pesan_error_konfig_loop = \"Error krusial: 'konfigurasi_kata_kunci_target' tidak terdefinisi. Periksa sel Konfigurasi.\"\n",
    "                    print(pesan_error_konfig_loop)\n",
    "                    kamus_hasil_ekstraksi_file = {\"error_konfigurasi_global\": pesan_error_konfig_loop}\n",
    "                else:\n",
    "                    try:\n",
    "                        kamus_hasil_ekstraksi_file = ekstrak_data_keuangan_tahunan(\n",
    "                            teks_hasil_ekstraksi_file, \n",
    "                            konfigurasi_kata_kunci_target, \n",
    "                            pengali_global=pengali_dokumen_file\n",
    "                        )\n",
    "                        print(f\"Ekstraksi kata kunci untuk '{nama_file_dokumen}' selesai.\")\n",
    "                        # Opsional: Tampilkan hasil per file\n",
    "                        # if kamus_hasil_ekstraksi_file:\n",
    "                        #     for k, v in kamus_hasil_ekstraksi_file.items():\n",
    "                        #         print(f\"  - {k}: {v if v is not None else 'Tidak ditemukan'}\")\n",
    "                        # else:\n",
    "                        #     print(f\"  Tidak ada kata kunci yang ditemukan atau diekstrak untuk '{nama_file_dokumen}'.\")\n",
    "                    except Exception as e_ekstraksi:\n",
    "                        pesan_error_ekstraksi_loop = f\"Error selama proses ekstraksi kata kunci untuk '{nama_file_dokumen}': {str(e_ekstraksi)}\"\n",
    "                        print(pesan_error_ekstraksi_loop)\n",
    "                        kamus_hasil_ekstraksi_file = {\"error_runtime_ekstraksi\": pesan_error_ekstraksi_loop}\n",
    "                # --- Akhir Logika Ekstraksi Kata Kunci ---\n",
    "\n",
    "            elif not teks_hasil_ekstraksi_file.strip() and not teks_hasil_ekstraksi_file.startswith(\"Error:\"):\n",
    "                info_msg = f\"Info: Teks yang diekstrak dari '{nama_file_dokumen}' kosong atau hanya spasi putih.\"\n",
    "                print(info_msg)\n",
    "                kamus_hasil_ekstraksi_file = {\"info_parsing\": info_msg} # Log info ini\n",
    "            else: # Ada error dari parsing (teks_hasil_ekstraksi_file sudah berisi pesan error)\n",
    "                # Pesan error sudah dicetak saat parsing gagal\n",
    "                kamus_hasil_ekstraksi_file = {\"error_parsing\": teks_hasil_ekstraksi_file}\n",
    "\n",
    "            # Simpan hasil untuk file ini (meskipun ada error, simpan informasinya)\n",
    "            semua_hasil_ekstraksi.append({\n",
    "                \"nama_file\": nama_file_dokumen,\n",
    "                \"hasil_ekstraksi\": kamus_hasil_ekstraksi_file\n",
    "            })\n",
    "            print(f\"--- Pemrosesan untuk dokumen: {nama_file_dokumen} selesai. Hasil disimpan. ---\")\n",
    "            \n",
    "        print(\"\\n=== Semua dokumen dalam direktori telah diproses. ===\")\n",
    "\n",
    "# Ringkasan setelah loop selesai\n",
    "if 'semua_hasil_ekstraksi' in locals() and semua_hasil_ekstraksi:\n",
    "    print(f\"Total item dalam 'semua_hasil_ekstraksi': {len(semua_hasil_ekstraksi)} (termasuk potensi pesan error global atau info tidak ada file)\")\n",
    "    for hasil_item in semua_hasil_ekstraksi:\n",
    "        status = \"Sukses\"\n",
    "        if isinstance(hasil_item['hasil_ekstraksi'], dict) and any(k.startswith('error') for k in hasil_item['hasil_ekstraksi'].keys()):\n",
    "            status = \"Error\"\n",
    "        elif not hasil_item['hasil_ekstraksi']:\n",
    "            status = \"Kosong/Tidak ada data\"\n",
    "        print(f\"  Dokumen: {hasil_item['nama_file']}, Status Ekstraksi: {status}\")\n",
    "else:\n",
    "    print(\"Tidak ada hasil ekstraksi yang tersimpan atau 'semua_hasil_ekstraksi' kosong. Periksa log di atas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa89525e73aaa7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langkah terakhir adalah memformat daftar 'semua_hasil_ekstraksi' ke dalam format JSON.\n",
    "\n",
    "output_json_agregat = \"\"\n",
    "data_untuk_json = [] # Default ke list kosong\n",
    "\n",
    "if 'semua_hasil_ekstraksi' in locals() and isinstance(semua_hasil_ekstraksi, list) and semua_hasil_ekstraksi:\n",
    "    print(f\"'semua_hasil_ekstraksi' ditemukan dengan {len(semua_hasil_ekstraksi)} item. Akan diformat ke JSON.\")\n",
    "    data_untuk_json = semua_hasil_ekstraksi\n",
    "elif 'semua_hasil_ekstraksi' in locals() and not semua_hasil_ekstraksi: # List ada tapi kosong\n",
    "    print(\"Info: 'semua_hasil_ekstraksi' adalah list kosong. Ini mungkin karena tidak ada file yang diproses atau file tidak menghasilkan output.\")\n",
    "    data_untuk_json.append({\"info\": \"Tidak ada data yang diekstrak dari dokumen manapun.\"})\n",
    "else: # Variabel tidak ada atau bukan list\n",
    "    print(\"Error: 'semua_hasil_ekstraksi' tidak ditemukan, bukan list, atau kosong. Proses ekstraksi mungkin gagal total.\")\n",
    "    data_untuk_json.append({\n",
    "        \"error_kritis\": \"Variabel 'semua_hasil_ekstraksi' tidak tersedia atau tidak valid untuk diformat ke JSON.\"\n",
    "    })\n",
    "\n",
    "# Serialisasi ke JSON menggunakan json.dumps untuk list of dicts\n",
    "try:\n",
    "    # Fungsi format_ke_json diimpor untuk single dict, json.dumps lebih cocok untuk list of dicts\n",
    "    output_json_agregat = json.dumps(data_untuk_json, indent=4, ensure_ascii=False)\n",
    "    print(\"\\n--- Output Agregat Final (JSON dari semua_hasil_ekstraksi) ---\")\n",
    "    # Batasi print output jika terlalu panjang untuk konsol\n",
    "    if len(output_json_agregat) > 2000:\n",
    "        print(output_json_agregat[:2000] + \"... (output dipotong karena terlalu panjang untuk ditampilkan di sini)\")\n",
    "    else:\n",
    "        print(output_json_agregat)\n",
    "except TypeError as te:\n",
    "    error_serialization_msg = f\"Error saat serialisasi ke JSON: {te}. Pastikan semua data dalam 'semua_hasil_ekstraksi' dapat diserialisasi.\"\n",
    "    print(error_serialization_msg)\n",
    "    # Fallback jika ada objek yang tidak serializable, coba simpan pesan error\n",
    "    try:\n",
    "        output_json_agregat = json.dumps({\"error_json_serialization\": error_serialization_msg, \"data_partial_str\": str(data_untuk_json)[:1000]}, indent=4, ensure_ascii=False)\n",
    "    except Exception as e_fallback_serialize:\n",
    "        # Jika fallback pun gagal, buat pesan error paling dasar\n",
    "        output_json_agregat = json.dumps({\"critical_error_json_serialization\": str(e_fallback_serialize)})\n",
    "    print(\"\\n--- Output Fallback Error (JSON) ---\")\n",
    "    print(output_json_agregat)\n",
    "except Exception as e_general_json:\n",
    "    error_general_json_msg = f\"Error umum saat menyiapkan JSON: {e_general_json}.\"\n",
    "    print(error_general_json_msg)\n",
    "    output_json_agregat = json.dumps({\"critical_error_json_preparation\": error_general_json_msg}, indent=4, ensure_ascii=False)\n",
    "    print(\"\\n--- Output Fallback Error Umum (JSON) ---\")\n",
    "    print(output_json_agregat)\n",
    "\n",
    "# Menyimpan output JSON agregat ke direktori \"OutputSarana\"\n",
    "nama_file_output_json_agregat = \"hasil_ekstraksi_semua_dokumen.json\"\n",
    "output_dir_agregat = \"OutputSarana\" # Nama direktori output\n",
    "\n",
    "try:\n",
    "    os.makedirs(output_dir_agregat, exist_ok=True) # Buat direktori jika belum ada\n",
    "    full_output_path_agregat = os.path.join(output_dir_agregat, nama_file_output_json_agregat)\n",
    "    \n",
    "    with open(full_output_path_agregat, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(output_json_agregat)\n",
    "    print(f\"\\nMenyimpan hasil ekstraksi agregat semua dokumen ke berkas JSON: {full_output_path_agregat}\")\n",
    "except Exception as e_write:\n",
    "    print(f\"\\nERROR KRITIS: Gagal menyimpan berkas JSON utama di '{full_output_path_agregat}': {e_write}\")\n",
    "    # Coba simpan file error darurat jika penyimpanan utama gagal\n",
    "    try:\n",
    "        error_file_path = os.path.join(output_dir_agregat, \"ERROR_hasil_ekstraksi_semua_dokumen.json\")\n",
    "        emergency_output = {\n",
    "            \"error_saving_main_file\": str(e_write),\n",
    "            \"intended_path\": full_output_path_agregat,\n",
    "            \"data_snippet_tried_to_save\": output_json_agregat[:1000] + \"... (data dipotong)\"\n",
    "        }\n",
    "        with open(error_file_path, \"w\", encoding=\"utf-8\") as f_err:\n",
    "            json.dump(emergency_output, f_err, indent=4, ensure_ascii=False)\n",
    "        print(f\"Pesan error dan potongan data disimpan ke file darurat: {error_file_path}\")\n",
    "    except Exception as e_emergency_save:\n",
    "        print(f\"Gagal menyimpan file JSON error darurat juga: {e_emergency_save}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e545e27751b20e",
   "metadata": {},
   "source": [
    "## Catatan Akhir: Efisiensi, Keterbatasan, dan Pengembangan Lanjutan\n",
    "\n",
    "Notebook ini menyediakan alur kerja yang komprehensif untuk parsing dokumen dan ekstraksi informasi keuangan dasar. Namun, ada beberapa hal yang perlu diperhatikan:\n",
    "\n",
    "*   **Efisiensi Pemrosesan**:\n",
    "    *   **PDF Besar**: Seperti yang disebutkan, PDF besar dengan banyak halaman gambar bisa lambat karena OCR. Fitur **OCR Paralel** yang diimplementasikan di `parser_pdf.py` membantu mengurangi waktu tunggu.\n",
    "    *   **Caching**: Mekanisme **caching** untuk `parser_pdf.py` (disimpan di `.cache_parser_dokumen` secara default) akan sangat membantu jika Anda sering memproses ulang dokumen yang sama, karena hasil parsing akan diambil dari cache jika file tidak berubah.\n",
    "    *   **Pra-pemrosesan Gambar**: Langkah ini penting untuk akurasi OCR, tetapi juga menambah waktu pemrosesan untuk setiap gambar/halaman gambar.\n",
    "\n",
    "*   **Akurasi Ekstraksi Kata Kunci dan Nilai**:\n",
    "    *   **Logika Tahun Terbaru**: `pengekstrak_kata_kunci.py` kini mencoba mengidentifikasi tahun pelaporan dan memprioritaskan nilai yang berasosiasi dengan tahun tersebut, serta membedakannya dari nilai tahun sebelumnya. Akurasi logika ini sangat bergantung pada konsistensi format tabel dan layout dalam dokumen. Mungkin memerlukan penyesuaian regex lebih lanjut untuk berbagai format laporan keuangan.\n",
    "    *   **Variasi Kata Kunci**: Keberhasilan ekstraksi juga bergantung pada seberapa komprehensif daftar `variasi` untuk setiap `kata_dasar` dalam `konfigurasi_kata_kunci_target`.\n",
    "    *   **Normalisasi Nilai**: Fungsi `normalisasi_nilai_keuangan` menangani format umum Indonesia, tetapi format yang sangat tidak standar mungkin memerlukan penyesuaian.\n",
    "    *   **Konteks**: Ekstraktor saat ini menggunakan konteks kalimat dan kedekatan dengan tahun. Untuk kasus yang sangat ambigu, pemahaman struktur tabel atau elemen visual mungkin diperlukan (di luar cakupan saat ini).\n",
    "\n",
    "*   **Keterbatasan Bahasa Indonesia di NLTK**:\n",
    "    *   **Stopwords**: `pengekstrak_kata_kunci.py` mencoba menggunakan stopwords Bahasa Indonesia dari NLTK. Pastikan resource ini terinstal (`nltk.download('stopwords')`).\n",
    "    *   **Lemmatization/Stemming**: `WordNetLemmatizer` NLTK tidak dioptimalkan untuk Bahasa Indonesia. Untuk hasil yang lebih baik dalam normalisasi kata, pertimbangkan untuk mengintegrasikan stemmer khusus Bahasa Indonesia seperti PySastrawi (memerlukan instalasi terpisah). Saat ini, keakuratan pencocokan lebih bergantung pada variasi eksplisit yang disediakan.\n",
    "\n",
    "*   **Pengembangan Lanjutan yang Mungkin Dilakukan**:\n",
    "    *   Integrasi stemmer Bahasa Indonesia.\n",
    "    *   Pengembangan logika yang lebih canggih untuk memahami struktur tabel dalam dokumen.\n",
    "    *   Pelatihan model Machine Learning kustom untuk klasifikasi teks atau Named Entity Recognition (NER) pada dokumen keuangan untuk identifikasi entitas dan nilai yang lebih robust.\n",
    "    *   Antarmuka pengguna grafis (GUI) atau aplikasi web di atas logika ini.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "evaluasi-akurasi-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fungsi evaluasi dan konfigurasi kata kunci berhasil diimpor.\n",
      "Mencoba memuat hasil ekstraksi dari: OutputSarana/hasil_ekstraksi_semua_dokumen.json\n",
      "Berhasil memuat 1 entri dari hasil ekstraksi.\n",
      "Memulai evaluasi dengan direktori ground truth: train_documents/ground_truth/\n",
      "\n",
      "--- Hasil Evaluasi Akurasi ---\n",
      "\n",
      "Kata Kunci: Arus kas bersih yang diperoleh dari aktivitas operasi\n",
      "  Jumlah di Ground Truth: 1\n",
      "  Jumlah Terdeteksi: N/A\n",
      "  Tingkat Deteksi: 100.00%\n",
      "  Akurasi Nilai Persis (vs GT Occurrences): 0.00%\n",
      "  Jumlah Pasangan Nilai Numerik Ditemukan: 1\n",
      "  Mean Absolute Error (MAE): 105524000000000.00\n",
      "  Mean Percentage Error (MPE): 3366.00%\n",
      "  TP (Deteksi): 1, FP (Deteksi): 0, FN (Deteksi): 0\n",
      "  Presisi (Deteksi): 100.00%\n",
      "  Recall (Deteksi): 100.00%\n",
      "  F1-score (Deteksi): 100.00%\n",
      "\n",
      "Kata Kunci: Beban pajak penghasilan\n",
      "  Jumlah di Ground Truth: 1\n",
      "  Jumlah Terdeteksi: N/A\n",
      "  Tingkat Deteksi: 100.00%\n",
      "  Akurasi Nilai Persis (vs GT Occurrences): 100.00%\n",
      "  Jumlah Pasangan Nilai Numerik Ditemukan: 1\n",
      "  Mean Absolute Error (MAE): 0.00\n",
      "  Mean Percentage Error (MPE): 0.00%\n",
      "  TP (Deteksi): 1, FP (Deteksi): 0, FN (Deteksi): 0\n",
      "  Presisi (Deteksi): 100.00%\n",
      "  Recall (Deteksi): 100.00%\n",
      "  F1-score (Deteksi): 100.00%\n",
      "\n",
      "Kata Kunci: Jumlah aset tidak lancar\n",
      "  Jumlah di Ground Truth: 1\n",
      "  Jumlah Terdeteksi: N/A\n",
      "  Tingkat Deteksi: 100.00%\n",
      "  Akurasi Nilai Persis (vs GT Occurrences): 100.00%\n",
      "  Jumlah Pasangan Nilai Numerik Ditemukan: 1\n",
      "  Mean Absolute Error (MAE): 0.00\n",
      "  Mean Percentage Error (MPE): 0.00%\n",
      "  TP (Deteksi): 1, FP (Deteksi): 0, FN (Deteksi): 0\n",
      "  Presisi (Deteksi): 100.00%\n",
      "  Recall (Deteksi): 100.00%\n",
      "  F1-score (Deteksi): 100.00%\n",
      "\n",
      "Kata Kunci: Laba sebelum pajak penghasilan\n",
      "  Jumlah di Ground Truth: 1\n",
      "  Jumlah Terdeteksi: N/A\n",
      "  Tingkat Deteksi: 100.00%\n",
      "  Akurasi Nilai Persis (vs GT Occurrences): 100.00%\n",
      "  Jumlah Pasangan Nilai Numerik Ditemukan: 1\n",
      "  Mean Absolute Error (MAE): 0.00\n",
      "  Mean Percentage Error (MPE): 0.00%\n",
      "  TP (Deteksi): 1, FP (Deteksi): 0, FN (Deteksi): 0\n",
      "  Presisi (Deteksi): 100.00%\n",
      "  Recall (Deteksi): 100.00%\n",
      "  F1-score (Deteksi): 100.00%\n",
      "\n",
      "Kata Kunci: Laba tahun berjalan\n",
      "  Jumlah di Ground Truth: 1\n",
      "  Jumlah Terdeteksi: N/A\n",
      "  Tingkat Deteksi: 100.00%\n",
      "  Akurasi Nilai Persis (vs GT Occurrences): 100.00%\n",
      "  Jumlah Pasangan Nilai Numerik Ditemukan: 1\n",
      "  Mean Absolute Error (MAE): 0.00\n",
      "  Mean Percentage Error (MPE): 0.00%\n",
      "  TP (Deteksi): 1, FP (Deteksi): 0, FN (Deteksi): 0\n",
      "  Presisi (Deteksi): 100.00%\n",
      "  Recall (Deteksi): 100.00%\n",
      "  F1-score (Deteksi): 100.00%\n",
      "\n",
      "Kata Kunci: Jumlah liabilitas dan ekuitas\n",
      "  Jumlah di Ground Truth: 1\n",
      "  Jumlah Terdeteksi: N/A\n",
      "  Tingkat Deteksi: 100.00%\n",
      "  Akurasi Nilai Persis (vs GT Occurrences): 100.00%\n",
      "  Jumlah Pasangan Nilai Numerik Ditemukan: 1\n",
      "  Mean Absolute Error (MAE): 0.00\n",
      "  Mean Percentage Error (MPE): 0.00%\n",
      "  TP (Deteksi): 1, FP (Deteksi): 0, FN (Deteksi): 0\n",
      "  Presisi (Deteksi): 100.00%\n",
      "  Recall (Deteksi): 100.00%\n",
      "  F1-score (Deteksi): 100.00%\n",
      "\n",
      "Kata Kunci: Jumlah ekuitas\n",
      "  Jumlah di Ground Truth: 1\n",
      "  Jumlah Terdeteksi: N/A\n",
      "  Tingkat Deteksi: 100.00%\n",
      "  Akurasi Nilai Persis (vs GT Occurrences): 100.00%\n",
      "  Jumlah Pasangan Nilai Numerik Ditemukan: 1\n",
      "  Mean Absolute Error (MAE): 0.00\n",
      "  Mean Percentage Error (MPE): 0.00%\n",
      "  TP (Deteksi): 1, FP (Deteksi): 0, FN (Deteksi): 0\n",
      "  Presisi (Deteksi): 100.00%\n",
      "  Recall (Deteksi): 100.00%\n",
      "  F1-score (Deteksi): 100.00%\n",
      "\n",
      "Kata Kunci: Laba bruto\n",
      "  Jumlah di Ground Truth: 1\n",
      "  Jumlah Terdeteksi: N/A\n",
      "  Tingkat Deteksi: 100.00%\n",
      "  Akurasi Nilai Persis (vs GT Occurrences): 100.00%\n",
      "  Jumlah Pasangan Nilai Numerik Ditemukan: 1\n",
      "  Mean Absolute Error (MAE): 0.00\n",
      "  Mean Percentage Error (MPE): 0.00%\n",
      "  TP (Deteksi): 1, FP (Deteksi): 0, FN (Deteksi): 0\n",
      "  Presisi (Deteksi): 100.00%\n",
      "  Recall (Deteksi): 100.00%\n",
      "  F1-score (Deteksi): 100.00%\n",
      "\n",
      "Kata Kunci: Jumlah aset lancar\n",
      "  Jumlah di Ground Truth: 1\n",
      "  Jumlah Terdeteksi: N/A\n",
      "  Tingkat Deteksi: 100.00%\n",
      "  Akurasi Nilai Persis (vs GT Occurrences): 100.00%\n",
      "  Jumlah Pasangan Nilai Numerik Ditemukan: 1\n",
      "  Mean Absolute Error (MAE): 0.00\n",
      "  Mean Percentage Error (MPE): 0.00%\n",
      "  TP (Deteksi): 1, FP (Deteksi): 0, FN (Deteksi): 0\n",
      "  Presisi (Deteksi): 100.00%\n",
      "  Recall (Deteksi): 100.00%\n",
      "  F1-score (Deteksi): 100.00%\n",
      "\n",
      "Kata Kunci: Beban pokok pendapatan\n",
      "  Jumlah di Ground Truth: 1\n",
      "  Jumlah Terdeteksi: N/A\n",
      "  Tingkat Deteksi: 100.00%\n",
      "  Akurasi Nilai Persis (vs GT Occurrences): 100.00%\n",
      "  Jumlah Pasangan Nilai Numerik Ditemukan: 1\n",
      "  Mean Absolute Error (MAE): 0.00\n",
      "  Mean Percentage Error (MPE): 0.00%\n",
      "  TP (Deteksi): 1, FP (Deteksi): 0, FN (Deteksi): 0\n",
      "  Presisi (Deteksi): 100.00%\n",
      "  Recall (Deteksi): 100.00%\n",
      "  F1-score (Deteksi): 100.00%\n",
      "\n",
      "Kata Kunci: Jumlah liabilitas jangka panjang\n",
      "  Jumlah di Ground Truth: 1\n",
      "  Jumlah Terdeteksi: N/A\n",
      "  Tingkat Deteksi: 100.00%\n",
      "  Akurasi Nilai Persis (vs GT Occurrences): 100.00%\n",
      "  Jumlah Pasangan Nilai Numerik Ditemukan: 1\n",
      "  Mean Absolute Error (MAE): 0.00\n",
      "  Mean Percentage Error (MPE): 0.00%\n",
      "  TP (Deteksi): 1, FP (Deteksi): 0, FN (Deteksi): 0\n",
      "  Presisi (Deteksi): 100.00%\n",
      "  Recall (Deteksi): 100.00%\n",
      "  F1-score (Deteksi): 100.00%\n",
      "\n",
      "Kata Kunci: Jumlah liabilitas\n",
      "  Jumlah di Ground Truth: 1\n",
      "  Jumlah Terdeteksi: N/A\n",
      "  Tingkat Deteksi: 100.00%\n",
      "  Akurasi Nilai Persis (vs GT Occurrences): 0.00%\n",
      "  Jumlah Pasangan Nilai Numerik Ditemukan: 1\n",
      "  Mean Absolute Error (MAE): 1989000000000.00\n",
      "  Mean Percentage Error (MPE): 12.21%\n",
      "  TP (Deteksi): 1, FP (Deteksi): 0, FN (Deteksi): 0\n",
      "  Presisi (Deteksi): 100.00%\n",
      "  Recall (Deteksi): 100.00%\n",
      "  F1-score (Deteksi): 100.00%\n",
      "\n",
      "Kata Kunci: Arus kas bersih yang digunakan untuk aktivitas pendanaan\n",
      "  Jumlah di Ground Truth: 1\n",
      "  Jumlah Terdeteksi: N/A\n",
      "  Tingkat Deteksi: 100.00%\n",
      "  Akurasi Nilai Persis (vs GT Occurrences): 0.00%\n",
      "  Jumlah Pasangan Nilai Numerik Ditemukan: 1\n",
      "  Mean Absolute Error (MAE): 91000000000.00\n",
      "  Mean Percentage Error (MPE): 0.44%\n",
      "  TP (Deteksi): 1, FP (Deteksi): 0, FN (Deteksi): 0\n",
      "  Presisi (Deteksi): 100.00%\n",
      "  Recall (Deteksi): 100.00%\n",
      "  F1-score (Deteksi): 100.00%\n",
      "\n",
      "Kata Kunci: Jumlah aset\n",
      "  Jumlah di Ground Truth: 1\n",
      "  Jumlah Terdeteksi: N/A\n",
      "  Tingkat Deteksi: 100.00%\n",
      "  Akurasi Nilai Persis (vs GT Occurrences): 0.00%\n",
      "  Jumlah Pasangan Nilai Numerik Ditemukan: 1\n",
      "  Mean Absolute Error (MAE): 9137700000000.00\n",
      "  Mean Percentage Error (MPE): 90.47%\n",
      "  TP (Deteksi): 1, FP (Deteksi): 0, FN (Deteksi): 0\n",
      "  Presisi (Deteksi): 100.00%\n",
      "  Recall (Deteksi): 100.00%\n",
      "  F1-score (Deteksi): 100.00%\n",
      "\n",
      "Kata Kunci: Arus kas bersih yang diperoleh dari aktivitas investasi\n",
      "  Jumlah di Ground Truth: 1\n",
      "  Jumlah Terdeteksi: N/A\n",
      "  Tingkat Deteksi: 100.00%\n",
      "  Akurasi Nilai Persis (vs GT Occurrences): 0.00%\n",
      "  Jumlah Pasangan Nilai Numerik Ditemukan: 1\n",
      "  Mean Absolute Error (MAE): 3092000000000.00\n",
      "  Mean Percentage Error (MPE): 18.38%\n",
      "  TP (Deteksi): 1, FP (Deteksi): 0, FN (Deteksi): 0\n",
      "  Presisi (Deteksi): 100.00%\n",
      "  Recall (Deteksi): 100.00%\n",
      "  F1-score (Deteksi): 100.00%\n",
      "\n",
      "Kata Kunci: Jumlah liabilitas jangka pendek\n",
      "  Jumlah di Ground Truth: 1\n",
      "  Jumlah Terdeteksi: N/A\n",
      "  Tingkat Deteksi: 100.00%\n",
      "  Akurasi Nilai Persis (vs GT Occurrences): 0.00%\n",
      "  Jumlah Pasangan Nilai Numerik Ditemukan: 1\n",
      "  Mean Absolute Error (MAE): 12870000000000.00\n",
      "  Mean Percentage Error (MPE): 900.00%\n",
      "  TP (Deteksi): 1, FP (Deteksi): 0, FN (Deteksi): 0\n",
      "  Presisi (Deteksi): 100.00%\n",
      "  Recall (Deteksi): 100.00%\n",
      "  F1-score (Deteksi): 100.00%\n",
      "\n",
      "Kata Kunci: Pendapatan bersih\n",
      "  Jumlah di Ground Truth: 1\n",
      "  Jumlah Terdeteksi: N/A\n",
      "  Tingkat Deteksi: 100.00%\n",
      "  Akurasi Nilai Persis (vs GT Occurrences): 100.00%\n",
      "  Jumlah Pasangan Nilai Numerik Ditemukan: 1\n",
      "  Mean Absolute Error (MAE): 0.00\n",
      "  Mean Percentage Error (MPE): 0.00%\n",
      "  TP (Deteksi): 1, FP (Deteksi): 0, FN (Deteksi): 0\n",
      "  Presisi (Deteksi): 100.00%\n",
      "  Recall (Deteksi): 100.00%\n",
      "  F1-score (Deteksi): 100.00%\n"
     ]
    }
   ],
   "source": [
    "# --- Sel Evaluasi Akurasi ---\n",
    "import os # Diperlukan jika belum diimpor di atas atau jika kernel di-restart\n",
    "import json # Diperlukan jika belum diimpor di atas atau jika kernel di-restart\n",
    "try:\n",
    "    from SaranaModule.evaluasi_akurasi import load_json_data, compare_results, assign_heuristic_scores, prepare_roc_data\n",
    "    from SaranaModule.pengekstrak_kata_kunci import DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT\n",
    "    print(\"Fungsi evaluasi dan konfigurasi kata kunci berhasil diimpor.\")\n",
    "except ImportError as e_import:\n",
    "    print(f\"Gagal mengimpor modul evaluasi atau konfigurasi: {e_import}. Pastikan file .py terkait ada dan benar.\")\n",
    "    # Definisikan fungsi dummy jika impor gagal\n",
    "    def load_json_data(path): print(\"load_json_data tidak terdefinisi karena error impor.\"); return None\n",
    "    def compare_results(data, path): print(\"compare_results tidak terdefinisi karena error impor.\"); return {}\n",
    "    def assign_heuristic_scores(item, kw_config): print(\"assign_heuristic_scores tidak terdefinisi karena error impor.\"); return []\n",
    "    def prepare_roc_data(items, gt_dir): print(\"prepare_roc_data tidak terdefinisi karena error impor.\"); return {'roc_points': [], 'auc': 0.0}\n",
    "    DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT = [] # Dummy\n",
    "\n",
    "path_hasil_ekstraksi = \"OutputSarana/hasil_ekstraksi_semua_dokumen.json\"\n",
    "direktori_ground_truth = \"train_documents/ground_truth/\"\n",
    "\n",
    "print(f\"Mencoba memuat hasil ekstraksi dari: {path_hasil_ekstraksi}\")\n",
    "data_ekstraksi_semua = load_json_data(path_hasil_ekstraksi)\n",
    "\n",
    "if data_ekstraksi_semua is not None:\n",
    "    print(f\"Berhasil memuat {len(data_ekstraksi_semua) if isinstance(data_ekstraksi_semua, list) else 0} entri dari hasil ekstraksi.\")\n",
    "    # Pastikan data_ekstraksi_semua adalah list, sesuai output notebook\n",
    "    if not isinstance(data_ekstraksi_semua, list):\n",
    "        print(f\"Peringatan: data_ekstraksi_semua dari {path_hasil_ekstraksi} bukan merupakan list, melainkan {type(data_ekstraksi_semua)}. Fungsi compare_results mungkin tidak berjalan dengan benar.\")\n",
    "        # Jika ini adalah dict tunggal karena hanya satu file diproses dan JSON-nya adalah dict, bungkus dalam list\n",
    "        # Namun, berdasarkan modifikasi notebook, ini seharusnya selalu list.\n",
    "        # Jika ada error seperti KONFIGURASI_ERROR, data_ekstraksi_semua bisa jadi list berisi satu dict error.\n",
    "        if isinstance(data_ekstraksi_semua, dict) and \"nama_file\" not in data_ekstraksi_semua:\n",
    "             print(\"   Format tidak terduga, tidak terlihat seperti list hasil ekstraksi. Evaluasi mungkin tidak akurat.\")\n",
    "\n",
    "    print(f\"Memulai evaluasi dengan direktori ground truth: {direktori_ground_truth}\")\n",
    "    hasil_evaluasi = compare_results(data_ekstraksi_semua, direktori_ground_truth)\n",
    "    \n",
    "    print(\"\\n--- Hasil Evaluasi Akurasi ---\")\n",
    "    if hasil_evaluasi:\n",
    "        for keyword, metrics in hasil_evaluasi.items():\n",
    "            print(f\"\\nKata Kunci: {keyword}\")\n",
    "            print(f\"  Jumlah di Ground Truth: {metrics.get('gt_occurrences', 'N/A')}\")\n",
    "            print(f\"  Jumlah Terdeteksi: {metrics.get('detected_occurrences', 'N/A')}\")\n",
    "            detection_rate = metrics.get('detection_rate', 'N/A')\n",
    "            if isinstance(detection_rate, float):\n",
    "                print(f\"  Tingkat Deteksi: {detection_rate:.2f}%\")\n",
    "            else:\n",
    "                print(f\"  Tingkat Deteksi: {detection_rate}\")\n",
    "            \n",
    "            exact_match_accuracy = metrics.get('exact_value_match_accuracy', 'N/A')\n",
    "            if isinstance(exact_match_accuracy, float):\n",
    "                print(f\"  Akurasi Nilai Persis (vs GT Occurrences): {exact_match_accuracy:.2f}%\")\n",
    "            else:\n",
    "                print(f\"  Akurasi Nilai Persis (vs GT Occurrences): {exact_match_accuracy}\")\n",
    "            print(f\"  Jumlah Pasangan Nilai Numerik Ditemukan: {metrics.get('numeric_pairs_found', 'N/A')}\")\n",
    "\n",
    "            mae = metrics.get('mean_absolute_error', 'N/A')\n",
    "            if isinstance(mae, float):\n",
    "                print(f\"  Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "            else:\n",
    "                print(f\"  Mean Absolute Error (MAE): {mae}\")\n",
    "            \n",
    "            mpe = metrics.get('mean_percentage_error', 'N/A')\n",
    "            if isinstance(mpe, float):\n",
    "                print(f\"  Mean Percentage Error (MPE): {mpe:.2f}%\")\n",
    "            else:\n",
    "                print(f\"  Mean Percentage Error (MPE): {mpe}\")\n",
    "            \n",
    "            print(f\"  TP (Deteksi): {metrics.get('tp', 'N/A')}, FP (Deteksi): {metrics.get('fp', 'N/A')}, FN (Deteksi): {metrics.get('fn', 'N/A')}\")\n",
    "            precision = metrics.get('precision', 'N/A')\n",
    "            if isinstance(precision, float):\n",
    "                print(f\"  Presisi (Deteksi): {precision:.2f}%\")\n",
    "            else:\n",
    "                print(f\"  Presisi (Deteksi): {precision}\")\n",
    "\n",
    "            recall = metrics.get('recall', 'N/A')\n",
    "            if isinstance(recall, float):\n",
    "                print(f\"  Recall (Deteksi): {recall:.2f}%\")\n",
    "            else:\n",
    "                print(f\"  Recall (Deteksi): {recall}\")\n",
    "\n",
    "            f1_score = metrics.get('f1_score', 'N/A')\n",
    "            if isinstance(f1_score, float):\n",
    "                print(f\"  F1-score (Deteksi): {f1_score:.2f}%\")\n",
    "            else:\n",
    "                print(f\"  F1-score (Deteksi): {f1_score}\")\n",
    "    else:\n",
    "        print(\"Tidak ada hasil evaluasi (metrik) yang dihasilkan. Periksa log compare_results di atas.\")\n",
    "\n",
    "else:\n",
    "    print(f\"Gagal memuat hasil ekstraksi dari '{path_hasil_ekstraksi}'. Evaluasi tidak dapat dilanjutkan.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
