{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae6e51f2",
   "metadata": {},
   "source": [
    "# Parser Teks Dokumen dan Pengekstrak Kata Kunci Keuangan (Tahunan)\n",
    "\n",
    "Notebook ini bertujuan untuk mem-parsing teks dari berbagai jenis dokumen (gambar, TXT, DOCX, PDF) dan kemudian mengekstrak istilah-istilah keuangan spesifik beserta nilainya, dengan fokus pada **data tahun pelaporan terbaru**. Proses ini melibatkan beberapa teknologi dan fitur utama:\n",
    "- **OCR (Optical Character Recognition)**: Untuk mengekstrak teks dari gambar dan PDF berbasis gambar.\n",
    "- **Pra-pemrosesan Gambar**: Sebelum OCR, gambar diproses melalui beberapa tahap (konversi ke skala abu, penghilangan derau, binerisasi, dan percobaan pelurusan kemiringan) untuk meningkatkan kualitas OCR.\n",
    "- **Pemrosesan Paralel untuk PDF**: Halaman PDF yang memerlukan OCR diproses secara paralel untuk mempercepat ekstraksi.\n",
    "- **Mekanisme Caching**: Hasil parsing PDF disimpan dalam cache untuk menghindari pemrosesan ulang file yang sama jika tidak ada perubahan.\n",
    "- **Ekstraksi Kata Kunci Bertarget**: Mencari istilah keuangan yang telah ditentukan (dalam Bahasa Indonesia) dan mencoba mengidentifikasi nilai numerik yang berasosiasi dengan tahun pelaporan terbaru yang terdeteksi dalam dokumen.\n",
    "- **Normalisasi Nilai**: Nilai keuangan yang diekstrak dinormalisasi ke format float.\n",
    "- **Output JSON**: Hasil akhir ekstraksi kata kunci dan nilainya disajikan dalam format JSON.\n",
    "\n",
    "Pastikan semua skrip Python pendukung (`parser_gambar.py`, `parser_dokumen_teks.py`, `parser_pdf.py`, `pengekstrak_kata_kunci.py`, `utilitas_cache.py`) berada di direktori yang sama dengan notebook ini atau terinstal dalam lingkungan Python Anda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cbffd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:21:28.175687Z",
     "start_time": "2025-06-04T16:20:54.483798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berhasil memuat stopwords Bahasa Indonesia.\n",
      "WordNetLemmatizer berhasil diinisialisasi.\n",
      "Tokenizer 'punkt' tampaknya tersedia.\n",
      "Modul-modul kustom berhasil diimpor.\n",
      "Resource NLTK (wordnet) sudah ada.\n",
      "\n",
      "Pengaturan Selesai. Anda dapat melanjutkan ke sel Konfigurasi.\n"
     ]
    }
   ],
   "source": [
    "# Langkah Pengaturan Awal\n",
    "\n",
    "# 1. Impor Pustaka dan Modul Kustom\n",
    "# Pastikan semua skrip Python (.py) yang disebutkan di bawah ini\n",
    "# berada di direktori yang sama dengan notebook ini.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "\n",
    "# Impor fungsi-fungsi dari modul-modul utilitas kita\n",
    "try:\n",
    "    from SaranaModule.parser_gambar import ekstrak_teks_dari_gambar\n",
    "    from SaranaModule.parser_dokumen_teks import ekstrak_teks_dari_txt, ekstrak_teks_dari_docx\n",
    "    from SaranaModule.parser_pdf import ekstrak_teks_dari_pdf # Fungsi ini menggunakan ekstrak_teks_dari_gambar untuk OCR\n",
    "    from SaranaModule.pengekstrak_kata_kunci import (\n",
    "        DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT, # Daftar kata kunci default\n",
    "        identifikasi_tahun_pelaporan,       # Untuk menemukan tahun dalam dokumen\n",
    "        ekstrak_data_keuangan_tahunan,      # Fungsi ekstraksi utama yang baru\n",
    "        format_ke_json,                     # Untuk output JSON\n",
    "        normalisasi_nilai_keuangan,          # Untuk membersihkan nilai angka (jika ingin diuji terpisah)\n",
    "        deteksi_pengali_global              # Untuk mendeteksi pengali global seperti 'juta', 'miliar', dll.\n",
    "    )\n",
    "    from SaranaModule.utilitas_cache import bersihkan_cache_lama # Opsional, untuk manajemen cache\n",
    "    print(\"Modul-modul kustom berhasil diimpor.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error mengimpor modul kustom: {e}\")\n",
    "    print(\"Pastikan semua file .py (parser_gambar, parser_dokumen_teks, parser_pdf, pengekstrak_kata_kunci, utilitas_cache) berada di direktori yang sama.\")\n",
    "\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet.zip')\n",
    "    print(\"Resource NLTK (wordnet) sudah ada.\")\n",
    "except LookupError:\n",
    "    import ssl\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    print(\"Resource NLTK (wordnet) tidak ditemukan, mengunduh...\")\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('punkt_tab')\n",
    "    nltk.download('omw-1.4') # wordnet multilingual\n",
    "    nltk.download('punkt')   # untuk tokenisasi\n",
    "    nltk.download('stopwords') # untuk stopwords\n",
    "    print(\"Resource NLTK (wordnet) sudah terunduh.\")\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"Error terkait NLTK: {e}\")\n",
    "\n",
    "print(\"\\nPengaturan Selesai. Anda dapat melanjutkan ke sel Konfigurasi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46b6aed",
   "metadata": {},
   "source": [
    "## Penjelasan Fitur Utama\n",
    "\n",
    "Sebelum melanjutkan ke konfigurasi, berikut adalah ringkasan singkat tentang beberapa fitur utama yang digunakan dalam notebook ini:\n",
    "\n",
    "*   **Pra-pemrosesan Gambar untuk OCR**: Jika dokumen Anda adalah gambar atau PDF yang berisi halaman gambar, kualitas OCR sangat penting. Modul `parser_gambar.py` kini menyertakan langkah-langkah seperti konversi ke skala abu, penghilangan derau (noise), dan binerisasi (mengubah gambar menjadi hitam-putih) untuk meningkatkan akurasi Tesseract OCR. Implementasi dasar untuk pelurusan kemiringan (deskewing) juga ada, meskipun mungkin memerlukan penyesuaian lebih lanjut untuk kasus yang kompleks.\n",
    "*   **Pemrosesan Paralel untuk PDF**: Untuk mempercepat ekstraksi teks dari PDF yang memiliki banyak halaman berbasis gambar (yang memerlukan OCR), `parser_pdf.py` menggunakan `ThreadPoolExecutor`. Ini memungkinkan beberapa halaman diproses secara bersamaan, mengurangi waktu tunggu total.\n",
    "*   **Caching Hasil Parsing**: Untuk menghindari pemrosesan ulang file PDF yang sama berulang kali (yang bisa memakan waktu), `parser_pdf.py` kini terintegrasi dengan mekanisme caching (`utilitas_cache.py`). Hasil ekstraksi teks dari sebuah PDF akan disimpan dalam cache (default di direktori `.cache_parser_dokumen`). Jika Anda memproses PDF yang sama lagi dan file tersebut tidak berubah (berdasarkan path dan timestamp modifikasi terakhir), hasilnya akan diambil dari cache, yang jauh lebih cepat. Anda bisa membersihkan cache ini secara manual atau menggunakan fungsi `bersihkan_cache_lama` (jika ingin diimplementasikan lebih lanjut).\n",
    "*   **Logika Ekstraksi Nilai Berbasis Tahun**: Fungsi `ekstrak_data_keuangan_tahunan` dalam `pengekstrak_kata_kunci.py` dirancang untuk pertama-tama mengidentifikasi tahun pelaporan utama dalam dokumen. Kemudian, saat mencari nilai untuk kata kunci keuangan, ia akan mencoba memprioritaskan angka yang berasosiasi dengan tahun pelaporan tersebut dan membedakannya dari angka untuk tahun sebelumnya, jika keduanya muncul berdekatan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e509a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:24:29.942942Z",
     "start_time": "2025-06-04T16:24:29.937024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konfigurasi dimuat. Dokumen yang akan diproses: train_documents\n",
      "Kata kunci yang akan dicari: ['Jumlah aset lancar', 'Jumlah aset tidak lancar', 'Jumlah aset', 'Jumlah liabilitas jangka pendek', 'Jumlah liabilitas jangka panjang', 'Jumlah liabilitas', 'Jumlah ekuitas', 'Pendapatan bersih', 'Beban pokok pendapatan', 'Laba bruto', 'Laba sebelum pajak penghasilan', 'Laba tahun berjalan', 'Beban penjualan', 'Beban umum dan administrasi', 'Penghasilan bunga', 'Biaya keuangan', 'Keuntungan selisih kurs, bersih', 'Penghasilan dividen', 'Penghasilan lain-lain, bersih', 'Beban pajak penghasilan']\n",
      "Direktori cache PDF kustom diatur ke: .cache_parsing_dokumen\n"
     ]
    }
   ],
   "source": [
    "# --- Konfigurasi Pengguna ---\n",
    "\n",
    "# 1. Tentukan path ke dokumen Anda\n",
    "# PENTING: Ganti nilai variabel `path_dokumen` di bawah ini dengan path aktual ke dokumen yang ingin Anda proses.\n",
    "# Contoh untuk Linux/macOS: path_dokumen = \"/home/pengguna/dokumen/laporan_keuangan_2023.pdf\"\n",
    "# Contoh untuk Windows: path_dokumen = r\"C:\\Users\\Pengguna\\Documents\\LaporanKeuangan2023.docx\"\n",
    "path_dokumen = \"train_documents/astra_lapkeu.pdf\"  # <--- !!! GANTI INI DENGAN PATH FILE ANDA !!!\n",
    "\n",
    "# 2. Definisikan atau Modifikasi Kata Kunci yang Akan Diekstrak\n",
    "# `konfigurasi_kata_kunci_target` adalah list kamus (dictionary).\n",
    "# Setiap kamus harus memiliki:\n",
    "#    - 'kata_dasar': Nama kanonis untuk kata kunci tersebut (misalnya, \"Laba Bersih\"). Ini akan menjadi kunci dalam output JSON.\n",
    "#    - 'variasi': List berisi berbagai cara penulisan atau sinonim kata kunci tersebut yang mungkin muncul di dokumen.\n",
    "#\n",
    "# Anda bisa menggunakan daftar default yang diimpor (`DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT`)\n",
    "# atau membuat/memodifikasi daftar Anda sendiri di bawah ini.\n",
    "#\n",
    "# Untuk menggunakan daftar default:\n",
    "from SaranaModule.pengekstrak_kata_kunci import DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT\n",
    "konfigurasi_kata_kunci_target = DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT\n",
    "\n",
    "# 3. (Opsional) Konfigurasi Direktori Cache untuk PDF Parser\n",
    "# Jika Anda ingin parser PDF menggunakan direktori cache selain default (`.cache_parser_dokumen`),\n",
    "# Anda bisa menentukan path-nya di sini. Jika tidak, biarkan `None` untuk menggunakan default.\n",
    "direktori_cache_pdf_kustom = \".cache_parsing_dokumen\"\n",
    "\n",
    "# --- Akhir Konfigurasi Pengguna ---\n",
    "\n",
    "# Validasi awal konfigurasi\n",
    "if 'path_dokumen' not in locals() or path_dokumen == \"MASUKKAN_PATH_DOKUMEN_ANDA_DI_SINI.pdf\":\n",
    "    print(\"PERINGATAN: 'path_dokumen' belum diatur atau masih menggunakan nilai placeholder.\")\n",
    "    print(\"Mohon perbarui variabel 'path_dokumen' di atas dengan path ke berkas yang ingin Anda proses.\")\n",
    "elif not os.path.exists(path_dokumen):\n",
    "    print(f\"ERROR: Dokumen tidak ditemukan pada path yang ditentukan: {path_dokumen}\")\n",
    "    print(\"Mohon periksa kembali 'path_dokumen' dan pastikan berkas tersebut ada.\")\n",
    "else:\n",
    "    print(f\"Konfigurasi dimuat. Dokumen yang akan diproses: {path_dokumen}\")\n",
    "    print(f\"Kata kunci yang akan dicari: {[item['kata_dasar'] for item in konfigurasi_kata_kunci_target]}\")\n",
    "    if direktori_cache_pdf_kustom:\n",
    "        print(f\"Direktori cache PDF kustom diatur ke: {direktori_cache_pdf_kustom}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad4464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:24:34.363713Z",
     "start_time": "2025-06-04T16:24:34.357065Z"
    }
   },
   "outputs": [],
   "source": [
    "# Langkah ini akan mengekstrak seluruh teks dari dokumen yang telah Anda tentukan.\n",
    "# Proses ini mungkin memakan waktu, terutama untuk PDF besar atau gambar yang memerlukan OCR.\n",
    "\n",
    "teks_hasil_ekstraksi = \"\"\n",
    "\n",
    "# Pastikan path_dokumen telah dikonfigurasi dengan benar sebelum melanjutkan\n",
    "if 'path_dokumen' not in locals() or path_dokumen == \"MASUKKAN_PATH_DOKUMEN_ANDA_DI_SINI.pdf\" or not os.path.exists(path_dokumen):\n",
    "    if 'path_dokumen' in locals() and path_dokumen == \"MASUKKAN_PATH_DOKUMEN_ANDA_DI_SINI.pdf\":\n",
    "        pesan_error_parsing = \"Error: 'path_dokumen' masih menggunakan nilai placeholder. Silakan perbarui di sel Konfigurasi.\"\n",
    "    elif 'path_dokumen' not in locals():\n",
    "         pesan_error_parsing = \"Error: 'path_dokumen' tidak terdefinisi. Silakan definisikan di sel Konfigurasi.\"\n",
    "    else: # Berkas tidak ada\n",
    "        pesan_error_parsing = f\"Error: Dokumen tidak ditemukan pada path '{path_dokumen}'. Mohon verifikasi path di sel Konfigurasi.\"\n",
    "    print(pesan_error_parsing)\n",
    "    teks_hasil_ekstraksi = pesan_error_parsing # Simpan pesan error untuk sel berikutnya\n",
    "else:\n",
    "    print(f\"Memulai parsing untuk dokumen: {path_dokumen}...\")\n",
    "    nama_file = os.path.basename(path_dokumen)\n",
    "    ekstensi_file = os.path.splitext(nama_file)[1].lower()\n",
    "    print(f\"Tipe berkas terdeteksi: {ekstensi_file}\")\n",
    "    \n",
    "    try:\n",
    "        if ekstensi_file == '.pdf':\n",
    "            # Menggunakan fungsi ekstrak_teks_dari_gambar untuk OCR, dan direktori cache jika ada\n",
    "            # Pastikan variabel 'direktori_cache_pdf_kustom' ada dari sel konfigurasi\n",
    "            dir_cache = direktori_cache_pdf_kustom if 'direktori_cache_pdf_kustom' in locals() else None\n",
    "            teks_hasil_ekstraksi = ekstrak_teks_dari_pdf(path_dokumen, ekstrak_teks_dari_gambar, direktori_cache_kustom=dir_cache)\n",
    "        elif ekstensi_file in ['.jpg', '.jpeg', '.png', '.tiff', '.bmp', '.gif']:\n",
    "            teks_hasil_ekstraksi = ekstrak_teks_dari_gambar(path_dokumen)\n",
    "        elif ekstensi_file == '.txt':\n",
    "            teks_hasil_ekstraksi = ekstrak_teks_dari_txt(path_dokumen)\n",
    "        elif ekstensi_file == '.docx':\n",
    "            teks_hasil_ekstraksi = ekstrak_teks_dari_docx(path_dokumen)\n",
    "        else:\n",
    "            teks_hasil_ekstraksi = (f\"Error: Tipe berkas tidak didukung: {ekstensi_file}. \"\n",
    "                                   f\"Tipe yang didukung: PDF, JPG, JPEG, PNG, TIFF, BMP, GIF, TXT, DOCX.\")\n",
    "    except Exception as e:\n",
    "        teks_hasil_ekstraksi = f\"Error selama parsing dokumen '{nama_file}': {str(e)}\"\n",
    "\n",
    "# Tampilkan status dan cuplikan hasil ekstraksi\n",
    "if \"Error:\" not in teks_hasil_ekstraksi:\n",
    "    print(f\"Parsing dokumen '{nama_file}' selesai.\")\n",
    "    print(f\"Total karakter yang diekstrak: {len(teks_hasil_ekstraksi)}\")\n",
    "    print(\"\\n--- Cuplikan Teks Hasil Ekstraksi (500 karakter pertama) ---\")\n",
    "    print(teks_hasil_ekstraksi[:1000000] + \"...\" if len(teks_hasil_ekstraksi) > 500 else teks_hasil_ekstraksi)\n",
    "    print(\"--- Akhir Cuplikan ---\")\n",
    "else:\n",
    "    # Pesan error sudah dicetak di atas jika path_dokumen tidak valid\n",
    "    # Cetak pesan error jika berasal dari proses parsing itu sendiri\n",
    "    if not ('path_dokumen' in locals() and path_dokumen == \"MASUKKAN_PATH_DOKUMEN_ANDA_DI_SINI.pdf\") and        not ('path_dokumen' in locals() and not os.path.exists(path_dokumen)):\n",
    "        print(teks_hasil_ekstraksi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d8344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pengali dokumen yang terdeteksi: 1000000000.0\n",
      "\n",
      "Memulai proses ekstraksi kata kunci dan nilai tahunan...\n",
      "\n",
      "--- Kata Kunci dan Nilai Hasil Ekstraksi (Kamus Python) ---\n",
      "- Jumlah aset lancar: 19238000000.0\n",
      "- Jumlah aset tidak lancar: 81765000000.0\n",
      "- Jumlah aset: 19238000000.0\n",
      "- Jumlah liabilitas jangka pendek: 14300000000.0\n",
      "- Jumlah liabilitas jangka panjang: 1989000000.0\n",
      "- Jumlah liabilitas: 14300000000.0\n",
      "- Jumlah ekuitas: 84714000000.0\n",
      "- Pendapatan bersih: 108249000000.0\n",
      "- Beban pokok pendapatan: -97738000000.0\n",
      "- Laba bruto: 10511000000.0\n",
      "- Laba sebelum pajak penghasilan: 22136000000.0\n",
      "- Laba tahun berjalan: 21661000000.0\n",
      "- Beban penjualan: -5298000000.0\n",
      "- Beban umum dan administrasi: -4701000000.0\n",
      "- Penghasilan bunga: 322000000000.0\n",
      "- Biaya keuangan: -119000000000.0\n",
      "- Keuntungan selisih kurs, bersih: 1000000000.0\n",
      "- Penghasilan dividen: 19918000000.0\n",
      "- Penghasilan lain-lain, bersih: 1502000000.0\n",
      "- Beban pajak penghasilan: -475000000000.0\n"
     ]
    }
   ],
   "source": [
    "pengali_dokumen = 1.0\n",
    "print_output_pengali = []\n",
    "\n",
    "if 'teks_hasil_ekstraksi' in locals() and isinstance(teks_hasil_ekstraksi, str) and not \"Error:\" in teks_hasil_ekstraksi:\n",
    "    pengali_dokumen = deteksi_pengali_global(teks_hasil_ekstraksi)\n",
    "    print_output_pengali.append(f\"Pengali dokumen yang terdeteksi: {pengali_dokumen}\")\n",
    "elif 'teks_hasil_ekstraksi' in locals() and isinstance(teks_hasil_ekstraksi, str) and \"Error:\" in teks_hasil_ekstraksi:\n",
    "    error_msg_summary = teks_hasil_ekstraksi[:200].replace('\"', '\\\"').replace('\\\\', '\\\\\\\\')\n",
    "    print_output_pengali.append(f\"Tidak menjalankan deteksi pengali global karena ada error pada ekstraksi teks: {error_msg_summary}\")\n",
    "else:\n",
    "    print_output_pengali.append(\"Tidak menjalankan deteksi pengali global karena 'teks_hasil_ekstraksi' tidak valid atau tidak ditemukan.\")\n",
    "\n",
    "# Pastikan variabel ini ada, meskipun terjadi error di atas, untuk sel berikutnya\n",
    "if 'pengali_dokumen' not in locals():\n",
    "    pengali_dokumen = 1.0\n",
    "    print_output_pengali.append(\"Variabel 'pengali_dokumen' diinisialisasi ke default (1.0) karena tidak terdefinisi sebelumnya.\")\n",
    "\n",
    "# Print semua pesan terkait deteksi pengali\n",
    "for msg in print_output_pengali:\n",
    "    print(msg)\n",
    "\n",
    "# Langkah Ekstraksi Kata Kunci\n",
    "kamus_hasil_ekstraksi = {}\n",
    "\n",
    "if 'teks_hasil_ekstraksi' not in locals() or not teks_hasil_ekstraksi:\n",
    "    print(\"Error: Variabel 'teks_hasil_ekstraksi' tidak ditemukan atau kosong. Sel parsing dokumen mungkin belum dijalankan atau gagal.\")\n",
    "    kamus_hasil_ekstraksi = {\"error_pra_ekstraksi\": \"Variabel teks_hasil_ekstraksi tidak ada atau kosong.\"}\n",
    "elif \"Error:\" in teks_hasil_ekstraksi: # Jika ada pesan error dari langkah parsing\n",
    "    print(\"\\nMelewati ekstraksi kata kunci karena terjadi error pada langkah parsing dokumen.\")\n",
    "    print(f\"Detail Error Parsing: {teks_hasil_ekstraksi}\")\n",
    "    kamus_hasil_ekstraksi = {\"error_parsing_sebelumnya\": teks_hasil_ekstraksi}\n",
    "elif not teks_hasil_ekstraksi.strip():\n",
    "    print(\"\\nTeks yang diekstrak kosong atau hanya berisi spasi putih. Tidak ada kata kunci untuk dicari.\")\n",
    "    kamus_hasil_ekstraksi = {\"info\": \"Teks yang diekstrak kosong.\"}\n",
    "else:\n",
    "    try:\n",
    "        # Pastikan konfigurasi_kata_kunci_target terdefinisi dari sel Konfigurasi\n",
    "        if 'konfigurasi_kata_kunci_target' not in locals() or not konfigurasi_kata_kunci_target:\n",
    "            pesan_error_konfig = \"Error: 'konfigurasi_kata_kunci_target' tidak terdefinisi atau kosong. Mohon periksa sel Konfigurasi.\"\n",
    "            print(pesan_error_konfig)\n",
    "            kamus_hasil_ekstraksi = {\"error_konfigurasi\": pesan_error_konfig}\n",
    "        else:\n",
    "            print(\"\\nMemulai proses ekstraksi kata kunci dan nilai tahunan...\")\n",
    "            # Menggunakan fungsi ekstraksi data keuangan tahunan yang baru\n",
    "            kamus_hasil_ekstraksi = ekstrak_data_keuangan_tahunan(teks_hasil_ekstraksi, konfigurasi_kata_kunci_target, pengali_global=pengali_dokumen)\n",
    "            \n",
    "            print(\"\\n--- Kata Kunci dan Nilai Hasil Ekstraksi (Kamus Python) ---\")\n",
    "            if \"error\" not in kamus_hasil_ekstraksi and \"error_konfigurasi\" not in kamus_hasil_ekstraksi:\n",
    "                if kamus_hasil_ekstraksi:\n",
    "                    for kunci, nilai in kamus_hasil_ekstraksi.items():\n",
    "                        print(f\"- {kunci}: {nilai if nilai is not None else 'Tidak ditemukan'}\")\n",
    "                else:\n",
    "                    print(\"Tidak ada kata kunci yang berhasil diekstrak atau dikonfigurasi.\")\n",
    "            else: # Cetak error jika ada dari proses ekstraksi itu sendiri\n",
    "                 print(f\"Error atau masalah dalam hasil ekstraksi: {kamus_hasil_ekstraksi}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        pesan_error_ekstraksi = f\"Error selama proses ekstraksi kata kunci: {str(e)}\"\n",
    "        print(pesan_error_ekstraksi)\n",
    "        kamus_hasil_ekstraksi = {\"error_runtime_ekstraksi\": pesan_error_ekstraksi}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa89525e73aaa7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Output Final (JSON) ---\n",
      "{\n",
      "    \"Jumlah aset lancar\": 19238000000.0,\n",
      "    \"Jumlah aset tidak lancar\": 81765000000.0,\n",
      "    \"Jumlah aset\": 19238000000.0,\n",
      "    \"Jumlah liabilitas jangka pendek\": 14300000000.0,\n",
      "    \"Jumlah liabilitas jangka panjang\": 1989000000.0,\n",
      "    \"Jumlah liabilitas\": 14300000000.0,\n",
      "    \"Jumlah ekuitas\": 84714000000.0,\n",
      "    \"Pendapatan bersih\": 108249000000.0,\n",
      "    \"Beban pokok pendapatan\": -97738000000.0,\n",
      "    \"Laba bruto\": 10511000000.0,\n",
      "    \"Laba sebelum pajak penghasilan\": 22136000000.0,\n",
      "    \"Laba tahun berjalan\": 21661000000.0,\n",
      "    \"Beban penjualan\": -5298000000.0,\n",
      "    \"Beban umum dan administrasi\": -4701000000.0,\n",
      "    \"Penghasilan bunga\": 322000000000.0,\n",
      "    \"Biaya keuangan\": -119000000000.0,\n",
      "    \"Keuntungan selisih kurs, bersih\": 1000000000.0,\n",
      "    \"Penghasilan dividen\": 19918000000.0,\n",
      "    \"Penghasilan lain-lain, bersih\": 1502000000.0,\n",
      "    \"Beban pajak penghasilan\": -475000000000.0\n",
      "}\n",
      "\n",
      "Menyimpan hasil ekstraksi ke berkas JSON: OutputSarana/hasil_ekstraksi_train_documents.json\n"
     ]
    }
   ],
   "source": [
    "# Langkah terakhir adalah memformat kamus hasil ekstraksi ke dalam format JSON\n",
    "# untuk kemudahan pembacaan atau integrasi lebih lanjut.\n",
    "\n",
    "output_json_final = \"\"\n",
    "if 'kamus_hasil_ekstraksi' not in locals() or not kamus_hasil_ekstraksi:\n",
    "    print(\"Error: 'kamus_hasil_ekstraksi' tidak ditemukan atau kosong. Ekstraksi kata kunci mungkin gagal, dilewati, atau tidak menghasilkan apa-apa.\")\n",
    "    kamus_hasil_ekstraksi_untuk_json = {\"error_kritis\": \"kamus_hasil_ekstraksi tidak tersedia untuk format JSON.\"}\n",
    "    if 'kamus_hasil_ekstraksi' in locals() and not kamus_hasil_ekstraksi:\n",
    "        kamus_hasil_ekstraksi_untuk_json = {\"info\": \"Tidak ada data yang diekstrak untuk diformat ke JSON.\"}\n",
    "else:\n",
    "    kamus_hasil_ekstraksi_untuk_json = kamus_hasil_ekstraksi\n",
    "\n",
    "output_json_final = format_ke_json(kamus_hasil_ekstraksi_untuk_json)\n",
    "print(\"\\n--- Output Final (JSON) ---\")\n",
    "print(output_json_final)\n",
    "\n",
    "# Menyimpan output JSON ke direktori \"output_json\"\n",
    "nama_file_output_json = \"hasil_ekstraksi_data.json\"\n",
    "if 'path_dokumen' in locals() and path_dokumen != \"MASUKKAN_PATH_DOKUMEN_ANDA_DI_SINI.pdf\" and os.path.exists(path_dokumen):\n",
    "    nama_dasar_dokumen = os.path.splitext(os.path.basename(path_dokumen))[0]\n",
    "    nama_file_output_json = f\"hasil_ekstraksi_{nama_dasar_dokumen}.json\"\n",
    "    output_dir = \"OutputSarana\"  # Direktori output default\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    full_output_path = os.path.join(output_dir, nama_file_output_json)\n",
    "    with open(full_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(output_json_final)\n",
    "    print(f\"\\nMenyimpan hasil ekstraksi ke berkas JSON: {full_output_path}\")\n",
    "else:\n",
    "    print(\"\\nInfo: Penyimpanan ke berkas JSON dilewati karena path_dokumen tidak valid atau belum diatur.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e545e27751b20e",
   "metadata": {},
   "source": [
    "## Catatan Akhir: Efisiensi, Keterbatasan, dan Pengembangan Lanjutan\n",
    "\n",
    "Notebook ini menyediakan alur kerja yang komprehensif untuk parsing dokumen dan ekstraksi informasi keuangan dasar. Namun, ada beberapa hal yang perlu diperhatikan:\n",
    "\n",
    "*   **Efisiensi Pemrosesan**:\n",
    "    *   **PDF Besar**: Seperti yang disebutkan, PDF besar dengan banyak halaman gambar bisa lambat karena OCR. Fitur **OCR Paralel** yang diimplementasikan di `parser_pdf.py` membantu mengurangi waktu tunggu.\n",
    "    *   **Caching**: Mekanisme **caching** untuk `parser_pdf.py` (disimpan di `.cache_parser_dokumen` secara default) akan sangat membantu jika Anda sering memproses ulang dokumen yang sama, karena hasil parsing akan diambil dari cache jika file tidak berubah.\n",
    "    *   **Pra-pemrosesan Gambar**: Langkah ini penting untuk akurasi OCR, tetapi juga menambah waktu pemrosesan untuk setiap gambar/halaman gambar.\n",
    "\n",
    "*   **Akurasi Ekstraksi Kata Kunci dan Nilai**:\n",
    "    *   **Logika Tahun Terbaru**: `pengekstrak_kata_kunci.py` kini mencoba mengidentifikasi tahun pelaporan dan memprioritaskan nilai yang berasosiasi dengan tahun tersebut, serta membedakannya dari nilai tahun sebelumnya. Akurasi logika ini sangat bergantung pada konsistensi format tabel dan layout dalam dokumen. Mungkin memerlukan penyesuaian regex lebih lanjut untuk berbagai format laporan keuangan.\n",
    "    *   **Variasi Kata Kunci**: Keberhasilan ekstraksi juga bergantung pada seberapa komprehensif daftar `variasi` untuk setiap `kata_dasar` dalam `konfigurasi_kata_kunci_target`.\n",
    "    *   **Normalisasi Nilai**: Fungsi `normalisasi_nilai_keuangan` menangani format umum Indonesia, tetapi format yang sangat tidak standar mungkin memerlukan penyesuaian.\n",
    "    *   **Konteks**: Ekstraktor saat ini menggunakan konteks kalimat dan kedekatan dengan tahun. Untuk kasus yang sangat ambigu, pemahaman struktur tabel atau elemen visual mungkin diperlukan (di luar cakupan saat ini).\n",
    "\n",
    "*   **Keterbatasan Bahasa Indonesia di NLTK**:\n",
    "    *   **Stopwords**: `pengekstrak_kata_kunci.py` mencoba menggunakan stopwords Bahasa Indonesia dari NLTK. Pastikan resource ini terinstal (`nltk.download('stopwords')`).\n",
    "    *   **Lemmatization/Stemming**: `WordNetLemmatizer` NLTK tidak dioptimalkan untuk Bahasa Indonesia. Untuk hasil yang lebih baik dalam normalisasi kata, pertimbangkan untuk mengintegrasikan stemmer khusus Bahasa Indonesia seperti PySastrawi (memerlukan instalasi terpisah). Saat ini, keakuratan pencocokan lebih bergantung pada variasi eksplisit yang disediakan.\n",
    "\n",
    "*   **Pengembangan Lanjutan yang Mungkin Dilakukan**:\n",
    "    *   Integrasi stemmer Bahasa Indonesia.\n",
    "    *   Pengembangan logika yang lebih canggih untuk memahami struktur tabel dalam dokumen.\n",
    "    *   Pelatihan model Machine Learning kustom untuk klasifikasi teks atau Named Entity Recognition (NER) pada dokumen keuangan untuk identifikasi entitas dan nilai yang lebih robust.\n",
    "    *   Antarmuka pengguna grafis (GUI) atau aplikasi web di atas logika ini.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
