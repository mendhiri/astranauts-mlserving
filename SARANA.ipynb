{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae6e51f2",
   "metadata": {},
   "source": [
    "# SARANA - Parser Teks Dokumen dan Pengekstrak Kata Kunci Keuangan (Tahunan)\n",
    "\n",
    "Notebook ini bertujuan untuk mem-parsing teks dari berbagai jenis dokumen (gambar, TXT, DOCX, PDF) dan kemudian mengekstrak istilah-istilah keuangan spesifik beserta nilainya, dengan fokus pada **data tahun pelaporan terbaru**. Proses ini melibatkan beberapa teknologi dan fitur utama:\n",
    "- **Parsing PDF Fleksibel**: Mendukung dua metode parsing PDF: `PyMuPDF` (dengan kemampuan OCR untuk halaman gambar) dan `pdfplumber` (efisien untuk PDF digital).\n",
    "- **OCR (Optical Character Recognition)**: Menggunakan `Tesseract` atau `Ollama` untuk mengekstrak teks dari gambar dan PDF berbasis gambar (ketika menggunakan metode `PyMuPDF`).\n",
    "- **Pra-pemrosesan Gambar**: Sebelum OCR, gambar diproses melalui beberapa tahap (konversi ke skala abu, penghilangan derau, binerisasi, dan percobaan pelurusan kemiringan) untuk meningkatkan kualitas OCR.\n",
    "- **Pemrosesan Paralel untuk PDF (PyMuPDF)**: Halaman PDF yang memerlukan OCR (dengan `PyMuPDF`) diproses secara paralel untuk mempercepat ekstraksi.\n",
    "- **Mekanisme Caching**: Hasil parsing PDF (untuk kedua metode) disimpan dalam cache untuk menghindari pemrosesan ulang file yang sama jika tidak ada perubahan. Kunci cache memperhitungkan metode parsing yang digunakan.\n",
    "- **Ekstraksi Kata Kunci Bertarget**: Mencari istilah keuangan yang telah ditentukan (dalam Bahasa Indonesia) dan mencoba mengidentifikasi nilai numerik yang berasosiasi dengan tahun pelaporan terbaru yang terdeteksi dalam dokumen.\n",
    "- **Normalisasi Nilai**: Nilai keuangan yang diekstrak dinormalisasi ke format float.\n",
    "- **Output JSON**: Hasil akhir ekstraksi kata kunci dan nilainya disajikan dalam format JSON.\n",
    "\n",
    "Pastikan semua skrip Python pendukung (`parser_gambar.py`, `parser_dokumen_teks.py`, `parser_pdf.py`, `pengekstrak_kata_kunci.py`, `utilitas_cache.py`) berada di direktori yang sama dengan notebook ini atau terinstal dalam lingkungan Python Anda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cbffd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:21:28.175687Z",
     "start_time": "2025-06-04T16:20:54.483798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berhasil memuat stopwords Bahasa Indonesia.\n",
      "WordNetLemmatizer berhasil diinisialisasi.\n",
      "Tokenizer 'punkt' tampaknya tersedia.\n",
      "Modul-modul kustom berhasil diimpor.\n",
      "Resource NLTK (wordnet) sudah ada.\n",
      "\n",
      "Pengaturan Selesai. Anda dapat melanjutkan ke sel Konfigurasi.\n"
     ]
    }
   ],
   "source": [
    "# Langkah Pengaturan Awal\n",
    "\n",
    "# 1. Impor Pustaka dan Modul Kustom\n",
    "# Pastikan semua skrip Python (.py) yang disebutkan di bawah ini\n",
    "# berada di direktori yang sama dengan notebook ini.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "\n",
    "# Impor fungsi-fungsi dari modul-modul utilitas kita\n",
    "try:\n",
    "    from SaranaModule.parser_gambar import ekstrak_teks_dari_gambar, ocr_dengan_ollama # Tambahkan ocr_dengan_ollama\n",
    "    from SaranaModule.parser_dokumen_teks import ekstrak_teks_dari_txt, ekstrak_teks_dari_docx\n",
    "    from SaranaModule.parser_pdf import ekstrak_teks_dari_pdf # Fungsi ini menggunakan ekstrak_teks_dari_gambar untuk OCR\n",
    "    from SaranaModule.parser_tabular import ekstrak_data_dari_xlsx, ekstrak_data_dari_csv\n",
    "    from SaranaModule.pengekstrak_kata_kunci import (\n",
    "        DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT, # Daftar kata kunci default\n",
    "        identifikasi_tahun_pelaporan,       # Untuk menemukan tahun dalam dokumen\n",
    "        ekstrak_data_keuangan_tahunan,      # Fungsi ekstraksi utama yang baru\n",
    "        format_ke_json,                     # Untuk output JSON\n",
    "        normalisasi_nilai_keuangan,          # Untuk membersihkan nilai angka (jika ingin diuji terpisah)\n",
    "        deteksi_pengali_global              # Untuk mendeteksi pengali global seperti 'juta', 'miliar', dll.\n",
    "    )\n",
    "    print(\"Modul-modul kustom berhasil diimpor.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error mengimpor modul kustom: {e}\")\n",
    "    print(\"Pastikan semua file .py (parser_gambar, parser_dokumen_teks, parser_pdf, pengekstrak_kata_kunci, utilitas_cache) berada di direktori yang sama.\")\n",
    "\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet.zip')\n",
    "    print(\"Resource NLTK (wordnet) sudah ada.\")\n",
    "except LookupError:\n",
    "    import ssl\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    print(\"Resource NLTK (wordnet) tidak ditemukan, mengunduh...\")\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('punkt_tab')\n",
    "    nltk.download('omw-1.4') # wordnet multilingual\n",
    "    nltk.download('punkt')   # untuk tokenisasi\n",
    "    nltk.download('stopwords') # untuk stopwords\n",
    "    print(\"Resource NLTK (wordnet) sudah terunduh.\")\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"Error terkait NLTK: {e}\")\n",
    "\n",
    "print(\"\\nPengaturan Selesai. Anda dapat melanjutkan ke sel Konfigurasi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46b6aed",
   "metadata": {},
   "source": [
    "## Penjelasan Fitur Utama\n",
    "\n",
    "Sebelum melanjutkan ke konfigurasi, berikut adalah ringkasan singkat tentang beberapa fitur utama yang digunakan dalam notebook ini:\n",
    "\n",
    "*   **Pra-pemrosesan Gambar untuk OCR**: Jika dokumen Anda adalah gambar atau PDF yang berisi halaman gambar, kualitas OCR sangat penting. Modul `parser_gambar.py` kini menyertakan langkah-langkah seperti konversi ke skala abu, penghilangan derau (noise), dan binerisasi (mengubah gambar menjadi hitam-putih) untuk meningkatkan akurasi Tesseract OCR. Implementasi dasar untuk pelurusan kemiringan (deskewing) juga ada, meskipun mungkin memerlukan penyesuaian lebih lanjut untuk kasus yang kompleks.\n",
    "*   **Pemrosesan Paralel untuk PDF**: Untuk mempercepat ekstraksi teks dari PDF yang memiliki banyak halaman berbasis gambar (yang memerlukan OCR), `parser_pdf.py` menggunakan `ThreadPoolExecutor`. Ini memungkinkan beberapa halaman diproses secara bersamaan, mengurangi waktu tunggu total.\n",
    "*   **Caching Hasil Parsing**: Untuk menghindari pemrosesan ulang file PDF yang sama berulang kali (yang bisa memakan waktu), `parser_pdf.py` kini terintegrasi dengan mekanisme caching (`utilitas_cache.py`). Hasil ekstraksi teks dari sebuah PDF akan disimpan dalam cache (default di direktori `.cache_parser_dokumen`). Jika Anda memproses PDF yang sama lagi dan file tersebut tidak berubah (berdasarkan path dan timestamp modifikasi terakhir), hasilnya akan diambil dari cache, yang jauh lebih cepat. Anda bisa membersihkan cache ini secara manual atau menggunakan fungsi `bersihkan_cache_lama` (jika ingin diimplementasikan lebih lanjut).\n",
    "*   **Logika Ekstraksi Nilai Berbasis Tahun**: Fungsi `ekstrak_data_keuangan_tahunan` dalam `pengekstrak_kata_kunci.py` dirancang untuk pertama-tama mengidentifikasi tahun pelaporan utama dalam dokumen. Kemudian, saat mencari nilai untuk kata kunci keuangan, ia akan mencoba memprioritaskan angka yang berasosiasi dengan tahun pelaporan tersebut dan membedakannya dari angka untuk tahun sebelumnya, jika keduanya muncul berdekatan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e509a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:24:29.942942Z",
     "start_time": "2025-06-04T16:24:29.937024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konfigurasi dimuat. Direktori dokumen yang akan diproses: train_documents/\n",
      "Hasil ekstraksi akan disimpan ke: OutputSarana/hasil_ekstraksi_semua_dokumen.json\n",
      "Metode parsing PDF yang dipilih: pymupdf\n",
      "  Mesin OCR yang dipilih (untuk PyMuPDF): tesseract\n",
      "Kata kunci yang akan dicari: ['Jumlah aset lancar', 'Jumlah aset tidak lancar', 'Jumlah liabilitas jangka pendek', 'Jumlah liabilitas jangka panjang', 'Jumlah liabilitas', 'Jumlah ekuitas', 'Jumlah liabilitas dan ekuitas', 'Pendapatan bersih', 'Beban pokok pendapatan', 'Laba bruto', 'Laba sebelum pajak penghasilan', 'Beban pajak penghasilan', 'Laba tahun berjalan', 'Jumlah aset', 'Piutang usaha', 'Aset tetap bruto', 'Akumulasi penyusutan', 'Modal kerja bersih', 'Laba ditahan', 'Beban bunga', 'Beban penyusutan', 'Beban penjualan', 'Beban administrasi dan umum', 'Beban usaha', 'Piutang usaha tahun lalu', 'Pendapatan bersih tahun lalu', 'Laba kotor tahun lalu', 'Aset tidak lancar selain PPE tahun lalu', 'Total aset tahun lalu', 'Beban penyusutan tahun lalu', 'Aset tetap bruto tahun lalu', 'Beban SGA tahun lalu', 'Total liabilitas tahun lalu']\n",
      "Direktori cache PDF kustom diatur ke: .cache_parsing_dokumen\n"
     ]
    }
   ],
   "source": [
    "# --- Konfigurasi Pengguna ---\n",
    "\n",
    "# 1. Pilih Metode Parsing PDF\n",
    "# Pilihan: 'pymupdf', 'pdfplumber'\n",
    "# 'pymupdf' menggunakan PyMuPDF untuk ekstraksi teks dasar dan OCR jika diperlukan (lebih kompleks).\n",
    "# 'pdfplumber' menggunakan pdfplumber untuk ekstraksi teks (umumnya lebih baik untuk PDF digital, tidak melakukan OCR sendiri).\n",
    "METODE_PARSING_PDF = 'pymupdf' # atau 'pdfplumber'\n",
    "\n",
    "# 2. Pilih Mesin OCR yang akan digunakan (hanya relevan jika METODE_PARSING_PDF = 'pymupdf' dan PDF memerlukan OCR)\n",
    "# Pilihan: 'tesseract', 'ollama'\n",
    "# Jika memilih 'ollama', pastikan server Ollama berjalan dan model 'llama3.2-vision' sudah diunduh.\n",
    "MESIN_OCR_PILIHAN = 'tesseract'  # Ganti ke 'ollama' untuk menggunakan Ollama OCR dengan PyMuPDF\n",
    "# Prompt ini digunakan ketika MESIN_OCR_PILIHAN adalah 'ollama'. \n",
    "# Bertujuan untuk mendapatkan transkripsi teks mentah seakurat mungkin dengan mempertahankan layout, \n",
    "# agar outputnya optimal untuk diproses lebih lanjut oleh 'ekstrak_data_keuangan_tahunan'.\n",
    "PROMPT_OLLAMA_KHUSUS = \"Transcribe all text content from the provided financial document image. Preserve the original line breaks and layout as accurately as possible to facilitate further text-based data extraction.\"\n",
    "\n",
    "# 3. Tentukan path ke DIREKTORI yang berisi dokumen yang ingin Anda proses.\n",
    "# Contoh: \"train_documents/\" untuk data periode t, atau \"train_documents_t_minus_1/\" untuk data periode t-1.\n",
    "path_direktori_dokumen_input = \"train_documents/\"\n",
    "\n",
    "# 3. Tentukan nama file JSON output untuk menyimpan hasil ekstraksi.\n",
    "# Contoh: \"hasil_ekstraksi_semua_dokumen.json\" untuk periode t,\n",
    "#         \"hasil_ekstraksi_semua_dokumen_t_minus_1.json\" untuk periode t-1.\n",
    "nama_file_json_output = \"hasil_ekstraksi_semua_dokumen.json\"\n",
    "# Direktori output akan tetap \"OutputSarana/\" secara default, jadi path lengkapnya akan menjadi \"OutputSarana/nama_file_json_output\".\n",
    "\n",
    "# 4. Definisikan atau Modifikasi Kata Kunci yang Akan Diekstrak\n",
    "# `konfigurasi_kata_kunci_target` adalah list kamus (dictionary).\n",
    "# Setiap kamus harus memiliki:\n",
    "#    - 'kata_dasar': Nama kanonis untuk kata kunci tersebut (misalnya, \"Laba Bersih\"). Ini akan menjadi kunci dalam output JSON.\n",
    "#    - 'variasi': List berisi berbagai cara penulisan atau sinonim kata kunci tersebut yang mungkin muncul di dokumen.\n",
    "#\n",
    "# Anda bisa menggunakan daftar default yang diimpor (`DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT`)\n",
    "# atau membuat/memodifikasi daftar Anda sendiri di bawah ini.\n",
    "#\n",
    "# Untuk menggunakan daftar default:\n",
    "from SaranaModule.pengekstrak_kata_kunci import DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT\n",
    "konfigurasi_kata_kunci_target = DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT\n",
    "\n",
    "# 3. (Opsional) Konfigurasi Direktori Cache untuk PDF Parser\n",
    "# Jika Anda ingin parser PDF menggunakan direktori cache selain default (`.cache_parser_dokumen`),\n",
    "# Anda bisa menentukan path-nya di sini. Jika tidak, biarkan `None` untuk menggunakan default.\n",
    "direktori_cache_pdf_kustom = \".cache_parsing_dokumen\"\n",
    "\n",
    "# --- Akhir Konfigurasi Pengguna ---\n",
    "\n",
    "# Validasi awal konfigurasi\n",
    "if 'path_direktori_dokumen_input' not in locals() or not path_direktori_dokumen_input:\n",
    "    print(\"PERINGATAN: 'path_direktori_dokumen_input' belum diatur atau kosong.\")\n",
    "    print(\"Mohon perbarui variabel 'path_direktori_dokumen_input' di atas dengan path ke DIREKTORI yang berisi dokumen-dokumen yang ingin Anda proses.\")\n",
    "elif not os.path.isdir(path_direktori_dokumen_input):\n",
    "    print(f\"ERROR: Path direktori input yang ditentukan ('{path_direktori_dokumen_input}') bukan direktori atau tidak ditemukan.\")\n",
    "    print(\"Mohon periksa kembali 'path_direktori_dokumen_input' dan pastikan itu adalah direktori yang valid dan ada.\")\n",
    "elif 'nama_file_json_output' not in locals() or not nama_file_json_output:\n",
    "    print(\"PERINGATAN: 'nama_file_json_output' belum diatur atau kosong.\")\n",
    "    print(\"Mohon perbarui variabel 'nama_file_json_output' untuk menentukan nama file hasil ekstraksi.\")\n",
    "else:\n",
    "    print(f\"Konfigurasi dimuat. Direktori dokumen yang akan diproses: {path_direktori_dokumen_input}\")\n",
    "    print(f\"Hasil ekstraksi akan disimpan ke: OutputSarana/{nama_file_json_output}\")\n",
    "    print(f\"Metode parsing PDF yang dipilih: {METODE_PARSING_PDF}\")\n",
    "    if METODE_PARSING_PDF == 'pymupdf':\n",
    "        print(f\"  Mesin OCR yang dipilih (untuk PyMuPDF): {MESIN_OCR_PILIHAN}\")\n",
    "        if MESIN_OCR_PILIHAN == 'ollama':\n",
    "            print(f\"    Prompt Ollama: {PROMPT_OLLAMA_KHUSUS}\")\n",
    "    elif METODE_PARSING_PDF == 'pdfplumber':\n",
    "        print(\"  (Mesin OCR tidak digunakan secara langsung oleh pdfplumber untuk ekstraksi teks awal)\")\n",
    "    else:\n",
    "        print(f\"PERINGATAN: Metode parsing PDF '{METODE_PARSING_PDF}' tidak dikenal. Harap pilih 'pymupdf' atau 'pdfplumber'.\")\n",
    "\n",
    "    # Validasi pilihan MESIN_OCR_PILIHAN\n",
    "    if METODE_PARSING_PDF == 'pymupdf' and MESIN_OCR_PILIHAN not in ['tesseract', 'ollama']:\n",
    "        print(f\"PERINGATAN: MESIN_OCR_PILIHAN '{MESIN_OCR_PILIHAN}' tidak valid untuk PyMuPDF. Harap pilih 'tesseract' atau 'ollama'. Menggunakan 'tesseract' sebagai default.\")\n",
    "        MESIN_OCR_PILIHAN = 'tesseract'\n",
    "        \n",
    "    print(f\"Kata kunci yang akan dicari: {[item['kata_dasar'] for item in konfigurasi_kata_kunci_target]}\")\n",
    "    if direktori_cache_pdf_kustom:\n",
    "        print(f\"Direktori cache PDF kustom diatur ke: {direktori_cache_pdf_kustom}\")\n",
    "\n",
    "# Inisialisasi list untuk menyimpan semua hasil ekstraksi dari semua dokumen\n",
    "semua_hasil_ekstraksi = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ad4464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:24:34.363713Z",
     "start_time": "2025-06-04T16:24:34.357065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mencari dokumen dengan ekstensi yang didukung: .pdf, .jpg, .jpeg, .png, .tiff, .bmp, .gif, .txt, .docx, .xlsx, .csv di direktori: train_documents/\n",
      "Ditemukan 1 dokumen untuk diproses: ['lapkeu_x.pdf']\n",
      "\n",
      "--- Memulai pemrosesan untuk dokumen: lapkeu_x.pdf ---\n",
      "Tipe berkas terdeteksi: .pdf untuk lapkeu_x.pdf\n",
      "Cache tidak ditemukan atau tidak valid untuk lapkeu_x.pdf (Metode: pymupdf), memproses dari awal.\n",
      "INFO (Worker Halaman 5): Melakukan OCR pada './temp_pdf_page_5_fdf80790ba724918a685dbfed2fc8805.png' menggunakan mesin 'tesseract'...\n",
      "INFO (Worker Halaman 7): Melakukan OCR pada './temp_pdf_page_7_f961e128bc9e4507a6e2a4cbb9353b49.png' menggunakan mesin 'tesseract'...\n",
      "INFO (Worker Halaman 2): Melakukan OCR pada './temp_pdf_page_2_714d6f3a087c48a3b88570a83a3892df.png' menggunakan mesin 'tesseract'...\n",
      "INFO (Worker Halaman 3): Melakukan OCR pada './temp_pdf_page_3_9cdf03f3ac214b4a87d0ea6c5f592c66.png' menggunakan mesin 'tesseract'...\n",
      "INFO (Worker Halaman 8): Melakukan OCR pada './temp_pdf_page_8_98c1519d82e54a38a1092c722f6469c7.png' menggunakan mesin 'tesseract'...\n",
      "INFO (Worker Halaman 4): Melakukan OCR pada './temp_pdf_page_4_87ea20c7726d45f1bf6932c2a12ba3a4.png' menggunakan mesin 'tesseract'...\n",
      "INFO (Worker Halaman 1): Melakukan OCR pada './temp_pdf_page_1_3a752123c3a94eb9b54a4478d3aff362.png' menggunakan mesin 'tesseract'...\n",
      "INFO (Worker Halaman 6): Melakukan OCR pada './temp_pdf_page_6_534da7d007504cfbb69a7a198763bbec.png' menggunakan mesin 'tesseract'...\n",
      "INFO (Worker Halaman 3): OCR selesai, teks diekstrak (awal 100 char): '-\n",
      "pwc\n",
      "al aver: utama yang lee ce\n",
      "urakan sobanar berkut\n",
      "las dalam audit haw\n",
      "1 onenyisihan terhadap pi...'\n",
      "INFO (Worker Halaman 9): Melakukan OCR pada './temp_pdf_page_9_b80071001e764b81994a422503918f0a.png' menggunakan mesin 'tesseract'...\n",
      "INFO (Worker Halaman 2): OCR selesai, teks diekstrak (awal 100 char): '=\n",
      "LAPORAN AUDITOR INDEPENDEN\n",
      "KEPADA PARA PEMEGANG SAHAM\n",
      "'NOEPENOENT AUDITORS: REPORT\n",
      "TO THE SHAREHOL...'\n",
      "INFO (Worker Halaman 10): Melakukan OCR pada './temp_pdf_page_10_1ccc38a09fb245cf9057e5b567411e4a.png' menggunakan mesin 'tesseract'...\n",
      "INFO (Worker Halaman 5): OCR selesai, teks diekstrak (awal 100 char): '3\n",
      "pwe\n",
      "Pods tonaayt 31 Desembor 2024. » 2 tercatat\n",
      "PropeN PEMAMBANYAN Grup dea am Man\n",
      "Ry 15 ?\"2 minar...'\n",
      "INFO (Worker Halaman 7): OCR selesai, teks diekstrak (awal 100 char): 'Kami melakukan ans\n",
      "Terbatas ie\n",
      "ahtrs Sens tvtas independen\n",
      "umi ulama ian\n",
      "mempermbangkan serargkaian ...'\n",
      "INFO (Worker Halaman 4): OCR selesai, teks diekstrak (awal 100 char): 'Kam. manitat matodotoai sang Ygungtan dalam Boe 2st05te2 me mettodotay oseo ve tke meden\n",
      "bergo gamap...'\n",
      "INFO (Worker Halaman 1): OCR selesai, teks diekstrak (awal 100 char): 'Mai taintia al\n",
      "TANGGUNG JAWAB ATAS LAPORAN KEUANGAN\n",
      "KONSOLIDASIAN PADA TANGGAL\n",
      "H DESEMBER 2024 OAN 2...'\n",
      "INFO (Worker Halaman 8): OCR selesai, teks diekstrak (awal 100 char): 'jusunan apecan keuangan konsodasisn,\n",
      "Crosman Iwelangggung\n",
      "seriampuan Grup dalam mramperiaranan\n",
      "keela...'\n",
      "INFO (Worker Halaman 6): OCR selesai, teks diekstrak (awal 100 char): 'Kartu meripereleh ptrtaharrcan da mei prises\n",
      "'menaykien untuk Meas! apawuh tenor\n",
      "indikator penurunan...'\n",
      "INFO (Worker Halaman 10): OCR selesai, teks diekstrak (awal 100 char): 'Dow» ina, yarg dikomunikasikan kepada pinga yang\n",
      "Seranggung ste Atas tata kelola kami reverb\n",
      "utral t...'\n",
      "INFO (Worker Halaman 9): OCR selesai, teks diekstrak (awal 100 char): '+ Meng opsi ketapalan ketayakan ikuntangi\n",
      "Yang GQ. \"saean Serta kenajaran esumas\n",
      "Mura Cat. prune Sor...'\n",
      "Menyimpan hasil ke cache untuk: lapkeu_x.pdf (Metode: pymupdf)\n",
      "Parsing dokumen 'lapkeu_x.pdf' selesai. Total karakter: 12483\n",
      "Memulai ekstraksi kata kunci untuk: lapkeu_x.pdf\n",
      "Pengali terdeteksi untuk 'lapkeu_x.pdf': 1000000000.0\n",
      "Ekstraksi kata kunci untuk 'lapkeu_x.pdf' selesai.\n",
      "--- Pemrosesan untuk dokumen: lapkeu_x.pdf selesai. Hasil disimpan (secara terpisah untuk t dan t-1). ---\n",
      "\n",
      "=== Semua dokumen dalam direktori telah diproses. ===\n",
      "Total item dalam 'semua_hasil_ekstraksi_t': 1\n",
      "Total item dalam 'semua_hasil_ekstraksi_t_minus_1': 1\n"
     ]
    }
   ],
   "source": [
    "# Langkah ini akan melakukan iterasi melalui semua dokumen yang didukung dalam direktori yang ditentukan,\n",
    "# mengekstrak teks dari masing-masing dokumen, dan kemudian mengekstrak kata kunci.\n",
    "\n",
    "# Pastikan path_direktori_dokumen_input (direktori) telah dikonfigurasi dengan benar dan merupakan direktori\n",
    "if 'path_direktori_dokumen_input' not in locals() or not path_direktori_dokumen_input or not os.path.isdir(path_direktori_dokumen_input) or \\\n",
    "    'nama_file_json_output' not in locals() or not nama_file_json_output:\n",
    "    pesan_error_global = \"Error: Konfigurasi 'path_direktori_dokumen_input' atau 'nama_file_json_output' tidak valid. Silakan perbarui di sel Konfigurasi.\"\n",
    "    if 'path_direktori_dokumen_input' in locals() and (not path_direktori_dokumen_input):\n",
    "        pesan_error_global = \"Error: 'path_direktori_dokumen_input' (direktori) belum diatur atau kosong. Silakan perbarui di sel Konfigurasi.\"\n",
    "    elif 'path_direktori_dokumen_input' in locals() and not os.path.isdir(path_direktori_dokumen_input):\n",
    "        pesan_error_global = f\"Error: Path '{path_direktori_dokumen_input}' bukan direktori yang valid atau tidak ditemukan. Mohon verifikasi path di sel Konfigurasi.\"\n",
    "    elif 'nama_file_json_output' not in locals() or not nama_file_json_output:\n",
    "        pesan_error_global = \"Error: 'nama_file_json_output' belum diatur atau kosong. Silakan perbarui di sel Konfigurasi.\"\n",
    "    \n",
    "    print(pesan_error_global)\n",
    "    # MODIFIKASI: Inisialisasi list t dan t-1 jika ada error konfigurasi global\n",
    "    if 'semua_hasil_ekstraksi_t' not in locals(): semua_hasil_ekstraksi_t = [] \n",
    "    if 'semua_hasil_ekstraksi_t_minus_1' not in locals(): semua_hasil_ekstraksi_t_minus_1 = [] \n",
    "    semua_hasil_ekstraksi_t.append({\n",
    "        \"nama_file\": \"KONFIGURASI_ERROR\",\n",
    "        \"hasil_ekstraksi\": {\"error_global_konfigurasi\": pesan_error_global}\n",
    "    })\n",
    "else:\n",
    "    supported_extensions = ['.pdf', '.jpg', '.jpeg', '.png', '.tiff', '.bmp', '.gif', '.txt', '.docx', '.xlsx', '.csv']\n",
    "    print(f\"Mencari dokumen dengan ekstensi yang didukung: {', '.join(supported_extensions)} di direktori: {path_direktori_dokumen_input}\")\n",
    "    \n",
    "    # MODIFIKASI: Inisialisasi dua list untuk hasil t dan t-1\n",
    "    semua_hasil_ekstraksi_t = []\n",
    "    semua_hasil_ekstraksi_t_minus_1 = []\n",
    "\n",
    "    files_to_process = []\n",
    "    try:\n",
    "        files_to_process = [\n",
    "            f for f in os.listdir(path_direktori_dokumen_input) \n",
    "            if os.path.isfile(os.path.join(path_direktori_dokumen_input, f)) and \n",
    "            os.path.splitext(f)[1].lower() in supported_extensions\n",
    "        ]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Direktori '{path_direktori_dokumen_input}' tidak ditemukan. Periksa konfigurasi path_direktori_dokumen_input.\")\n",
    "        semua_hasil_ekstraksi_t.append({\"nama_file\": \"DIREKTORI_TIDAK_DITEMUKAN\", \"hasil_ekstraksi\": {\"error_direktori\": f\"Direktori '{path_direktori_dokumen_input}' tidak ditemukan.\"}})\n",
    "    except Exception as e_listdir:\n",
    "        print(f\"Error saat mengakses direktori '{path_direktori_dokumen_input}': {e_listdir}\")\n",
    "        semua_hasil_ekstraksi_t.append({\"nama_file\": \"AKSES_DIREKTORI_ERROR\", \"hasil_ekstraksi\": {\"error_direktori\": f\"Error mengakses '{path_direktori_dokumen_input}': {e_listdir}\"}})\n",
    "\n",
    "    if not files_to_process:\n",
    "        msg_no_files = f\"Tidak ada dokumen dengan ekstensi yang didukung ditemukan di {path_direktori_dokumen_input}\"\n",
    "        print(msg_no_files)\n",
    "        # Pastikan pesan 'tidak ada file' hanya ditambahkan jika belum ada error konfigurasi/direktori sebelumnya\n",
    "        if not any(d.get(\"nama_file\") in [\"KONFIGURASI_ERROR\", \"DIREKTORI_TIDAK_DITEMUKAN\", \"AKSES_DIREKTORI_ERROR\"] for d in semua_hasil_ekstraksi_t):\n",
    "            semua_hasil_ekstraksi_t.append({\"nama_file\": \"TIDAK_ADA_FILE\", \"hasil_ekstraksi\": {\"info\": msg_no_files}})\n",
    "    else:\n",
    "        print(f\"Ditemukan {len(files_to_process)} dokumen untuk diproses: {files_to_process}\")\n",
    "\n",
    "        for nama_file_dokumen in files_to_process:\n",
    "            current_file_path = os.path.join(path_direktori_dokumen_input, nama_file_dokumen)\n",
    "            print(f\"\\n--- Memulai pemrosesan untuk dokumen: {nama_file_dokumen} ---\")\n",
    "            \n",
    "            teks_hasil_ekstraksi_file = \"\" # Inisialisasi untuk setiap file\n",
    "            kamus_t_only = {} # MODIFIKASI: Untuk hasil t\n",
    "            kamus_t_minus_1_only = {} # MODIFIKASI: Untuk hasil t-1\n",
    "            \n",
    "            ekstensi_file = os.path.splitext(nama_file_dokumen)[1].lower()\n",
    "            print(f\"Tipe berkas terdeteksi: {ekstensi_file} untuk {nama_file_dokumen}\")\n",
    "\n",
    "            try:\n",
    "                if ekstensi_file == '.pdf':\n",
    "                    dir_cache = direktori_cache_pdf_kustom if 'direktori_cache_pdf_kustom' in locals() and direktori_cache_pdf_kustom else None\n",
    "                    teks_hasil_ekstraksi_file = ekstrak_teks_dari_pdf(\n",
    "                        current_file_path, \n",
    "                        fungsi_ocr_untuk_gambar=ekstrak_teks_dari_gambar, # Hanya digunakan jika metode_parsing='pymupdf' dan OCR diperlukan\n",
    "                        mesin_ocr=MESIN_OCR_PILIHAN, # Hanya digunakan jika metode_parsing='pymupdf' dan OCR diperlukan\n",
    "                        # opsi_praproses bisa ditambahkan jika relevan untuk PyMuPDF OCR\n",
    "                        direktori_cache_kustom=dir_cache,\n",
    "                        prompt_ollama=PROMPT_OLLAMA_KHUSUS if MESIN_OCR_PILIHAN == 'ollama' else \"get all the data from the image\", # Hanya untuk PyMuPDF OCR Ollama\n",
    "                        metode_parsing=METODE_PARSING_PDF # <-- TAMBAHKAN INI\n",
    "                    )\n",
    "                elif ekstensi_file in ['.jpg', '.jpeg', '.png', '.tiff', '.bmp', '.gif']:\n",
    "                    # Untuk gambar, MESIN_OCR_PILIHAN masih relevan\n",
    "                    teks_hasil_ekstraksi_file = ekstrak_teks_dari_gambar(\n",
    "                        current_file_path, \n",
    "                        mesin_ocr=MESIN_OCR_PILIHAN, # 'tesseract' atau 'ollama'\n",
    "                        # opsi_praproses bisa ditambahkan jika MESIN_OCR_PILIHAN bukan ollama\n",
    "                        prompt_ollama=PROMPT_OLLAMA_KHUSUS if MESIN_OCR_PILIHAN == 'ollama' else \"get all the data from the image\"\n",
    "                    )\n",
    "                elif ekstensi_file == '.xlsx':\n",
    "                    teks_hasil_ekstraksi_file = ekstrak_data_dari_xlsx(current_file_path)\n",
    "                elif ekstensi_file == '.csv':\n",
    "                    teks_hasil_ekstraksi_file = ekstrak_data_dari_csv(current_file_path)\n",
    "                elif ekstensi_file == '.txt':\n",
    "                    teks_hasil_ekstraksi_file = ekstrak_teks_dari_txt(current_file_path)\n",
    "                elif ekstensi_file == '.docx':\n",
    "                    teks_hasil_ekstraksi_file = ekstrak_teks_dari_docx(current_file_path)\n",
    "            except Exception as e_parse:\n",
    "                error_msg_parse = f\"Error selama parsing dokumen '{nama_file_dokumen}': {str(e_parse)}\"\n",
    "                print(error_msg_parse)\n",
    "                teks_hasil_ekstraksi_file = error_msg_parse # Jika error, teks_hasil_ekstraksi_file akan berisi pesan error (string)\n",
    "\n",
    "            # Beberapa parser (seperti ekstrak_teks_dari_gambar dengan Ollama) mungkin mengembalikan list of strings (baris).\n",
    "            # Fungsi selanjutnya seperti ekstrak_data_keuangan_tahunan mengharapkan satu string besar.\n",
    "            # Jadi, gabungkan jika hasilnya adalah list.\n",
    "            if isinstance(teks_hasil_ekstraksi_file, list):\n",
    "                print(f\"INFO: Menggabungkan list baris teks dari '{nama_file_dokumen}' menjadi satu string.\")\n",
    "                teks_hasil_ekstraksi_file = '\\n'.join(teks_hasil_ekstraksi_file)\n",
    "\n",
    "            # Lanjutkan hanya jika tidak ada error parsing dan teks tidak kosong\n",
    "            if not teks_hasil_ekstraksi_file.startswith(\"Error:\") and teks_hasil_ekstraksi_file.strip():\n",
    "                print(f\"Parsing dokumen '{nama_file_dokumen}' selesai. Total karakter: {len(teks_hasil_ekstraksi_file)}\")\n",
    "                print(f\"Memulai ekstraksi kata kunci untuk: {nama_file_dokumen}\")\n",
    "                pengali_dokumen_file = 1.0 \n",
    "                print_output_pengali_file = []\n",
    "                try:\n",
    "                    pengali_dokumen_file = deteksi_pengali_global(teks_hasil_ekstraksi_file)\n",
    "                    print_output_pengali_file.append(f\"Pengali terdeteksi untuk '{nama_file_dokumen}': {pengali_dokumen_file}\")\n",
    "                except Exception as e_pengali:\n",
    "                    print_output_pengali_file.append(f\"Error saat deteksi pengali untuk '{nama_file_dokumen}': {str(e_pengali)}. Menggunakan default 1.0.\")\n",
    "                    pengali_dokumen_file = 1.0\n",
    "                for msg in print_output_pengali_file: print(msg)\n",
    "                if 'konfigurasi_kata_kunci_target' not in locals() or not konfigurasi_kata_kunci_target:\n",
    "                    pesan_error_konfig_loop = \"Error krusial: 'konfigurasi_kata_kunci_target' tidak terdefinisi. Periksa sel Konfigurasi.\"\n",
    "                    print(pesan_error_konfig_loop)\n",
    "                    kamus_t_only = {\"error_konfigurasi_global\": pesan_error_konfig_loop} # MODIFIKASI\n",
    "                else:\n",
    "                    try:\n",
    "                        kamus_hasil_ekstraksi_file_lengkap = ekstrak_data_keuangan_tahunan(\n",
    "                            teks_hasil_ekstraksi_file, \n",
    "                            konfigurasi_kata_kunci_target, \n",
    "                            pengali_global=pengali_dokumen_file\n",
    "                        )\n",
    "                        print(f\"Ekstraksi kata kunci untuk '{nama_file_dokumen}' selesai.\")\n",
    "                        # MODIFIKASI: Memecah hasil_ekstraksi_file_lengkap menjadi t_only dan t_minus_1_only\n",
    "                        if isinstance(kamus_hasil_ekstraksi_file_lengkap, dict):\n",
    "                            for key, values_dict in kamus_hasil_ekstraksi_file_lengkap.items():\n",
    "                                if isinstance(values_dict, dict):\n",
    "                                    if values_dict.get('t') is not None:\n",
    "                                        kamus_t_only[key] = values_dict['t']\n",
    "                                    if values_dict.get('t-1') is not None:\n",
    "                                        kamus_t_minus_1_only[key] = values_dict['t-1']\n",
    "                                else: # Fallback jika struktur tidak seperti yang diharapkan\n",
    "                                    kamus_t_only[key] = values_dict \n",
    "                        else: # Jika hasil ekstraksi bukan dict (misal, error string dari tahap sebelumnya)\n",
    "                             kamus_t_only = kamus_hasil_ekstraksi_file_lengkap\n",
    "                    except Exception as e_ekstraksi:\n",
    "                        pesan_error_ekstraksi_loop = f\"Error selama proses ekstraksi kata kunci untuk '{nama_file_dokumen}': {str(e_ekstraksi)}\"\n",
    "                        print(pesan_error_ekstraksi_loop)\n",
    "                        kamus_t_only = {\"error_runtime_ekstraksi\": pesan_error_ekstraksi_loop} # MODIFIKASI\n",
    "                        kamus_t_minus_1_only = {} # Tetap kosong saat error\n",
    "            elif not teks_hasil_ekstraksi_file.strip() and not teks_hasil_ekstraksi_file.startswith(\"Error:\"):\n",
    "                info_msg = f\"Info: Teks yang diekstrak dari '{nama_file_dokumen}' kosong atau hanya spasi putih.\"\n",
    "                print(info_msg)\n",
    "                kamus_t_only = {\"info_parsing\": info_msg} # MODIFIKASI\n",
    "                kamus_t_minus_1_only = {}\n",
    "            else: # Ada error dari parsing (teks_hasil_ekstraksi_file sudah berisi pesan error)\n",
    "                kamus_t_only = {\"error_parsing\": teks_hasil_ekstraksi_file} # MODIFIKASI\n",
    "                kamus_t_minus_1_only = {}\n",
    "\n",
    "            # MODIFIKASI: Simpan ke list yang sesuai\n",
    "            if kamus_t_only: # Hanya tambahkan jika ada isinya (termasuk error/info)\n",
    "                semua_hasil_ekstraksi_t.append({\n",
    "                    \"nama_file\": nama_file_dokumen,\n",
    "                    \"hasil_ekstraksi\": kamus_t_only\n",
    "                })\n",
    "            \n",
    "            if kamus_t_minus_1_only: # Hanya tambahkan jika ada isinya\n",
    "                 semua_hasil_ekstraksi_t_minus_1.append({\n",
    "                    \"nama_file\": nama_file_dokumen,\n",
    "                    \"hasil_ekstraksi\": kamus_t_minus_1_only\n",
    "                })\n",
    "            print(f\"--- Pemrosesan untuk dokumen: {nama_file_dokumen} selesai. Hasil disimpan (secara terpisah untuk t dan t-1). ---\")\n",
    "            \n",
    "        print(\"\\n=== Semua dokumen dalam direktori telah diproses. ===\")\n",
    "\n",
    "# MODIFIKASI: Ringkasan setelah loop selesai (opsional, bisa disesuaikan untuk dua list)\n",
    "if 'semua_hasil_ekstraksi_t' in locals() and semua_hasil_ekstraksi_t:\n",
    "    print(f\"Total item dalam 'semua_hasil_ekstraksi_t': {len(semua_hasil_ekstraksi_t)}\")\n",
    "    # Tambahkan loop serupa untuk semua_hasil_ekstraksi_t_minus_1 jika perlu detail status\n",
    "else:\n",
    "    print(\"Tidak ada hasil ekstraksi (t) yang tersimpan atau list kosong. Periksa log di atas.\")\n",
    "if 'semua_hasil_ekstraksi_t_minus_1' in locals() and semua_hasil_ekstraksi_t_minus_1:\n",
    "    print(f\"Total item dalam 'semua_hasil_ekstraksi_t_minus_1': {len(semua_hasil_ekstraksi_t_minus_1)}\")\n",
    "else:\n",
    "    print(\"Tidak ada hasil ekstraksi (t-1) yang tersimpan atau list kosong.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa89525e73aaa7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'semua_hasil_ekstraksi_t' ditemukan dengan 1 item. Akan diformat ke JSON.\n",
      "\n",
      "--- Output Agregat Final (JSON untuk data t) ---\n",
      "[\n",
      "    {\n",
      "        \"nama_file\": \"lapkeu_x.pdf\",\n",
      "        \"hasil_ekstraksi\": {\n",
      "            \"Jumlah aset lancar\": 19238000000000.0,\n",
      "            \"Jumlah aset tidak lancar\": 81765000000000.0,\n",
      "            \"Jumlah liabilitas jangka pendek\": 14300000000000.0,\n",
      "            \"Jumlah liabilitas jangka panjang\": 1989000000000.0,\n",
      "            \"Jumlah liabilitas\": 14300000000000.0,\n",
      "            \"Jumlah ekuitas\": 84714000000000.0,\n",
      "            \"Jumlah liabilitas dan ekuitas\": 101003000000000.0,\n",
      "            \"Pendapatan bersih\": 108249000000000.0,\n",
      "            \"Beban pokok pendapatan\": -97738000000000.0,\n",
      "            \"Laba bruto\": 10511000000000.0,\n",
      "            \"Laba sebelum pajak penghasilan\": 22136000000000.0,\n",
      "            \"Beban pajak penghasilan\": -475000000000.0,\n",
      "            \"Laba tahun berjalan\": 21661000000000.0,\n",
      "            \"Jumlah aset\": 19238000000000.0,\n",
      "            \"Piutang usaha\": 1000000000.0,\n",
      "            \"Aset tetap bruto\": 15697000000000.0,\n",
      "            \"Laba ditahan\": 425000000000.0,\n",
      "            \"Be... (output t dipotong)\n",
      "\n",
      "Menyimpan hasil ekstraksi (t) semua dokumen ke berkas JSON: Output/Sarana/hasil_ekstraksi_semua_dokumen.json\n",
      "'semua_hasil_ekstraksi_t_minus_1' ditemukan dengan 1 item. Akan diformat ke JSON.\n",
      "\n",
      "--- Output Agregat Final (JSON untuk data t-1) ---\n",
      "[\n",
      "    {\n",
      "        \"nama_file\": \"lapkeu_x.pdf\",\n",
      "        \"hasil_ekstraksi\": {\n",
      "            \"Jumlah aset lancar\": 21682000000000.0,\n",
      "            \"Jumlah aset tidak lancar\": 79502000000000.0,\n",
      "            \"Jumlah liabilitas jangka pendek\": 15275000000000.0,\n",
      "            \"Jumlah liabilitas jangka panjang\": 1851000000000.0,\n",
      "            \"Jumlah liabilitas\": 15275000000000.0,\n",
      "            \"Jumlah ekuitas\": 84058000000000.0,\n",
      "            \"Jumlah liabilitas dan ekuitas\": 101184000000000.0,\n",
      "            \"Pendapatan bersih\": 106427000000000.0,\n",
      "            \"Beban pokok pendapatan\": -95573000000000.0,\n",
      "            \"Laba bruto\": 10854000000000.0,\n",
      "            \"Laba sebelum pajak penghasilan\": 31478000000000.0,\n",
      "            \"Beban pajak penghasilan\": -547000000000.0,\n",
      "            \"Laba tahun berjalan\": 30931000000000.0,\n",
      "            \"Jumlah aset\": 21682000000000.0,\n",
      "            \"Piutang usaha\": 2023000000000.0,\n",
      "            \"Aset tetap bruto\": 15472000000000.0,\n",
      "            \"Laba ditahan\": 425000000000.0,\n",
      "            ... (output t-1 dipotong)\n",
      "\n",
      "Menyimpan hasil ekstraksi (t-1) semua dokumen ke berkas JSON: Output/Sarana/hasil_ekstraksi_semua_dokumen_t_minus_1.json\n"
     ]
    }
   ],
   "source": [
    "# MODIFIKASI: Langkah ini sekarang akan memformat dan menyimpan dua set data: t dan t-1.\n",
    "\n",
    "output_dir_agregat = \"Output/Sarana\"\n",
    "os.makedirs(output_dir_agregat, exist_ok=True) # Buat direktori jika belum ada\n",
    "\n",
    "# --- PENYIMPANAN DATA T ---\n",
    "if 'nama_file_json_output' in locals() and nama_file_json_output:\n",
    "    data_untuk_json_t = []\n",
    "    if 'semua_hasil_ekstraksi_t' in locals() and isinstance(semua_hasil_ekstraksi_t, list):\n",
    "        if semua_hasil_ekstraksi_t: # Jika list tidak kosong\n",
    "            print(f\"'semua_hasil_ekstraksi_t' ditemukan dengan {len(semua_hasil_ekstraksi_t)} item. Akan diformat ke JSON.\")\n",
    "            data_untuk_json_t = semua_hasil_ekstraksi_t\n",
    "        else: # List ada tapi kosong\n",
    "            print(\"Info: 'semua_hasil_ekstraksi_t' adalah list kosong (tidak ada file diproses atau file tidak menghasilkan output).\")\n",
    "            data_untuk_json_t.append({\"info\": \"Tidak ada data (t) yang diekstrak dari dokumen manapun.\"})\n",
    "    else: # Variabel tidak ada atau bukan list\n",
    "        print(\"Error: 'semua_hasil_ekstraksi_t' tidak ditemukan atau tidak valid. Proses ekstraksi mungkin gagal total.\")\n",
    "        data_untuk_json_t.append({\"error_kritis\": \"Variabel 'semua_hasil_ekstraksi_t' tidak tersedia atau tidak valid.\"})\n",
    "\n",
    "    try:\n",
    "        output_json_t = json.dumps(data_untuk_json_t, indent=4, ensure_ascii=False)\n",
    "        print(\"\\n--- Output Agregat Final (JSON untuk data t) ---\")\n",
    "        if len(output_json_t) > 1000: print(output_json_t[:1000] + \"... (output t dipotong)\")\n",
    "        else: print(output_json_t)\n",
    "        \n",
    "        full_output_path_t = os.path.join(output_dir_agregat, nama_file_json_output) # Nama file asli untuk data t\n",
    "        with open(full_output_path_t, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(output_json_t)\n",
    "        print(f\"\\nMenyimpan hasil ekstraksi (t) semua dokumen ke berkas JSON: {full_output_path_t}\")\n",
    "    except Exception as e_write_t:\n",
    "        print(f\"\\nERROR: Gagal menyimpan berkas JSON (t) di '{full_output_path_t}': {e_write_t}\")\n",
    "else:\n",
    "    print(\"\\nPERINGATAN: 'nama_file_json_output' tidak terdefinisi. Hasil JSON (t) tidak disimpan.\")\n",
    "\n",
    "# --- PENYIMPANAN DATA T-1 ---\n",
    "if 'nama_file_json_output' in locals() and nama_file_json_output:\n",
    "    data_untuk_json_t_minus_1 = []\n",
    "    save_t_minus_1_file = False # Flag untuk menentukan apakah file t-1 perlu disimpan\n",
    "\n",
    "    if 'semua_hasil_ekstraksi_t_minus_1' in locals() and isinstance(semua_hasil_ekstraksi_t_minus_1, list):\n",
    "        if semua_hasil_ekstraksi_t_minus_1: # Jika list tidak kosong\n",
    "            print(f\"'semua_hasil_ekstraksi_t_minus_1' ditemukan dengan {len(semua_hasil_ekstraksi_t_minus_1)} item. Akan diformat ke JSON.\")\n",
    "            data_untuk_json_t_minus_1 = semua_hasil_ekstraksi_t_minus_1\n",
    "            save_t_minus_1_file = True\n",
    "        else: # List ada tapi kosong\n",
    "            print(\"Info: 'semua_hasil_ekstraksi_t_minus_1' adalah list kosong (tidak ada data t-1 yang diekstrak).\")\n",
    "            # Tidak membuat file jika memang tidak ada data t-1 sama sekali\n",
    "    else: # Variabel tidak ada atau bukan list\n",
    "        print(\"Error: 'semua_hasil_ekstraksi_t_minus_1' tidak ditemukan atau tidak valid.\")\n",
    "        # data_untuk_json_t_minus_1.append({\"error_kritis\": \"Variabel 'semua_hasil_ekstraksi_t_minus_1' tidak tersedia.\"}) # Hindari menyimpan file error jika listnya tidak ada\n",
    "\n",
    "    if save_t_minus_1_file:\n",
    "        try:\n",
    "            output_json_t_minus_1 = json.dumps(data_untuk_json_t_minus_1, indent=4, ensure_ascii=False)\n",
    "            print(\"\\n--- Output Agregat Final (JSON untuk data t-1) ---\")\n",
    "            if len(output_json_t_minus_1) > 1000: print(output_json_t_minus_1[:1000] + \"... (output t-1 dipotong)\")\n",
    "            else: print(output_json_t_minus_1)\n",
    "\n",
    "            base, ext = os.path.splitext(nama_file_json_output)\n",
    "            nama_file_t_minus_1 = f\"{base}_t_minus_1{ext}\"\n",
    "            full_output_path_t_minus_1 = os.path.join(output_dir_agregat, nama_file_t_minus_1)\n",
    "            \n",
    "            with open(full_output_path_t_minus_1, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(output_json_t_minus_1)\n",
    "            print(f\"\\nMenyimpan hasil ekstraksi (t-1) semua dokumen ke berkas JSON: {full_output_path_t_minus_1}\")\n",
    "\n",
    "        except Exception as e_write_t_minus_1:\n",
    "            print(f\"\\nERROR: Gagal menyimpan berkas JSON (t-1) di '{full_output_path_t_minus_1}': {e_write_t_minus_1}\")\n",
    "    elif not ('semua_hasil_ekstraksi_t_minus_1' in locals() and semua_hasil_ekstraksi_t_minus_1):\n",
    "        print(\"\\nInfo: Tidak ada data (t-1) yang diproses atau valid untuk disimpan.\")\n",
    "else:\n",
    "    print(\"\\nPERINGATAN: 'nama_file_json_output' tidak terdefinisi. Hasil JSON (t-1) tidak disimpan.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e545e27751b20e",
   "metadata": {},
   "source": [
    "## Catatan Akhir: Efisiensi, Keterbatasan, dan Pengembangan Lanjutan\n",
    "\n",
    "Notebook ini menyediakan alur kerja yang komprehensif untuk parsing dokumen dan ekstraksi informasi keuangan dasar. Namun, ada beberapa hal yang perlu diperhatikan:\n",
    "\n",
    "*   **Efisiensi Pemrosesan**:\n",
    "    *   **PDF Besar**: Seperti yang disebutkan, PDF besar dengan banyak halaman gambar bisa lambat karena OCR. Fitur **OCR Paralel** yang diimplementasikan di `parser_pdf.py` membantu mengurangi waktu tunggu.\n",
    "    *   **Caching**: Mekanisme **caching** untuk `parser_pdf.py` (disimpan di `.cache_parser_dokumen` secara default) akan sangat membantu jika Anda sering memproses ulang dokumen yang sama, karena hasil parsing akan diambil dari cache jika file tidak berubah.\n",
    "    *   **Pra-pemrosesan Gambar**: Langkah ini penting untuk akurasi OCR, tetapi juga menambah waktu pemrosesan untuk setiap gambar/halaman gambar.\n",
    "\n",
    "*   **Akurasi Ekstraksi Kata Kunci dan Nilai**:\n",
    "    *   **Logika Tahun Terbaru**: `pengekstrak_kata_kunci.py` kini mencoba mengidentifikasi tahun pelaporan dan memprioritaskan nilai yang berasosiasi dengan tahun tersebut, serta membedakannya dari nilai tahun sebelumnya. Akurasi logika ini sangat bergantung pada konsistensi format tabel dan layout dalam dokumen. Mungkin memerlukan penyesuaian regex lebih lanjut untuk berbagai format laporan keuangan.\n",
    "    *   **Variasi Kata Kunci**: Keberhasilan ekstraksi juga bergantung pada seberapa komprehensif daftar `variasi` untuk setiap `kata_dasar` dalam `konfigurasi_kata_kunci_target`.\n",
    "    *   **Normalisasi Nilai**: Fungsi `normalisasi_nilai_keuangan` menangani format umum Indonesia, tetapi format yang sangat tidak standar mungkin memerlukan penyesuaian.\n",
    "    *   **Konteks**: Ekstraktor saat ini menggunakan konteks kalimat dan kedekatan dengan tahun. Untuk kasus yang sangat ambigu, pemahaman struktur tabel atau elemen visual mungkin diperlukan (di luar cakupan saat ini).\n",
    "\n",
    "*   **Keterbatasan Bahasa Indonesia di NLTK**:\n",
    "    *   **Stopwords**: `pengekstrak_kata_kunci.py` mencoba menggunakan stopwords Bahasa Indonesia dari NLTK. Pastikan resource ini terinstal (`nltk.download('stopwords')`).\n",
    "    *   **Lemmatization/Stemming**: `WordNetLemmatizer` NLTK tidak dioptimalkan untuk Bahasa Indonesia. Untuk hasil yang lebih baik dalam normalisasi kata, pertimbangkan untuk mengintegrasikan stemmer khusus Bahasa Indonesia seperti PySastrawi (memerlukan instalasi terpisah). Saat ini, keakuratan pencocokan lebih bergantung pada variasi eksplisit yang disediakan.\n",
    "\n",
    "*   **Pengembangan Lanjutan yang Mungkin Dilakukan**:\n",
    "    *   Integrasi stemmer Bahasa Indonesia.\n",
    "    *   Pengembangan logika yang lebih canggih untuk memahami struktur tabel dalam dokumen.\n",
    "    *   Pelatihan model Machine Learning kustom untuk klasifikasi teks atau Named Entity Recognition (NER) pada dokumen keuangan untuk identifikasi entitas dan nilai yang lebih robust.\n",
    "    *   Antarmuka pengguna grafis (GUI) atau aplikasi web di atas logika ini.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
