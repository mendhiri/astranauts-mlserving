{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae6e51f2",
   "metadata": {},
   "source": [
    "# Parser Teks Dokumen dan Pengekstrak Kata Kunci Keuangan (Tahunan)\n",
    "\n",
    "Notebook ini bertujuan untuk mem-parsing teks dari berbagai jenis dokumen (gambar, TXT, DOCX, PDF) dan kemudian mengekstrak istilah-istilah keuangan spesifik beserta nilainya, dengan fokus pada **data tahun pelaporan terbaru**. Proses ini melibatkan beberapa teknologi dan fitur utama:\n",
    "- **OCR (Optical Character Recognition)**: Untuk mengekstrak teks dari gambar dan PDF berbasis gambar.\n",
    "- **Pra-pemrosesan Gambar**: Sebelum OCR, gambar diproses melalui beberapa tahap (konversi ke skala abu, penghilangan derau, binerisasi, dan percobaan pelurusan kemiringan) untuk meningkatkan kualitas OCR.\n",
    "- **Pemrosesan Paralel untuk PDF**: Halaman PDF yang memerlukan OCR diproses secara paralel untuk mempercepat ekstraksi.\n",
    "- **Mekanisme Caching**: Hasil parsing PDF disimpan dalam cache untuk menghindari pemrosesan ulang file yang sama jika tidak ada perubahan.\n",
    "- **Ekstraksi Kata Kunci Bertarget**: Mencari istilah keuangan yang telah ditentukan (dalam Bahasa Indonesia) dan mencoba mengidentifikasi nilai numerik yang berasosiasi dengan tahun pelaporan terbaru yang terdeteksi dalam dokumen.\n",
    "- **Normalisasi Nilai**: Nilai keuangan yang diekstrak dinormalisasi ke format float.\n",
    "- **Output JSON**: Hasil akhir ekstraksi kata kunci dan nilainya disajikan dalam format JSON.\n",
    "\n",
    "Pastikan semua skrip Python pendukung (`parser_gambar.py`, `parser_dokumen_teks.py`, `parser_pdf.py`, `pengekstrak_kata_kunci.py`, `utilitas_cache.py`) berada di direktori yang sama dengan notebook ini atau terinstal dalam lingkungan Python Anda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cbffd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:21:28.175687Z",
     "start_time": "2025-06-04T16:20:54.483798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berhasil memuat stopwords Bahasa Indonesia.\n",
      "WordNetLemmatizer berhasil diinisialisasi.\n",
      "Tokenizer 'punkt' tampaknya tersedia.\n",
      "Modul-modul kustom berhasil diimpor.\n",
      "Resource NLTK (wordnet) sudah ada.\n",
      "\n",
      "Pengaturan Selesai. Anda dapat melanjutkan ke sel Konfigurasi.\n"
     ]
    }
   ],
   "source": [
    "# Langkah Pengaturan Awal\n",
    "\n",
    "# 1. Impor Pustaka dan Modul Kustom\n",
    "# Pastikan semua skrip Python (.py) yang disebutkan di bawah ini\n",
    "# berada di direktori yang sama dengan notebook ini.\n",
    "\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "\n",
    "# Impor fungsi-fungsi dari modul-modul utilitas kita\n",
    "try:\n",
    "    from SaranaModule.parser_gambar import ekstrak_teks_dari_gambar\n",
    "    from SaranaModule.parser_dokumen_teks import ekstrak_teks_dari_txt, ekstrak_teks_dari_docx\n",
    "    from SaranaModule.parser_pdf import ekstrak_teks_dari_pdf # Fungsi ini menggunakan ekstrak_teks_dari_gambar untuk OCR\n",
    "    from SaranaModule.parser_tabular import ekstrak_data_dari_xlsx, ekstrak_data_dari_csv\n",
    "    from SaranaModule.pengekstrak_kata_kunci import (\n",
    "        DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT, # Daftar kata kunci default\n",
    "        identifikasi_tahun_pelaporan,       # Untuk menemukan tahun dalam dokumen\n",
    "        ekstrak_data_keuangan_tahunan,      # Fungsi ekstraksi utama yang baru\n",
    "        format_ke_json,                     # Untuk output JSON\n",
    "        normalisasi_nilai_keuangan,          # Untuk membersihkan nilai angka (jika ingin diuji terpisah)\n",
    "        deteksi_pengali_global              # Untuk mendeteksi pengali global seperti 'juta', 'miliar', dll.\n",
    "    )\n",
    "    print(\"Modul-modul kustom berhasil diimpor.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error mengimpor modul kustom: {e}\")\n",
    "    print(\"Pastikan semua file .py (parser_gambar, parser_dokumen_teks, parser_pdf, pengekstrak_kata_kunci, utilitas_cache) berada di direktori yang sama.\")\n",
    "\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet.zip')\n",
    "    print(\"Resource NLTK (wordnet) sudah ada.\")\n",
    "except LookupError:\n",
    "    import ssl\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    print(\"Resource NLTK (wordnet) tidak ditemukan, mengunduh...\")\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('punkt_tab')\n",
    "    nltk.download('omw-1.4') # wordnet multilingual\n",
    "    nltk.download('punkt')   # untuk tokenisasi\n",
    "    nltk.download('stopwords') # untuk stopwords\n",
    "    print(\"Resource NLTK (wordnet) sudah terunduh.\")\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"Error terkait NLTK: {e}\")\n",
    "\n",
    "print(\"\\nPengaturan Selesai. Anda dapat melanjutkan ke sel Konfigurasi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46b6aed",
   "metadata": {},
   "source": [
    "## Penjelasan Fitur Utama\n",
    "\n",
    "Sebelum melanjutkan ke konfigurasi, berikut adalah ringkasan singkat tentang beberapa fitur utama yang digunakan dalam notebook ini:\n",
    "\n",
    "*   **Pra-pemrosesan Gambar untuk OCR**: Jika dokumen Anda adalah gambar atau PDF yang berisi halaman gambar, kualitas OCR sangat penting. Modul `parser_gambar.py` kini menyertakan langkah-langkah seperti konversi ke skala abu, penghilangan derau (noise), dan binerisasi (mengubah gambar menjadi hitam-putih) untuk meningkatkan akurasi Tesseract OCR. Implementasi dasar untuk pelurusan kemiringan (deskewing) juga ada, meskipun mungkin memerlukan penyesuaian lebih lanjut untuk kasus yang kompleks.\n",
    "*   **Pemrosesan Paralel untuk PDF**: Untuk mempercepat ekstraksi teks dari PDF yang memiliki banyak halaman berbasis gambar (yang memerlukan OCR), `parser_pdf.py` menggunakan `ThreadPoolExecutor`. Ini memungkinkan beberapa halaman diproses secara bersamaan, mengurangi waktu tunggu total.\n",
    "*   **Caching Hasil Parsing**: Untuk menghindari pemrosesan ulang file PDF yang sama berulang kali (yang bisa memakan waktu), `parser_pdf.py` kini terintegrasi dengan mekanisme caching (`utilitas_cache.py`). Hasil ekstraksi teks dari sebuah PDF akan disimpan dalam cache (default di direktori `.cache_parser_dokumen`). Jika Anda memproses PDF yang sama lagi dan file tersebut tidak berubah (berdasarkan path dan timestamp modifikasi terakhir), hasilnya akan diambil dari cache, yang jauh lebih cepat. Anda bisa membersihkan cache ini secara manual atau menggunakan fungsi `bersihkan_cache_lama` (jika ingin diimplementasikan lebih lanjut).\n",
    "*   **Logika Ekstraksi Nilai Berbasis Tahun**: Fungsi `ekstrak_data_keuangan_tahunan` dalam `pengekstrak_kata_kunci.py` dirancang untuk pertama-tama mengidentifikasi tahun pelaporan utama dalam dokumen. Kemudian, saat mencari nilai untuk kata kunci keuangan, ia akan mencoba memprioritaskan angka yang berasosiasi dengan tahun pelaporan tersebut dan membedakannya dari angka untuk tahun sebelumnya, jika keduanya muncul berdekatan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e509a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:24:29.942942Z",
     "start_time": "2025-06-04T16:24:29.937024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konfigurasi dimuat. Direktori dokumen yang akan diproses: train_documents/\n",
      "Hasil ekstraksi akan disimpan ke: OutputSarana/hasil_ekstraksi_semua_dokumen.json\n",
      "Kata kunci yang akan dicari: ['Jumlah aset lancar', 'Jumlah aset tidak lancar', 'Jumlah liabilitas jangka pendek', 'Jumlah liabilitas jangka panjang', 'Jumlah ekuitas', 'Jumlah liabilitas dan ekuitas', 'Pendapatan bersih', 'Beban pokok pendapatan', 'Laba bruto', 'Laba sebelum pajak penghasilan', 'Beban pajak penghasilan', 'Laba tahun berjalan', 'Jumlah aset', 'Piutang usaha', 'Aset tetap', 'Aset tetap bruto', 'Akumulasi penyusutan', 'Modal kerja bersih', 'Jumlah liabilitas', 'Laba ditahan', 'Beban bunga', 'Beban penyusutan', 'Beban penjualan', 'Beban administrasi dan umum', 'Beban usaha', 'Arus kas bersih yang diperoleh dari aktivitas operasi', 'Arus kas bersih yang diperoleh dari aktivitas investasi', 'Arus kas bersih yang digunakan untuk aktivitas pendanaan', 'Piutang usaha tahun lalu', 'Pendapatan bersih tahun lalu', 'Laba kotor tahun lalu', 'Aset tidak lancar selain PPE tahun lalu', 'Total aset tahun lalu', 'Beban penyusutan tahun lalu', 'Aset tetap bruto tahun lalu', 'Beban SGA tahun lalu', 'Total liabilitas tahun lalu']\n",
      "Direktori cache PDF kustom diatur ke: .cache_parsing_dokumen\n"
     ]
    }
   ],
   "source": [
    "# --- Konfigurasi Pengguna ---\n",
    "\n",
    "# 1. Tentukan path ke DIREKTORI yang berisi dokumen yang ingin Anda proses.\n",
    "# Contoh: \"train_documents/\" untuk data periode t, atau \"train_documents_t_minus_1/\" untuk data periode t-1.\n",
    "path_direktori_dokumen_input = \"train_documents/\"\n",
    "\n",
    "# 2. Tentukan nama file JSON output untuk menyimpan hasil ekstraksi.\n",
    "# Contoh: \"hasil_ekstraksi_semua_dokumen.json\" untuk periode t,\n",
    "#         \"hasil_ekstraksi_semua_dokumen_t_minus_1.json\" untuk periode t-1.\n",
    "nama_file_json_output = \"hasil_ekstraksi_semua_dokumen.json\"\n",
    "# Direktori output akan tetap \"OutputSarana/\" secara default, jadi path lengkapnya akan menjadi \"OutputSarana/nama_file_json_output\".\n",
    "\n",
    "# 3. Definisikan atau Modifikasi Kata Kunci yang Akan Diekstrak\n",
    "# `konfigurasi_kata_kunci_target` adalah list kamus (dictionary).\n",
    "# Setiap kamus harus memiliki:\n",
    "#    - 'kata_dasar': Nama kanonis untuk kata kunci tersebut (misalnya, \"Laba Bersih\"). Ini akan menjadi kunci dalam output JSON.\n",
    "#    - 'variasi': List berisi berbagai cara penulisan atau sinonim kata kunci tersebut yang mungkin muncul di dokumen.\n",
    "#\n",
    "# Anda bisa menggunakan daftar default yang diimpor (`DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT`)\n",
    "# atau membuat/memodifikasi daftar Anda sendiri di bawah ini.\n",
    "#\n",
    "# Untuk menggunakan daftar default:\n",
    "from SaranaModule.pengekstrak_kata_kunci import DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT\n",
    "konfigurasi_kata_kunci_target = DAFTAR_KATA_KUNCI_KEUANGAN_DEFAULT\n",
    "\n",
    "# 3. (Opsional) Konfigurasi Direktori Cache untuk PDF Parser\n",
    "# Jika Anda ingin parser PDF menggunakan direktori cache selain default (`.cache_parser_dokumen`),\n",
    "# Anda bisa menentukan path-nya di sini. Jika tidak, biarkan `None` untuk menggunakan default.\n",
    "direktori_cache_pdf_kustom = \".cache_parsing_dokumen\"\n",
    "\n",
    "# --- Akhir Konfigurasi Pengguna ---\n",
    "\n",
    "# Validasi awal konfigurasi\n",
    "if 'path_direktori_dokumen_input' not in locals() or not path_direktori_dokumen_input:\n",
    "    print(\"PERINGATAN: 'path_direktori_dokumen_input' belum diatur atau kosong.\")\n",
    "    print(\"Mohon perbarui variabel 'path_direktori_dokumen_input' di atas dengan path ke DIREKTORI yang berisi dokumen-dokumen yang ingin Anda proses.\")\n",
    "elif not os.path.isdir(path_direktori_dokumen_input):\n",
    "    print(f\"ERROR: Path direktori input yang ditentukan ('{path_direktori_dokumen_input}') bukan direktori atau tidak ditemukan.\")\n",
    "    print(\"Mohon periksa kembali 'path_direktori_dokumen_input' dan pastikan itu adalah direktori yang valid dan ada.\")\n",
    "elif 'nama_file_json_output' not in locals() or not nama_file_json_output:\n",
    "    print(\"PERINGATAN: 'nama_file_json_output' belum diatur atau kosong.\")\n",
    "    print(\"Mohon perbarui variabel 'nama_file_json_output' untuk menentukan nama file hasil ekstraksi.\")\n",
    "else:\n",
    "    print(f\"Konfigurasi dimuat. Direktori dokumen yang akan diproses: {path_direktori_dokumen_input}\")\n",
    "    print(f\"Hasil ekstraksi akan disimpan ke: OutputSarana/{nama_file_json_output}\")\n",
    "    print(f\"Kata kunci yang akan dicari: {[item['kata_dasar'] for item in konfigurasi_kata_kunci_target]}\")\n",
    "    if direktori_cache_pdf_kustom:\n",
    "        print(f\"Direktori cache PDF kustom diatur ke: {direktori_cache_pdf_kustom}\")\n",
    "\n",
    "# Inisialisasi list untuk menyimpan semua hasil ekstraksi dari semua dokumen\n",
    "semua_hasil_ekstraksi = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ad4464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:24:34.363713Z",
     "start_time": "2025-06-04T16:24:34.357065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mencari dokumen dengan ekstensi yang didukung: .pdf, .jpg, .jpeg, .png, .tiff, .bmp, .gif, .txt, .docx, .xlsx, .csv di direktori: train_documents/\n",
      "Ditemukan 1 dokumen untuk diproses: ['astra_lapkeu.pdf']\n",
      "\n",
      "--- Memulai pemrosesan untuk dokumen: astra_lapkeu.pdf ---\n",
      "Tipe berkas terdeteksi: .pdf untuk astra_lapkeu.pdf\n",
      "Mengambil hasil dari cache untuk: astra_lapkeu.pdf\n",
      "Parsing dokumen 'astra_lapkeu.pdf' selesai. Total karakter: 12483\n",
      "Memulai ekstraksi kata kunci untuk: astra_lapkeu.pdf\n",
      "Pengali terdeteksi untuk 'astra_lapkeu.pdf': 1000000000.0\n",
      "Ekstraksi kata kunci untuk 'astra_lapkeu.pdf' selesai.\n",
      "--- Pemrosesan untuk dokumen: astra_lapkeu.pdf selesai. Hasil disimpan (secara terpisah untuk t dan t-1). ---\n",
      "\n",
      "=== Semua dokumen dalam direktori telah diproses. ===\n",
      "Total item dalam 'semua_hasil_ekstraksi_t': 1\n",
      "Total item dalam 'semua_hasil_ekstraksi_t_minus_1': 1\n"
     ]
    }
   ],
   "source": [
    "# Langkah ini akan melakukan iterasi melalui semua dokumen yang didukung dalam direktori yang ditentukan,\n",
    "# mengekstrak teks dari masing-masing dokumen, dan kemudian mengekstrak kata kunci.\n",
    "\n",
    "# Pastikan path_direktori_dokumen_input (direktori) telah dikonfigurasi dengan benar dan merupakan direktori\n",
    "if 'path_direktori_dokumen_input' not in locals() or not path_direktori_dokumen_input or not os.path.isdir(path_direktori_dokumen_input) or \\\n",
    "    'nama_file_json_output' not in locals() or not nama_file_json_output:\n",
    "    pesan_error_global = \"Error: Konfigurasi 'path_direktori_dokumen_input' atau 'nama_file_json_output' tidak valid. Silakan perbarui di sel Konfigurasi.\"\n",
    "    if 'path_direktori_dokumen_input' in locals() and (not path_direktori_dokumen_input):\n",
    "        pesan_error_global = \"Error: 'path_direktori_dokumen_input' (direktori) belum diatur atau kosong. Silakan perbarui di sel Konfigurasi.\"\n",
    "    elif 'path_direktori_dokumen_input' in locals() and not os.path.isdir(path_direktori_dokumen_input):\n",
    "        pesan_error_global = f\"Error: Path '{path_direktori_dokumen_input}' bukan direktori yang valid atau tidak ditemukan. Mohon verifikasi path di sel Konfigurasi.\"\n",
    "    elif 'nama_file_json_output' not in locals() or not nama_file_json_output:\n",
    "        pesan_error_global = \"Error: 'nama_file_json_output' belum diatur atau kosong. Silakan perbarui di sel Konfigurasi.\"\n",
    "    \n",
    "    print(pesan_error_global)\n",
    "    # MODIFIKASI: Inisialisasi list t dan t-1 jika ada error konfigurasi global\n",
    "    if 'semua_hasil_ekstraksi_t' not in locals(): semua_hasil_ekstraksi_t = [] \n",
    "    if 'semua_hasil_ekstraksi_t_minus_1' not in locals(): semua_hasil_ekstraksi_t_minus_1 = [] \n",
    "    semua_hasil_ekstraksi_t.append({\n",
    "        \"nama_file\": \"KONFIGURASI_ERROR\",\n",
    "        \"hasil_ekstraksi\": {\"error_global_konfigurasi\": pesan_error_global}\n",
    "    })\n",
    "else:\n",
    "    supported_extensions = ['.pdf', '.jpg', '.jpeg', '.png', '.tiff', '.bmp', '.gif', '.txt', '.docx', '.xlsx', '.csv']\n",
    "    print(f\"Mencari dokumen dengan ekstensi yang didukung: {', '.join(supported_extensions)} di direktori: {path_direktori_dokumen_input}\")\n",
    "    \n",
    "    # MODIFIKASI: Inisialisasi dua list untuk hasil t dan t-1\n",
    "    semua_hasil_ekstraksi_t = []\n",
    "    semua_hasil_ekstraksi_t_minus_1 = []\n",
    "\n",
    "    files_to_process = []\n",
    "    try:\n",
    "        files_to_process = [\n",
    "            f for f in os.listdir(path_direktori_dokumen_input) \n",
    "            if os.path.isfile(os.path.join(path_direktori_dokumen_input, f)) and \n",
    "            os.path.splitext(f)[1].lower() in supported_extensions\n",
    "        ]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Direktori '{path_direktori_dokumen_input}' tidak ditemukan. Periksa konfigurasi path_direktori_dokumen_input.\")\n",
    "        semua_hasil_ekstraksi_t.append({\"nama_file\": \"DIREKTORI_TIDAK_DITEMUKAN\", \"hasil_ekstraksi\": {\"error_direktori\": f\"Direktori '{path_direktori_dokumen_input}' tidak ditemukan.\"}})\n",
    "    except Exception as e_listdir:\n",
    "        print(f\"Error saat mengakses direktori '{path_direktori_dokumen_input}': {e_listdir}\")\n",
    "        semua_hasil_ekstraksi_t.append({\"nama_file\": \"AKSES_DIREKTORI_ERROR\", \"hasil_ekstraksi\": {\"error_direktori\": f\"Error mengakses '{path_direktori_dokumen_input}': {e_listdir}\"}})\n",
    "\n",
    "    if not files_to_process:\n",
    "        msg_no_files = f\"Tidak ada dokumen dengan ekstensi yang didukung ditemukan di {path_direktori_dokumen_input}\"\n",
    "        print(msg_no_files)\n",
    "        # Pastikan pesan 'tidak ada file' hanya ditambahkan jika belum ada error konfigurasi/direktori sebelumnya\n",
    "        if not any(d.get(\"nama_file\") in [\"KONFIGURASI_ERROR\", \"DIREKTORI_TIDAK_DITEMUKAN\", \"AKSES_DIREKTORI_ERROR\"] for d in semua_hasil_ekstraksi_t):\n",
    "            semua_hasil_ekstraksi_t.append({\"nama_file\": \"TIDAK_ADA_FILE\", \"hasil_ekstraksi\": {\"info\": msg_no_files}})\n",
    "    else:\n",
    "        print(f\"Ditemukan {len(files_to_process)} dokumen untuk diproses: {files_to_process}\")\n",
    "\n",
    "        for nama_file_dokumen in files_to_process:\n",
    "            current_file_path = os.path.join(path_direktori_dokumen_input, nama_file_dokumen)\n",
    "            print(f\"\\n--- Memulai pemrosesan untuk dokumen: {nama_file_dokumen} ---\")\n",
    "            \n",
    "            teks_hasil_ekstraksi_file = \"\" # Inisialisasi untuk setiap file\n",
    "            kamus_t_only = {} # MODIFIKASI: Untuk hasil t\n",
    "            kamus_t_minus_1_only = {} # MODIFIKASI: Untuk hasil t-1\n",
    "            \n",
    "            ekstensi_file = os.path.splitext(nama_file_dokumen)[1].lower()\n",
    "            print(f\"Tipe berkas terdeteksi: {ekstensi_file} untuk {nama_file_dokumen}\")\n",
    "\n",
    "            try:\n",
    "                if ekstensi_file == '.pdf':\n",
    "                    dir_cache = direktori_cache_pdf_kustom if 'direktori_cache_pdf_kustom' in locals() and direktori_cache_pdf_kustom else None\n",
    "                    teks_hasil_ekstraksi_file = ekstrak_teks_dari_pdf(current_file_path, ekstrak_teks_dari_gambar, direktori_cache_kustom=dir_cache)\n",
    "                elif ekstensi_file in ['.jpg', '.jpeg', '.png', '.tiff', '.bmp', '.gif']:\n",
    "                    teks_hasil_ekstraksi_file = ekstrak_teks_dari_gambar(current_file_path)\n",
    "                elif ekstensi_file == '.xlsx':\n",
    "                    teks_hasil_ekstraksi_file = ekstrak_data_dari_xlsx(current_file_path)\n",
    "                elif ekstensi_file == '.csv':\n",
    "                    teks_hasil_ekstraksi_file = ekstrak_data_dari_csv(current_file_path)\n",
    "                elif ekstensi_file == '.txt':\n",
    "                    teks_hasil_ekstraksi_file = ekstrak_teks_dari_txt(current_file_path)\n",
    "                elif ekstensi_file == '.docx':\n",
    "                    teks_hasil_ekstraksi_file = ekstrak_teks_dari_docx(current_file_path)\n",
    "            except Exception as e_parse:\n",
    "                error_msg_parse = f\"Error selama parsing dokumen '{nama_file_dokumen}': {str(e_parse)}\"\n",
    "                print(error_msg_parse)\n",
    "                teks_hasil_ekstraksi_file = error_msg_parse \n",
    "\n",
    "            if not teks_hasil_ekstraksi_file.startswith(\"Error:\") and teks_hasil_ekstraksi_file.strip():\n",
    "                print(f\"Parsing dokumen '{nama_file_dokumen}' selesai. Total karakter: {len(teks_hasil_ekstraksi_file)}\")\n",
    "                print(f\"Memulai ekstraksi kata kunci untuk: {nama_file_dokumen}\")\n",
    "                pengali_dokumen_file = 1.0 \n",
    "                print_output_pengali_file = []\n",
    "                try:\n",
    "                    pengali_dokumen_file = deteksi_pengali_global(teks_hasil_ekstraksi_file)\n",
    "                    print_output_pengali_file.append(f\"Pengali terdeteksi untuk '{nama_file_dokumen}': {pengali_dokumen_file}\")\n",
    "                except Exception as e_pengali:\n",
    "                    print_output_pengali_file.append(f\"Error saat deteksi pengali untuk '{nama_file_dokumen}': {str(e_pengali)}. Menggunakan default 1.0.\")\n",
    "                    pengali_dokumen_file = 1.0\n",
    "                for msg in print_output_pengali_file: print(msg)\n",
    "                if 'konfigurasi_kata_kunci_target' not in locals() or not konfigurasi_kata_kunci_target:\n",
    "                    pesan_error_konfig_loop = \"Error krusial: 'konfigurasi_kata_kunci_target' tidak terdefinisi. Periksa sel Konfigurasi.\"\n",
    "                    print(pesan_error_konfig_loop)\n",
    "                    kamus_t_only = {\"error_konfigurasi_global\": pesan_error_konfig_loop} # MODIFIKASI\n",
    "                else:\n",
    "                    try:\n",
    "                        kamus_hasil_ekstraksi_file_lengkap = ekstrak_data_keuangan_tahunan(\n",
    "                            teks_hasil_ekstraksi_file, \n",
    "                            konfigurasi_kata_kunci_target, \n",
    "                            pengali_global=pengali_dokumen_file\n",
    "                        )\n",
    "                        print(f\"Ekstraksi kata kunci untuk '{nama_file_dokumen}' selesai.\")\n",
    "                        # MODIFIKASI: Memecah hasil_ekstraksi_file_lengkap menjadi t_only dan t_minus_1_only\n",
    "                        if isinstance(kamus_hasil_ekstraksi_file_lengkap, dict):\n",
    "                            for key, values_dict in kamus_hasil_ekstraksi_file_lengkap.items():\n",
    "                                if isinstance(values_dict, dict):\n",
    "                                    if values_dict.get('t') is not None:\n",
    "                                        kamus_t_only[key] = values_dict['t']\n",
    "                                    if values_dict.get('t-1') is not None:\n",
    "                                        kamus_t_minus_1_only[key] = values_dict['t-1']\n",
    "                                else: # Fallback jika struktur tidak seperti yang diharapkan\n",
    "                                    kamus_t_only[key] = values_dict \n",
    "                        else: # Jika hasil ekstraksi bukan dict (misal, error string dari tahap sebelumnya)\n",
    "                             kamus_t_only = kamus_hasil_ekstraksi_file_lengkap\n",
    "                    except Exception as e_ekstraksi:\n",
    "                        pesan_error_ekstraksi_loop = f\"Error selama proses ekstraksi kata kunci untuk '{nama_file_dokumen}': {str(e_ekstraksi)}\"\n",
    "                        print(pesan_error_ekstraksi_loop)\n",
    "                        kamus_t_only = {\"error_runtime_ekstraksi\": pesan_error_ekstraksi_loop} # MODIFIKASI\n",
    "                        kamus_t_minus_1_only = {} # Tetap kosong saat error\n",
    "            elif not teks_hasil_ekstraksi_file.strip() and not teks_hasil_ekstraksi_file.startswith(\"Error:\"):\n",
    "                info_msg = f\"Info: Teks yang diekstrak dari '{nama_file_dokumen}' kosong atau hanya spasi putih.\"\n",
    "                print(info_msg)\n",
    "                kamus_t_only = {\"info_parsing\": info_msg} # MODIFIKASI\n",
    "                kamus_t_minus_1_only = {}\n",
    "            else: # Ada error dari parsing (teks_hasil_ekstraksi_file sudah berisi pesan error)\n",
    "                kamus_t_only = {\"error_parsing\": teks_hasil_ekstraksi_file} # MODIFIKASI\n",
    "                kamus_t_minus_1_only = {}\n",
    "\n",
    "            # MODIFIKASI: Simpan ke list yang sesuai\n",
    "            if kamus_t_only: # Hanya tambahkan jika ada isinya (termasuk error/info)\n",
    "                semua_hasil_ekstraksi_t.append({\n",
    "                    \"nama_file\": nama_file_dokumen,\n",
    "                    \"hasil_ekstraksi\": kamus_t_only\n",
    "                })\n",
    "            \n",
    "            if kamus_t_minus_1_only: # Hanya tambahkan jika ada isinya\n",
    "                 semua_hasil_ekstraksi_t_minus_1.append({\n",
    "                    \"nama_file\": nama_file_dokumen,\n",
    "                    \"hasil_ekstraksi\": kamus_t_minus_1_only\n",
    "                })\n",
    "            print(f\"--- Pemrosesan untuk dokumen: {nama_file_dokumen} selesai. Hasil disimpan (secara terpisah untuk t dan t-1). ---\")\n",
    "            \n",
    "        print(\"\\n=== Semua dokumen dalam direktori telah diproses. ===\")\n",
    "\n",
    "# MODIFIKASI: Ringkasan setelah loop selesai (opsional, bisa disesuaikan untuk dua list)\n",
    "if 'semua_hasil_ekstraksi_t' in locals() and semua_hasil_ekstraksi_t:\n",
    "    print(f\"Total item dalam 'semua_hasil_ekstraksi_t': {len(semua_hasil_ekstraksi_t)}\")\n",
    "    # Tambahkan loop serupa untuk semua_hasil_ekstraksi_t_minus_1 jika perlu detail status\n",
    "else:\n",
    "    print(\"Tidak ada hasil ekstraksi (t) yang tersimpan atau list kosong. Periksa log di atas.\")\n",
    "if 'semua_hasil_ekstraksi_t_minus_1' in locals() and semua_hasil_ekstraksi_t_minus_1:\n",
    "    print(f\"Total item dalam 'semua_hasil_ekstraksi_t_minus_1': {len(semua_hasil_ekstraksi_t_minus_1)}\")\n",
    "else:\n",
    "    print(\"Tidak ada hasil ekstraksi (t-1) yang tersimpan atau list kosong.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa89525e73aaa7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'semua_hasil_ekstraksi_t' ditemukan dengan 1 item. Akan diformat ke JSON.\n",
      "\n",
      "--- Output Agregat Final (JSON untuk data t) ---\n",
      "[\n",
      "    {\n",
      "        \"nama_file\": \"astra_lapkeu.pdf\",\n",
      "        \"hasil_ekstraksi\": {\n",
      "            \"Jumlah aset lancar\": 19238000000000.0,\n",
      "            \"Jumlah aset tidak lancar\": 81765000000000.0,\n",
      "            \"Jumlah liabilitas jangka pendek\": 14300000000000.0,\n",
      "            \"Jumlah liabilitas jangka panjang\": 1989000000000.0,\n",
      "            \"Jumlah ekuitas\": 84714000000000.0,\n",
      "            \"Jumlah liabilitas dan ekuitas\": 101003000000000.0,\n",
      "            \"Pendapatan bersih\": 108249000000000.0,\n",
      "            \"Beban pokok pendapatan\": -97738000000000.0,\n",
      "            \"Laba bruto\": 10511000000000.0,\n",
      "            \"Laba sebelum pajak penghasilan\": 22136000000000.0,\n",
      "            \"Beban pajak penghasilan\": -475000000000.0,\n",
      "            \"Laba tahun berjalan\": 21661000000000.0,\n",
      "            \"Jumlah aset\": 19238000000000.0,\n",
      "            \"Piutang usaha\": 1000000000.0,\n",
      "            \"Aset tetap\": 15697000000000.0,\n",
      "            \"Jumlah liabilitas\": 14300000000000.0,\n",
      "            \"Laba ditahan\": 425000000000.0,\n",
      "            \"Beba... (output t dipotong)\n",
      "\n",
      "Menyimpan hasil ekstraksi (t) semua dokumen ke berkas JSON: Output/Sarana/hasil_ekstraksi_semua_dokumen.json\n",
      "'semua_hasil_ekstraksi_t_minus_1' ditemukan dengan 1 item. Akan diformat ke JSON.\n",
      "\n",
      "--- Output Agregat Final (JSON untuk data t-1) ---\n",
      "[\n",
      "    {\n",
      "        \"nama_file\": \"astra_lapkeu.pdf\",\n",
      "        \"hasil_ekstraksi\": {\n",
      "            \"Jumlah aset lancar\": 21682000000000.0,\n",
      "            \"Jumlah aset tidak lancar\": 79502000000000.0,\n",
      "            \"Jumlah liabilitas jangka pendek\": 15275000000000.0,\n",
      "            \"Jumlah liabilitas jangka panjang\": 1851000000000.0,\n",
      "            \"Jumlah ekuitas\": 84058000000000.0,\n",
      "            \"Jumlah liabilitas dan ekuitas\": 101184000000000.0,\n",
      "            \"Pendapatan bersih\": 106427000000000.0,\n",
      "            \"Beban pokok pendapatan\": -95573000000000.0,\n",
      "            \"Laba bruto\": 10854000000000.0,\n",
      "            \"Laba sebelum pajak penghasilan\": 31478000000000.0,\n",
      "            \"Beban pajak penghasilan\": -547000000000.0,\n",
      "            \"Laba tahun berjalan\": 30931000000000.0,\n",
      "            \"Jumlah aset\": 21682000000000.0,\n",
      "            \"Piutang usaha\": 2023000000000.0,\n",
      "            \"Aset tetap\": 15472000000000.0,\n",
      "            \"Jumlah liabilitas\": 15275000000000.0,\n",
      "            \"Beban bunga\": -132000000000.0,\n",
      "            \"B... (output t-1 dipotong)\n",
      "\n",
      "Menyimpan hasil ekstraksi (t-1) semua dokumen ke berkas JSON: Output/Sarana/hasil_ekstraksi_semua_dokumen_t_minus_1.json\n"
     ]
    }
   ],
   "source": [
    "# MODIFIKASI: Langkah ini sekarang akan memformat dan menyimpan dua set data: t dan t-1.\n",
    "\n",
    "output_dir_agregat = \"Output/Sarana\"\n",
    "os.makedirs(output_dir_agregat, exist_ok=True) # Buat direktori jika belum ada\n",
    "\n",
    "# --- PENYIMPANAN DATA T ---\n",
    "if 'nama_file_json_output' in locals() and nama_file_json_output:\n",
    "    data_untuk_json_t = []\n",
    "    if 'semua_hasil_ekstraksi_t' in locals() and isinstance(semua_hasil_ekstraksi_t, list):\n",
    "        if semua_hasil_ekstraksi_t: # Jika list tidak kosong\n",
    "            print(f\"'semua_hasil_ekstraksi_t' ditemukan dengan {len(semua_hasil_ekstraksi_t)} item. Akan diformat ke JSON.\")\n",
    "            data_untuk_json_t = semua_hasil_ekstraksi_t\n",
    "        else: # List ada tapi kosong\n",
    "            print(\"Info: 'semua_hasil_ekstraksi_t' adalah list kosong (tidak ada file diproses atau file tidak menghasilkan output).\")\n",
    "            data_untuk_json_t.append({\"info\": \"Tidak ada data (t) yang diekstrak dari dokumen manapun.\"})\n",
    "    else: # Variabel tidak ada atau bukan list\n",
    "        print(\"Error: 'semua_hasil_ekstraksi_t' tidak ditemukan atau tidak valid. Proses ekstraksi mungkin gagal total.\")\n",
    "        data_untuk_json_t.append({\"error_kritis\": \"Variabel 'semua_hasil_ekstraksi_t' tidak tersedia atau tidak valid.\"})\n",
    "\n",
    "    try:\n",
    "        output_json_t = json.dumps(data_untuk_json_t, indent=4, ensure_ascii=False)\n",
    "        print(\"\\n--- Output Agregat Final (JSON untuk data t) ---\")\n",
    "        if len(output_json_t) > 1000: print(output_json_t[:1000] + \"... (output t dipotong)\")\n",
    "        else: print(output_json_t)\n",
    "        \n",
    "        full_output_path_t = os.path.join(output_dir_agregat, nama_file_json_output) # Nama file asli untuk data t\n",
    "        with open(full_output_path_t, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(output_json_t)\n",
    "        print(f\"\\nMenyimpan hasil ekstraksi (t) semua dokumen ke berkas JSON: {full_output_path_t}\")\n",
    "    except Exception as e_write_t:\n",
    "        print(f\"\\nERROR: Gagal menyimpan berkas JSON (t) di '{full_output_path_t}': {e_write_t}\")\n",
    "else:\n",
    "    print(\"\\nPERINGATAN: 'nama_file_json_output' tidak terdefinisi. Hasil JSON (t) tidak disimpan.\")\n",
    "\n",
    "# --- PENYIMPANAN DATA T-1 ---\n",
    "if 'nama_file_json_output' in locals() and nama_file_json_output:\n",
    "    data_untuk_json_t_minus_1 = []\n",
    "    save_t_minus_1_file = False # Flag untuk menentukan apakah file t-1 perlu disimpan\n",
    "\n",
    "    if 'semua_hasil_ekstraksi_t_minus_1' in locals() and isinstance(semua_hasil_ekstraksi_t_minus_1, list):\n",
    "        if semua_hasil_ekstraksi_t_minus_1: # Jika list tidak kosong\n",
    "            print(f\"'semua_hasil_ekstraksi_t_minus_1' ditemukan dengan {len(semua_hasil_ekstraksi_t_minus_1)} item. Akan diformat ke JSON.\")\n",
    "            data_untuk_json_t_minus_1 = semua_hasil_ekstraksi_t_minus_1\n",
    "            save_t_minus_1_file = True\n",
    "        else: # List ada tapi kosong\n",
    "            print(\"Info: 'semua_hasil_ekstraksi_t_minus_1' adalah list kosong (tidak ada data t-1 yang diekstrak).\")\n",
    "            # Tidak membuat file jika memang tidak ada data t-1 sama sekali\n",
    "    else: # Variabel tidak ada atau bukan list\n",
    "        print(\"Error: 'semua_hasil_ekstraksi_t_minus_1' tidak ditemukan atau tidak valid.\")\n",
    "        # data_untuk_json_t_minus_1.append({\"error_kritis\": \"Variabel 'semua_hasil_ekstraksi_t_minus_1' tidak tersedia.\"}) # Hindari menyimpan file error jika listnya tidak ada\n",
    "\n",
    "    if save_t_minus_1_file:\n",
    "        try:\n",
    "            output_json_t_minus_1 = json.dumps(data_untuk_json_t_minus_1, indent=4, ensure_ascii=False)\n",
    "            print(\"\\n--- Output Agregat Final (JSON untuk data t-1) ---\")\n",
    "            if len(output_json_t_minus_1) > 1000: print(output_json_t_minus_1[:1000] + \"... (output t-1 dipotong)\")\n",
    "            else: print(output_json_t_minus_1)\n",
    "\n",
    "            base, ext = os.path.splitext(nama_file_json_output)\n",
    "            nama_file_t_minus_1 = f\"{base}_t_minus_1{ext}\"\n",
    "            full_output_path_t_minus_1 = os.path.join(output_dir_agregat, nama_file_t_minus_1)\n",
    "            \n",
    "            with open(full_output_path_t_minus_1, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(output_json_t_minus_1)\n",
    "            print(f\"\\nMenyimpan hasil ekstraksi (t-1) semua dokumen ke berkas JSON: {full_output_path_t_minus_1}\")\n",
    "\n",
    "        except Exception as e_write_t_minus_1:\n",
    "            print(f\"\\nERROR: Gagal menyimpan berkas JSON (t-1) di '{full_output_path_t_minus_1}': {e_write_t_minus_1}\")\n",
    "    elif not ('semua_hasil_ekstraksi_t_minus_1' in locals() and semua_hasil_ekstraksi_t_minus_1):\n",
    "        print(\"\\nInfo: Tidak ada data (t-1) yang diproses atau valid untuk disimpan.\")\n",
    "else:\n",
    "    print(\"\\nPERINGATAN: 'nama_file_json_output' tidak terdefinisi. Hasil JSON (t-1) tidak disimpan.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e545e27751b20e",
   "metadata": {},
   "source": [
    "## Catatan Akhir: Efisiensi, Keterbatasan, dan Pengembangan Lanjutan\n",
    "\n",
    "Notebook ini menyediakan alur kerja yang komprehensif untuk parsing dokumen dan ekstraksi informasi keuangan dasar. Namun, ada beberapa hal yang perlu diperhatikan:\n",
    "\n",
    "*   **Efisiensi Pemrosesan**:\n",
    "    *   **PDF Besar**: Seperti yang disebutkan, PDF besar dengan banyak halaman gambar bisa lambat karena OCR. Fitur **OCR Paralel** yang diimplementasikan di `parser_pdf.py` membantu mengurangi waktu tunggu.\n",
    "    *   **Caching**: Mekanisme **caching** untuk `parser_pdf.py` (disimpan di `.cache_parser_dokumen` secara default) akan sangat membantu jika Anda sering memproses ulang dokumen yang sama, karena hasil parsing akan diambil dari cache jika file tidak berubah.\n",
    "    *   **Pra-pemrosesan Gambar**: Langkah ini penting untuk akurasi OCR, tetapi juga menambah waktu pemrosesan untuk setiap gambar/halaman gambar.\n",
    "\n",
    "*   **Akurasi Ekstraksi Kata Kunci dan Nilai**:\n",
    "    *   **Logika Tahun Terbaru**: `pengekstrak_kata_kunci.py` kini mencoba mengidentifikasi tahun pelaporan dan memprioritaskan nilai yang berasosiasi dengan tahun tersebut, serta membedakannya dari nilai tahun sebelumnya. Akurasi logika ini sangat bergantung pada konsistensi format tabel dan layout dalam dokumen. Mungkin memerlukan penyesuaian regex lebih lanjut untuk berbagai format laporan keuangan.\n",
    "    *   **Variasi Kata Kunci**: Keberhasilan ekstraksi juga bergantung pada seberapa komprehensif daftar `variasi` untuk setiap `kata_dasar` dalam `konfigurasi_kata_kunci_target`.\n",
    "    *   **Normalisasi Nilai**: Fungsi `normalisasi_nilai_keuangan` menangani format umum Indonesia, tetapi format yang sangat tidak standar mungkin memerlukan penyesuaian.\n",
    "    *   **Konteks**: Ekstraktor saat ini menggunakan konteks kalimat dan kedekatan dengan tahun. Untuk kasus yang sangat ambigu, pemahaman struktur tabel atau elemen visual mungkin diperlukan (di luar cakupan saat ini).\n",
    "\n",
    "*   **Keterbatasan Bahasa Indonesia di NLTK**:\n",
    "    *   **Stopwords**: `pengekstrak_kata_kunci.py` mencoba menggunakan stopwords Bahasa Indonesia dari NLTK. Pastikan resource ini terinstal (`nltk.download('stopwords')`).\n",
    "    *   **Lemmatization/Stemming**: `WordNetLemmatizer` NLTK tidak dioptimalkan untuk Bahasa Indonesia. Untuk hasil yang lebih baik dalam normalisasi kata, pertimbangkan untuk mengintegrasikan stemmer khusus Bahasa Indonesia seperti PySastrawi (memerlukan instalasi terpisah). Saat ini, keakuratan pencocokan lebih bergantung pada variasi eksplisit yang disediakan.\n",
    "\n",
    "*   **Pengembangan Lanjutan yang Mungkin Dilakukan**:\n",
    "    *   Integrasi stemmer Bahasa Indonesia.\n",
    "    *   Pengembangan logika yang lebih canggih untuk memahami struktur tabel dalam dokumen.\n",
    "    *   Pelatihan model Machine Learning kustom untuk klasifikasi teks atau Named Entity Recognition (NER) pada dokumen keuangan untuk identifikasi entitas dan nilai yang lebih robust.\n",
    "    *   Antarmuka pengguna grafis (GUI) atau aplikasi web di atas logika ini.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
